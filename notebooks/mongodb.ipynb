{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_chunkers import StatisticalChunker\n",
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Các bạn đồng nghiệp CMC thân mến, Đối với mỗi người, tuổi 30 đánh dấu sự trưởng thành, vững vàng; là giai đoạn chuyển mình  với những hoài bão, khát khao cống hiến và mang lại nhiều giá trị hơn cho cuộc đời.\n",
      "Với CMC, tuổi 30 là dấu mốc quan trọng trên hành trình xây dựng và phát triển mới để trở  thành Tập đoàn số toàn cầu với một ước mơ lớn, một sứ mệnh lớn lao hơn: tạo ra ngày  càng nhiều những Di sản số cho chính chúng ta và cho đất nước, xã hội.\n",
      "Cuốn Sử ký CMC 30 - “Kiến tạo di sản số” là chuyến hành trình trở về những dấu mốc,  những trang nhật ký hào hùng trong suốt 30 năm xây dựng và phát triển của Tập đoàn. \n",
      "Ký ức 30 năm ấy, là bức phác họa chân thực nhất về hình ảnh Người CMC ngay từ những  ngày đầu khởi nghiệp; là hình ảnh mộc mạc, giản dị của những kỹ sư công nghệ đầy đam  mê, bản lĩnh; dám nghĩ, dám làm; là dấu chân của hàng ngàn anh em CMC nhiệt huyết, kỷ  luật, sáng tạo trong từng công việc được giao; là khát khao, là sự nỗ lực không ngừng nghỉ  để tạo nên những thành tựu đáng tự hào cho sự phát triển của CMC trong 30 năm qua và  những giai đoạn tiếp theo. \n",
      "Sử ký CMC 30 được chia làm 2 phần: Phần 1 - Sử gồm 3 chương Lửa - Khát - Cháy ghi lại  dấu mốc của CMC với 10 năm hình thành, 10 năm xây dựng và 10 năm phát triển rực rỡ của  Tập đoàn. Phần 2 - Ký mang tên Kiến tạo, là ký ức, là những câu chuyện, cảm xúc, tâm sự  của Người CMC xuyên suốt 30 năm.\n",
      "Tôi tin rằng, cuốn Sử ký CMC 30 là minh chứng rõ nét cho tinh thần gắn kết, tình yêu, niềm  tự hào của mỗi Người CMC chúng ta! Hãy luôn giữ nguồn cảm hứng, tình yêu, ngọn lửa khát khao mãnh liệt ấy để viết tiếp  những trang sử mới trên con đường Kiến tạo Di sản số cho mình, cho CMC; và góp phần  xây dựng CMC của chúng ta trở thành Tập đoàn mang tầm thế giới, đưa Việt Nam trở  thành quốc gia trung tâm trên bản đồ số toàn cầu! Chủ tịch HĐQT/ Chủ tịch điều hành Tập đoàn Nguyễn Trung Chính.Chương 1 -  là cánh cửa kỷ lục đầu tiên mở ra lịch sử CMC. Đây là bước khắc họa chân thực về 10 (1993 - 2003) với những bước\n"
     ]
    }
   ],
   "source": [
    "with open('data_for_chunks/su_ky_30_preproccesssing.txt','r', encoding='utf-8') as suky_doc:\n",
    "    documents=suky_doc.read()\n",
    "print(documents[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"hiieu/halong_embedding\"\n",
    "encoder=HuggingFaceEncoder(name=model_name)\n",
    "statistic_chunking = StatisticalChunker(encoder=encoder,min_split_tokens=50,max_split_tokens=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 20:49:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 28/28 [03:51<00:00,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 101, triggered by: token limit\n",
      "\u001b[31mCác bạn đồng nghiệp CMC thân mến, Đối với mỗi người, tuổi 30 đánh dấu sự trưởng thành, vững vàng; là giai đoạn chuyển mình  với những hoài bão, khát khao cống hiến và mang lại nhiều giá trị hơn cho cuộc đời.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 122, triggered by: token limit\n",
      "\u001b[32mVới CMC, tuổi 30 là dấu mốc quan trọng trên hành trình xây dựng và phát triển mới để trở  thành Tập đoàn số toàn cầu với một ước mơ lớn, một sứ mệnh lớn lao hơn: tạo ra ngày  càng nhiều những Di sản số cho chính chúng ta và cho đất nước, xã hội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 84, triggered by: token limit\n",
      "\u001b[34mCuốn Sử ký CMC 30 - “Kiến tạo di sản số” là chuyến hành trình trở về những dấu mốc,  những trang nhật ký hào hùng trong suốt 30 năm xây dựng và phát triển của Tập đoàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 233, triggered by: token limit\n",
      "\u001b[35mKý ức 30 năm ấy, là bức phác họa chân thực nhất về hình ảnh Người CMC ngay từ những  ngày đầu khởi nghiệp; là hình ảnh mộc mạc, giản dị của những kỹ sư công nghệ đầy đam  mê, bản lĩnh; dám nghĩ, dám làm; là dấu chân của hàng ngàn anh em CMC nhiệt huyết, kỷ  luật, sáng tạo trong từng công việc được giao; là khát khao, là sự nỗ lực không ngừng nghỉ  để tạo nên những thành tựu đáng tự hào cho sự phát triển của CMC trong 30 năm qua và  những giai đoạn tiếp theo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 155, triggered by: token limit\n",
      "\u001b[31mSử ký CMC 30 được chia làm 2 phần: Phần 1 - Sử gồm 3 chương Lửa - Khát - Cháy ghi lại  dấu mốc của CMC với 10 năm hình thành, 10 năm xây dựng và 10 năm phát triển rực rỡ của  Tập đoàn. Phần 2 - Ký mang tên Kiến tạo, là ký ức, là những câu chuyện, cảm xúc, tâm sự  của Người CMC xuyên suốt 30 năm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 68, triggered by: token limit\n",
      "\u001b[32mTôi tin rằng, cuốn Sử ký CMC 30 là minh chứng rõ nét cho tinh thần gắn kết, tình yêu, niềm  tự hào của mỗi Người CMC chúng ta!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 141, triggered by: token limit\n",
      "\u001b[34mHãy luôn giữ nguồn cảm hứng, tình yêu, ngọn lửa khát khao mãnh liệt ấy để viết tiếp  những trang sử mới trên con đường Kiến tạo Di sản số cho mình, cho CMC; và góp phần  xây dựng CMC của chúng ta trở thành Tập đoàn mang tầm thế giới, đưa Việt Nam trở  thành quốc gia trung tâm trên bản đồ số toàn cầu!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 157, triggered by: token limit\n",
      "\u001b[35mChủ tịch HĐQT/ Chủ tịch điều hành Tập đoàn Nguyễn Trung Chính.Chương 1 -  là cánh cửa kỷ lục đầu tiên mở ra lịch sử CMC. Đây là bước khắc họa chân thực về 10 (1993 - 2003) với những bước đi không hò thanh của Tập đoàn quyết, đặt nền móng vững chắc cho sự phát triển của CMC trong những giai đoạn tiếp theo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 185, triggered by: token limit\n",
      "\u001b[31mLật giờ từng trang sách và cánh cửa khám phá từng dấu ấn, từng câu chuyện bi quyết của CMC những bước chân đầu tiên, khẳng định về sự đổi chiều linh thi trong trong kinh doanh, hay những câu chuyện cảm hứng về con người, tinh thần CMC và thành quả tu hào mà chúng ta đặt được ngày chuyển  bắt đầu cuộc nghiệp. . . Câu chuyện tình đầy  và  gặp gỡ nhân duyên của 2 nhà sáng lập CMC:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 181, triggered by: 0.30\n",
      "\u001b[32mCó Chủ tịch Hà Thế Minh và Chủ tịch hiện thời Nguyễn Trung Chính của Tập đoàn Công nghệ CMC. Cùng khám phá điểm tương đồng của họ với những nhà sáng lập của các Tập đoàn công nghệ  lớn  trên thế giới như Legend (Lenovo) hay xuất phát từ những Viện nghiên cứu, công nghệ tài năng, gian di; cùng chung lý tưởng và hoài bão đưa công nghệ vào đời sống xã hội, mang lại giá trị thực cho con người.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 188, triggered by: token limit\n",
      "\u001b[34mRa đời năm 1993 với tên gọi Công ty TNHH HT & NT, sau đó đổi tên thành Công ty TNHH Máy tính truyền thông CMC vào 1995, rất nhanh chóng, CMC đã phát triển và trở thành một tập hợp các công ty công nghệ lớn,  tại Việt Nam, bao gồm: Công ty  Máy tính truyền thông CMC (Hà Nội), Công ty Sản xuất và Dịch vụ Máy tính Thể  Trung - CMS, Công ty Nhật Quang - Blue Sky,  Công ty Máy tính Truyền thông II (CMC Sài Gòn).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 54, triggered by: 0.21\n",
      "\u001b[35mNgay từ những ngày đầu, CMC đã kiên định: Phải  đầu tư một cách bài bản và những  lính  yếu mà  công ty tham gia.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 186, triggered by: token limit\n",
      "\u001b[31mVà mô hình quản lý tiên tiến hiệu quả, trình độ cao, trao việc cho đúng người  là 1 trong những con của Công ty và  trong  Group trong 10 năm. Với 10 năm hình thành, CMC đã phát triển vững chắc trên cả ba chân kiềng trong ngành Công nghệ thông tin: Tiền phong trong lĩnh vực đầu tư nghiên cứu và sản xuất phần mềm;  dùng  khách hàng; và  đặc biệt đã chiếm được vị trí số 1  trong với  máy  tính Việt Nam - thương hiệu  CMS.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 166, triggered by: token limit\n",
      "\u001b[32mMột thập kỷ trôi qua, với những bước  đi  tư tin và vững chắc, luôn  chạy hết mình với những \"đam mê\"  và  tinh yêu  công nghệ, CMC  đã  dám  sơ  và  tiên, đóng góp  quan trọng  vào sự phát triển của  đời sống xã hội, đặc biệt là giai đoạn còn nhiều  khó khăn của  Đất nước - Giai đoạn ĐỔI MỚI.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 255, triggered by: token limit\n",
      "\u001b[34mKIẾN TẠO DỊ SẢN SỐ 3.Tiếng còi của Đoàn tàu Đổi mới gióng lên những khát khao  trong trái tim người Việt Nam, thúc giục một dân tộc biến  đau thương thành sức mạnh và truyền đi thông điệp dám  nghĩ, dám mơ và dám thực hiện những ước mơ lớn… ÐOÀN TÀU ÐỔI MỚI  Tiếng còi của Giấc mơ về CHIẾC MÁY TÍNH MADE IN VIỆT NAM.Năm 1986 đánh dấu những thay đổi quan trọng trong đường lối, chủ  trương, chính sách phát triển của Nhà nước khi Việt Nam vừa thoát  khỏi “Thời kỳ bao cấp”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 131, triggered by: 0.24\n",
      "\u001b[35mNhững tờ tem phiếu, sổ gạo quý giá in dấu  trong ký ức một thời của bao người Việt Nam đã lùi dần vào dĩ vãng,  mở ra giai đoạn phát triển mới của dân tộc. Đường lối đổi mới toàn diện đất nước đã tác động trực tiếp tới việc  đổi mới cơ chế quản lý khoa học & kỹ thuật.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 17, tokens 122, triggered by: 0.22\n",
      "\u001b[31mNghị quyết Đại hội Đảng  VI (1986) khẳng định “Cơ chế quản lý kinh tế, quản lý khoa học &  kỹ thuật phải đòi hỏi và khuyến khích việc sáng tạo và ứng dụng  rộng rãi các thành tựu khoa học & kỹ thuật, đưa lại hiệu quả  thiết thực”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 18, tokens 245, triggered by: token limit\n",
      "\u001b[32mNếu như trước đó, việc nghiên cứu khoa học được định nghĩa gắn liền  những nghiên cứu hàn lâm, đỉnh cao và chỉ nằm trong phòng thí  nghiệm thì những năm đầu của thập niên 80, có một nhà khoa học đã  tự chọn cho mình lối rẽ khác: xin thành lập một tổ chức nghiên cứu  phát triển nhưng tập trung vào ứng dụng công nghệ. “Cuộc chơi” ấy  đòi hỏi những kỹ sư giỏi, các nhà kỹ thuật đủ tầm và đủ say mê để  đem những công nghệ cao vào giải quyết các yêu cầu từ xí nghiệp,  từ thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 19, tokens 200, triggered by: token limit\n",
      "\u001b[34m“Người chiến binh ngược dòng tiên phong” ấy là Giáo sư Vũ Đình Cự  - một nhà chính khách, một nhà khoa học tài ba - nguyên Viện trưởng  Viện Công nghệ Quốc gia, nguyên Ủy viên Ban Chấp hành Trung ương  Đảng Cộng sản Việt Nam, nguyên Phó Chủ tịch Quốc hội. Viện Nghiên cứu Công nghệ Quốc gia (viết tắt là Nacentech) được  thành lập tháng 10 năm 1984 với sứ mệnh đưa ứng dụng khoa học kỹ  thuật vào trong cuộc sống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 20, tokens 105, triggered by: token limit\n",
      "\u001b[35mNhững năm 80 của thế kỷ trước, không khí khắp nơi rộn ràng về một  thời kỳ mới của dân tộc Việt Nam. Anh vẫn còn nhớ mình đã chứng  kiến một đoàn tàu được kéo bởi toa tàu mang tên ĐỔI MỚI.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 21, tokens 170, triggered by: token limit\n",
      "\u001b[31mAnh Nguyễn Trung Chính   Chủ tịch HĐQT Tập đoàn nhớ lại Tiếng còi rộn ràng của  đoàn tàu đổi mới   .Viện thực hiện nhiệm vụ nghiên cứu, làm chủ các công nghệ cao tiến  tới sáng tạo, chuyển giao công nghệ nhằm đáp ứng yêu cầu của thị  trường, góp phần thực hiện công nghiệp hoá, hiện đại hoá đất nước  và đảm bảo an ninh quốc phòng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 22, tokens 117, triggered by: token limit\n",
      "\u001b[32mNhững định hướng của Viện thời bấy  giờ rất “hot”: công nghệ thông tin, công nghệ laser, công nghệ vi  điện tử, công nghệ vật liệu mới, công nghệ sinh học… Các lĩnh vực  khác cũng được đầu tư một cách bài bản (so với tiềm lực đất nước  thời bấy giờ).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 23, tokens 137, triggered by: token limit\n",
      "\u001b[34mMột thành quả lớn sau này vẫn được nhắc đến đó là  Viện Công nghệ Laser đã thành công trong việc kéo đường cáp quang  đầu tiên nối Bưu điện Bờ Hồ với Trung tâm Viễn thông ở Láng (VNPT  ngày nay). Nacentech là nơi quy tụ những tài năng trẻ và thực sự  trở thành “ngôi sao” trong giới khoa học công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 24, tokens 206, triggered by: token limit\n",
      "\u001b[35mSau 6 năm học tập bài bản và 3 năm làm việc thực tế tại những viện  nghiên cứu, những liên hiệp, xí nghiệp lớn của Hungary, anh thanh  niên trẻ Hà Thế Minh về nước và được tin tưởng giao nhiệm vụ đứng  đầu “phòng” công nghệ thông tin tại Viện Nghiên cứu Công nghệ Quốc  gia Nacentech. Đồng hành với anh là hai đồng nghiệp đầu tiên: anh  Hoàng Ngọc Hùng và anh Hoàng Đăng Hải – những người có thâm niên ở  Viện hơn một vài tháng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 25, tokens 104, triggered by: 0.24\n",
      "\u001b[31m.Cậu tân kỹ sư Điện tử - Viễn thông tài năng  của Đại học Bách Khoa Hà Nội - Nguyễn Trung  Chính là nhân viên đầu tiên được anh trưởng  phòng Hà Thế Minh tuyển về. Mối nhân duyên của  CMC có lẽ xuất phát từ đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 26, tokens 136, triggered by: 0.20\n",
      "\u001b[32mKhi vào năm 1987,  Anh Chính gặp anh Minh nhờ sự giới thiệu tình  cờ của người bạn là anh Trung. Anh Trung cũng học ở Hungary trên anh Minh mấy  khóa. Sau cuộc phỏng vấn đặc biệt với các màn  test năng lực thú vị và “hỏi xoáy đáp xoay”,  anh Chính đã về Viện làm việc cùng anh Minh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 27, tokens 51, triggered by: 0.16\n",
      "\u001b[34mSau này, các anh cùng 11 thành viên của phòng  trở thành một tập thể công nghệ thông tin rất  mạnh của Việt Nam thời bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 28, tokens 160, triggered by: 0.20\n",
      "\u001b[35m7  Khi được giới thiệu về một viện mới  thành lập - Viện Công nghệ Quốc gia  với những cơ chế đặc thù và định hướng  mới mẻ:đưa những kết quả nghiên cứu  vào ứng dụng. tuy gọi là Viện nhưng  ngoài 3 lãnh đạo chủ chốt, một vài nhân  viên văn phòng thì mới chỉ có hai nhóm  nghiên cứu đang được thành lập, mỗi  nhóm một vài ba người.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 29, tokens 217, triggered by: token limit\n",
      "\u001b[31mThấy hấp dẫn  – tuy rất thách thức – tôi quyết định đến  để xin việc. Anh Hà Thế Minh hồi tưởng   Trong hồi ký 15 năm CMC Hình ảnh Anh Nguyễn Trung Chính Hình ảnh Anh Hà Thế Minh.Ngày ấy, máy tính - “chiếc hộp nhỏ có thể gõ ra chữ” là một điều  lạ lẫm và mới mẻ ở Việt Nam. Để thực hiện mục tiêu Đổi mới, việc  tiếp cận công nghệ để đến gần hơn với những thành tựu khoa học trên  thế giới là một điều cấp bách.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 30, tokens 173, triggered by: token limit\n",
      "\u001b[32mTrong một buổi làm việc cùng Thủ  tướng Phạm Văn Đồng, Giáo sư Vũ Đình Cự nhận nhiệm vụ sản xuất máy  tính tại Việt Nam để cung cấp cho thị trường trong nước với giá rẻ  và trước hết phục vụ cho ngành giáo dục. Đề án nghiên cứu và sản  xuất máy tính được giao cho Phòng Tin học - Viện Công nghệ Vi điện  tử - đơn vị trực thuộc Viện Nghiên cứu Công nghệ Quốc gia.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 31, tokens 95, triggered by: 0.25\n",
      "\u001b[34mAnh em Viện Vi điện tử bắt tay nghiên cứu đề án chế tạo máy tính. Việc tiếp cận những tài liệu mới, bao gồm cả những tài liệu bí mật,  các tài liệu “xách tay” từ nước ngoài về rất vất vả.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 32, tokens 98, triggered by: 0.24\n",
      "\u001b[35mNhững người  kỹ sư trẻ thời đó phải dịch từ ngôn ngữ máy dịch ngược lại ngôn  ngữ lập trình (Assembly). Việc nhập dây chuyền sản xuất máy tính  cũng gặp khó khăn do ảnh hưởng của chính sách cấm vận.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 33, tokens 52, triggered by: 0.21\n",
      "\u001b[31mTập thể lãnh  đạo và cán bộ nhân viên Viện phải huy động tất cả mối quan hệ quen  biết để nhờ giúp đỡ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 34, tokens 97, triggered by: 0.10\n",
      "\u001b[32m8 Những “chiếc hộp nhỏ có thể gõ ra chữ” đầu tiên của Việt Nam Hình ảnh IBM PC 1981 Hình ảnh IBM PC 1981 .Vào năm 1986, Phòng Tin học nhận được hai chiếc máy tính đầu tiên  để tìm hiểu và nghiên cứu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 35, tokens 95, triggered by: 0.24\n",
      "\u001b[34mMột trong số đó là máy IBM XT với CPU  tốc độ 4.77 MHz và ổ đĩa cứng 20 MB và 1 ổ đĩa mềm 5 ¼”  màn hình  đơn sắc (monochrome) với giá không thể tưởng tượng được: 10.000 $  Mỹ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 36, tokens 157, triggered by: token limit\n",
      "\u001b[35mTheo so sánh dí dỏm của anh Hà Thế Minh, căn hộ tầng 4 khu tập  thể Trung Tự (trên đầu nhà anh) có giá là 1 cây vàng tương đương  gần 400 $ Mỹ hay căn nhà số 18 Lê Văn Hưu 90m2 tại Hà Nội lúc đó  giá 20 cây vàng (gần 8000$ Mỹ) mới thấy chiếc máy tính ngày đó có  giá trị to lớn như thế nào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 37, tokens 193, triggered by: token limit\n",
      "\u001b[31mAnh không có đủ thông tin để bình luận  là tại sao nó đắt thế, chỉ biết là “sếp” giao cho máy và nói “các  cậu phải cẩn thận”. Háo hức khi nhận chiếc máy tính mới, cả phòng chăm chú nghiên cứu,  đọc catalogue nhiều lần bằng tiếng Anh để thực hiện nhiệm vụ lắp  ráp các bộ phận, ổ cứng vào (vì phải tháo ra trong quá trình vận  chuyển). Giây phút lắp ổ cứng, tất cả nín thở hồi hộp chờ đợi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 38, tokens 138, triggered by: 0.26\n",
      "\u001b[32mSự  vui mừng hiện ra trên những khuôn mặt cả nhóm kỹ sư khi máy tính  boot được thành công với màu xanh đặc trưng của màn hình đơn sắc. Chiếc máy tính thứ 2 được giao về Viện là máy tính clone AT với  màn hình màu (CGA : độ phân giải thấp  640:480 và 16 màu) cùng ổ  cứng 40 MB.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 39, tokens 62, triggered by: 0.14\n",
      "\u001b[34mMàn hình màu đem lại sự phong phú và sự hấp dẫn trong  công việc và không thể không kể đến các màn chơi game đầu tiên đầy  ấn tượng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 40, tokens 277, triggered by: token limit\n",
      "\u001b[35mGiá của nó đỡ “khủng bố hơn”: “chỉ có” 4000$. Hình ảnh IBM PC   .Chúng tôi đã đầu tư rất nhiều thời gian cho việc thử nghiệm tất  cả những gì chúng tôi có được nhằm chuyển giao cho xã hội, cho  khách hàng; làm chủ các thiết bị, hệ điều hành; làm chủ mạng  Novell, các quy trình thiết kế, lắp đặt; làm chủ hệ thống chế bản  phục vụ văn phòng, các nhà in; nghiên cứu hệ điều hành Minix với  tham vọng xây dựng hệ Unix riêng của Việt nam; nghiên cứu hệ thống  xử lý song song sử dụng Transputer nhằm xây dựng năng lực tính toán  giá thành thấp cho Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 41, tokens 199, triggered by: 0.27\n",
      "\u001b[31mNhưng có lẽ có ý nghĩa nhất, có mục  tiêu rõ ràng nhất là việc thiết kế và xây dựng máy tính bác Tô. Ý  tưởng này xuất phát từ mong muốn cháy bỏng của Việt Nam: làm sao  thiết kế được một máy tính giá thành hạ, làm chủ được công nghệ để  phục vụ cho giáo dục, cho người tiêu dùng có thu nhập vừa phải. Với khát khao và mục tiêu cao cả ấy, nhóm kỹ sư trẻ tập trung vào  đề án nghiên cứu và sản xuất máy tính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 42, tokens 60, triggered by: 0.15\n",
      "\u001b[32mThời gian cao điểm của đề  án, khoảng 10 thành viên của phòng đều chưa có gia đình, luôn sục  sôi với nghiên cứu và thử nghiệm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 43, tokens 66, triggered by: 0.15\n",
      "\u001b[34mAnh trưởng phòng Hà Thế Minh khi  ấy mới 29 tuổi - là người lớn tuổi nhất, anh Nguyễn Trung Chính  mới chỉ 25 tuổi, còn lại toàn người trẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 44, tokens 189, triggered by: 0.23\n",
      "\u001b[35mThời đó, Viện nghiên cứu  nằm trong chế độ bảo mật của Nhà nước nên mọi tài sản trí tuệ đều  đặt ở Viện, nhân viên tuyệt đối không được mang tài liệu về nhà. Đất nước vừa bước qua thời bao cấp, các sản phẩm công nghệ, máy  tính rất hiếm, chỉ ở Viện mới có máy tính nên mọi người phải đến  Viện để làm, ánh đèn tại trụ sở đi thuê ở Bảo tàng Lịch sử Việt  Nam không bao giờ tắt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 45, tokens 120, triggered by: 0.04\n",
      "\u001b[31mNăm 1988, những nỗ lực của các chàng kỹ sư tài năng được đền đáp  xứng đáng khi sản phẩm đã hoàn thiện về thiết kế và làm xong sản  phẩm mẫu đầu tiên gọi là “prototype”, sản xuất ở mức thử nghiệm  100 chiếc, được đưa ra phục vụ cho cơ quan Tổng cục Bưu điện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 46, tokens 65, triggered by: 0.19\n",
      "\u001b[32m. . Giá một chiếc máy XT clone có giá thành khoảng 10 0 0$ Mỹ. Mục tiêu chúng tôi đặt ra là thiết bị phải dưới 40 0$ Mỹ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 47, tokens 203, triggered by: token limit\n",
      "\u001b[34mCố Chủ tịch Hà Thế Minh Theo Hồi ký 15 năm CMC 10  Máy tính Bác Tô -  công trình ý nghĩa.Những sản phẩm này được gọi là “Máy tính Bác Tô” (lấy theo tên bí  danh của Cố Thủ tướng Phạm Văn Đồng - Thủ tướng đầu tiên của nước  Cộng hòa Xã hội Chủ nghĩa Việt Nam). “Máy tính Bác Tô” sử dụng CPU  8bit của Hitachi, RAM Dynamic, có bảng mạch chính, ổ đĩa 1.44’’,  bàn phím, hệ phát triển EPROM.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 48, tokens 92, triggered by: 0.21\n",
      "\u001b[35m. . Tuy nhiên, công nghệ và chất lượng  sản xuất trong nước thời điểm đó còn chưa phát triển tương xứng  nên Viện quyết định nghiên cứu tiếp và thuê Đài Loan sản xuất bo  mạch chủ theo thiết kế của Viện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 49, tokens 72, triggered by: 0.21\n",
      "\u001b[31m.Toàn bộ tài sản của Viện Công nghệ Vi điện tử, đặc biệt là Phòng  Tin học - nơi đang tập trung các thiết bị để nghiên cứu và sản xuất  máy tính đã bị cháy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 50, tokens 57, triggered by: 0.26\n",
      "\u001b[32mNguyên nhân cháy được xác định do mô-tơ của  máy biến áp công suất lớn bị kẹt, om nhiệt và gây cháy tại chỗ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 51, tokens 63, triggered by: 0.22\n",
      "\u001b[34mLửa bén vào sơn, nhựa ở bản mạch các máy tính khiến đám cháy lan  rộng nhanh chóng, đến mức sàn gạch của mấy phòng ấy mủn ra.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 52, tokens 129, triggered by: 0.18\n",
      "\u001b[35mNhững  kỹ sư trẻ chỉ còn biết đứng nhìn những thành quả của mình đã bị thiêu rụi. Viện cháy có nghĩa là những hệ thống quan trọng như hệ thống thiết  kế mạch chuyên dụng colorcam của Tây Đức, toàn bộ thiết kế được tự  động hoá phần lớn đều bị cháy hết.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 53, tokens 114, triggered by: token limit\n",
      "\u001b[31mTrị giá cả máy và phần mềm vào  khoảng vài trăm ngàn USD. Có thể con số vài trăm ngàn USD bây giờ  không ý nghĩa lắm nhưng vào thập niên 80, khi chúng ta ăn không đủ  no và còn phải độn bo bo thì mới hiểu được mất mát đó lớn thế nào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 54, tokens 200, triggered by: token limit\n",
      "\u001b[32mĐêm Chủ nhật, khi những con phố chìm trong giấc ngủ say, trong ánh  đèn tại Bảo tàng Lịch sử Việt Nam, những người kỹ sư trẻ tuổi đã  hoàn thiện thiết kế bo mạch chủ, in ra bản film để hôm sau chuyển  sang Đài Loan sản xuất và tạm biệt nhau ra về với niềm hy vọng về  những chiếc máy tính đầu tiên do người Việt Nam sản xuất. Nhưng  những chàng trai ấy không thể biết rằng chỉ vài tiếng sau, họ gặp  nhau trong một hoàn cảnh không ngờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 55, tokens 200, triggered by: token limit\n",
      "\u001b[34m“Sáng sớm, những người kỹ sư Viện Vi điện tử nhận được tin báo đến  Viện ngay. Trước mắt họ là khung cảnh tan hoang, những cột khói còn  lững lờ trong không trung, không khí đặc quánh, xe cứu hỏa xếp hàng  dưới sân, lính cứu hỏa vừa mới dập cháy xong”   Theo hồi ức của Giáo sư Chu Hảo 12  Hoài bão  dang dở….Vụ cháy gây thiệt hại khoảng 500 ngàn USD – một khoản tiền khổng  lồ tại thời điểm đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 56, tokens 172, triggered by: 0.24\n",
      "\u001b[35mNhóm cán bộ tham gia đề án gần như “thất  nghiệp” trong vòng 02 năm. Ngọn lửa ấy tuy tước đi tương lai của  “Máy tính bác Tô” và tạm dừng về giấc mơ chiếc “Máy tính Made in  Vietnam” nhưng ngọn lửa ấy đồng thời cũng thổi bùng lên những ước  mơ cháy bỏng của hai người kỹ sư trẻ và là khởi nguồn của câu  chuyện CMC – “Cháy Mà Có”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 57, tokens 65, triggered by: 0.19\n",
      "\u001b[31m“Chúng tôi xót như dao cắt vào tim. Nếu không có vụ cháy đó thì  năm 1988, Việt Nam đã có máy tính đầu tiên, ngang ngửa với thế  giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 58, tokens 65, triggered by: 0.27\n",
      "\u001b[32mChắc chắn giới tri thức Việt Nam sẽ sử dụng “máy tính Bác  Tô” do Viện Nghiên cứu Công nghệ Quốc gia nghiên cứu và  sản xuất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 59, tokens 68, triggered by: token limit\n",
      "\u001b[34m.” Anh Nguyễn Trung Chính  nhớ lại “Cho đến bây giờ, tôi vẫn chỉ tiếc một sự nghiệp, một đề án rất tốt,  rất có tương lai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 60, tokens 193, triggered by: token limit\n",
      "\u001b[35mThứ hai, tôi tiếc đội ngũ kỹ thuật rất giỏi, giàu đam  mê, nhiệt huyết, tiếc một cơ hội cho không những anh em kỹ thuật của  Viện mà cơ hội để phát triển của khoa học công nghệ Việt Nam.”  Giáo sư Chu Hảo  chia sẻ  .ADCOM Những thành tựu lớn lao đều khởi nguồn từ điều phi thường nhỏ bé:  một giọt nước làm nên đại dương, một hạt giống làm nên cả khu rừng  rộng lớn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 61, tokens 148, triggered by: token limit\n",
      "\u001b[31mSự thành công được quyết định bởi rất nhiều yếu tố nhưng  có lẽ “những bước chân đầu tiên” – bước chân mạnh mẽ, dám khát  khao, dám hành động… đóng vai trò quan trọng nhất. Và ADCOM là bước chân đầu tiên của hành trình 30 năm – 50 năm – 100  năm của Tập đoàn Công nghệ CMC bền vững và trường tồn!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 62, tokens 95, triggered by: token limit\n",
      "\u001b[32mHành trình vạn dặm BẮT ÐẦU TỪ  MỘT BƯỚC CHÂN.“Ngôi sao Tivi” và “Doanh nhân Hungary” của Viện Công nghệ Vi điện tử Sau vụ cháy, công tác điều tra diễn ra nhiều tháng trời.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 63, tokens 133, triggered by: token limit\n",
      "\u001b[34mDo xác  định không có yếu tố cố tình phá hoại, Viện Công nghệ Vi điện tử  (Viện Nghiên cứu Công nghệ Quốc Gia) được yêu cầu cần tổ chức các  hoạt động sản xuất kinh doanh tạo ra lợi nhuận để khắc phục những  tổn thất của vụ cháy, nếu không sẽ bị truy cứu trách nhiệm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 64, tokens 138, triggered by: token limit\n",
      "\u001b[35mMột hoạt động sản xuất được Viện triển khai là lắp ráp tivi, đây cũng là một mô hình đi đầu cho việc thí điểm nghiên cứu khoa học công nghệ kết hợp sản xuất và phát triển kinh doanh tại  Việt Nam thời ấy. 3.000 chiếc tivi nhanh chóng được lắp ráp dưới áp lực đền bù tổn  thất của vụ cháy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 65, tokens 199, triggered by: 0.14\n",
      "\u001b[31mViệc lắp ráp đối với những người kỹ sư công nghệ  chẳng khó khăn gì nhưng kinh doanh lại là một câu chuyện xa lạ với  những chàng trai vốn đã quen với việc nghiên cứu. Hàng tháng trời,  3.000 chiếc tivi vẫn tồn kho. Tuy nhiên ngay sau đó, Viện Công nghệ  Vi điện tử xuất hiện một “Ngôi sao tivi”, “giải quyết ngon lành”  bài toán khó với kỷ lục: bán 2.000 chiếc tivi chỉ trong một vài  tháng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 66, tokens 161, triggered by: token limit\n",
      "\u001b[32mChàng trai ấy tên là Nguyễn Trung Chính (Chủ tịch HĐQT hiện  thời Tập đoàn Công nghệ CMC). Viện trưởng Chu Hảo ra chính sách,  mỗi người bán được một chiếc tivi sẽ được thưởng 1% tương ứng,  “Ngôi sao tivi” Nguyễn Trung Chính nghiễm nhiên nhận phần thưởng  có giá trị 20 chiếc tivi – một tài sản lớn thời bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 67, tokens 106, triggered by: token limit\n",
      "\u001b[34mBên cạnh đó, trong Viện Công nghệ Vi điện tử xuất hiện câu chuyện  về một ông chủ với tư duy nhạy bén, từng có kinh nghiệm kinh doanh  từ Hungary qua Liên Xô, đó là anh Hà Thế Minh (Cố Chủ tịch Tập đoàn  Công nghệ CMC).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 68, tokens 162, triggered by: 0.18\n",
      "\u001b[35mBên cạnh niềm đam mê với khoa học công nghệ, “Ngôi  sao Tivi” và “Doanh nhân Hungary” tìm thấy sự đồng điệu về sở thích  kinh doanh và khát khao đem những kiến thức của mình ứng dụng vào  đời sống. Hai anh cũng nhận thấy đây là thời điểm cần phải có sự thay đổi,  cần làm cái gì đó năng động hơn, nhạy bén hơn với thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 69, tokens 164, triggered by: token limit\n",
      "\u001b[31mSợi  dây đồng điệu và khát khao ấy đã kéo hai con người cùng chung một  hoãi bão và ước mơ – ước mơ đặt những viên gạch đầu tiên cho chương  sử mang tên CMC. .Khoảng năm 1988 – 1989, những con phố thủ đô in dấu bóng hình hai  chàng trai trẻ với hoài bão khởi nghiệp bằng việc nhận máy tính  hỏng về sửa và kinh doanh đồ điện tử.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 70, tokens 173, triggered by: 0.27\n",
      "\u001b[32mHai người kỹ sư trẻ bắt đầu  suy nghĩ đến việc làm nhà nước hay theo đuổi đam mê của mình: kinh  doanh và buôn bán dựa trên thế mạnh cốt lõi - công nghệ thông tin. Với sự mộc mạc, thẳng thắn của những người kỹ sư công nghệ cùng  kinh nghiệm buôn bán, sự nhạy bén vốn có, hai anh đã bắt tay ngay  vào thực hiện và gặt hái nhiều thành công.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 71, tokens 150, triggered by: token limit\n",
      "\u001b[34mNăm 1989, khi cung cấp máy tính cho Phòng Thực tập máy tính -  Trường Đại học Thăng Long, anh Minh và anh Chính nhận nhiệm vụ đào  tạo thực hành máy tính cho các sinh viên của trường trong căn nhà  nhỏ 3 gian 1 chái tại số 34 Hàn Thuyên. Đồng thời, hai anh sử dụng  địa điểm này là phòng tiếp khách, giao dịch mua bán máy tính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 72, tokens 195, triggered by: token limit\n",
      "\u001b[35mCăn  nhà nhỏ trên phố Hàn Thuyên ấy là nơi khởi đầu của những điều lớn  lao được hai anh xây dựng sau này. Từ số vốn được tích cóp được qua những hoạt động kinh doanh trước  đó và qua những nỗ lực buôn bán thiết bị công nghệ của hai người  kỹ sư trẻ, căn nhà Tây Hồ đứng tên Hà Thế Minh và Nguyễn Trung  Chính thành hình. Trung thu năm 1991, một nhóm người trẻ ngồi lại  cùng nhau trong căn nhà mới hoàn thiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 73, tokens 152, triggered by: token limit\n",
      "\u001b[31mTheo lời anh Chính kể, căn  nhà có một điểm rất thú vị: móng nhà của anh Chính còn đặt trên  đất của anh Minh - chi tiết đặc biệt này cũng giống như sợi dây  kết nối khăng khít giữa hai nhà sáng lập CMC cùng tình cảm chân  thật và vô tư nhất cũng như tinh thần đoàn kết, gắn bó của anh em  CMC sau này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 74, tokens 181, triggered by: token limit\n",
      "\u001b[32mNgày “khai trương” căn nhà mới đó, bên cạnh nồi ốc  luộc đơn sơ, những chàng trai trẻ đã bàn luận, ấp ủ hoài bão về  một điều lớn lao hơn… Căn nhà nhỏ ấp ủ   những ước mơ lớn lao.Sau khi tích luỹ được số vốn nhờ kinh doanh trong thời gian đó và  việc cho thuê nhà Tây Hồ, hai chàng trai trẻ xin thành lập Trung  tâm trực thuộc Viện Công Viện Vi điện tử.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 75, tokens 80, triggered by: 0.19\n",
      "\u001b[34mTrung tâm hoạt động tự  chủ với nguồn vốn ban đầu 50 triệu, mọi cơ sở vật chất, địa điểm  đều đi thuê. Mỗi năm trích 1% lợi nhuận nộp lại Viện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 76, tokens 131, triggered by: token limit\n",
      "\u001b[35mADCOM – Giấc mơ thành hình Hình ảnh: Quyết định thành lập Trung tâm ADCOM   .8  Thời ấy, con dấu pháp lý có hai loại: dấu tròn và dấu vuông. Trung  tâm ADCOM sử dụng dấu vuông là đơn vị được Viện thành lập nhưng  chưa có tư cách pháp nhân và cần ký kết các hợp đồng qua Viện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 77, tokens 92, triggered by: 0.21\n",
      "\u001b[31mVới  đặc thù kinh doanh nhập khẩu máy tính và chính sách chỉ cho phép  các tổ chức Nhà nước có chức năng xuất nhập khẩu nên ADCOM thường  “mượn” pháp nhân của Viện để thực hiện các hoạt động nhập khẩu máy  tính kinh doanh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 78, tokens 100, triggered by: token limit\n",
      "\u001b[32mTrung tâm ADCOM nhỏ nhắn với số lượng nhân sự chưa đến chục người  bao gồm: anh Hà Thế Minh và anh Nguyễn Trung Chính là lãnh đạo của  trung tâm, chị Nga kế toán, chị Hoàng Lai phân phối bán hàng và  nhóm kỹ thuật.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 79, tokens 140, triggered by: token limit\n",
      "\u001b[34mCác phòng được ngăn cách bằng những bức tường với  ô thoáng tròn, mọi người có thể dễ dàng trao đổi với nhau  qua những ô tròn bé tí đó từ bàn làm việc của mình. .ADCOM kinh doanh nhưng cũng triển khai nhiều công nghệ từ rất sớm  vì là nơi hội tụ của các kỹ sư tin học lành nghề.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 80, tokens 76, triggered by: token limit\n",
      "\u001b[35mNhững người kỹ  sư tài năng của ADCOM đã nghiên cứu và sản xuất nhiều công trình  nổi tiếng, một trong số đó phải kể đến công trình cho ngành mật mã  của Ban Cơ yếu Trung ương.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 81, tokens 128, triggered by: token limit\n",
      "\u001b[31mHiện nay toàn bộ máy mật mã trên toàn  thế giới đều sử dụng card mật mã được ADCOM phát triển - bộ phần  cứng cắm vào một máy PC để mô phỏng máy telex đồng thời mã hóa toàn  bộ phát và nhận tin cho lực lượng hoạt động mật tình báo. Đây là  sản phẩm đầy tự hào của người ADCOM.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 82, tokens 139, triggered by: 0.26\n",
      "\u001b[32mNhắc về thời kỳ ADCOM, Anh Chính còn nhớ như in những ngày sản xuất  tổng đài số bán cho các tỉnh và địa phương, có thời điểm lên tới  256 số cho cấp huyện. Phần điều khiển trung tâm số 100%, xử lý tín  hiệu số bằng hai bo mạch máy tính song song với phần mềm điều khiển  thông qua máy tính PC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 83, tokens 109, triggered by: 0.17\n",
      "\u001b[34mSau đó chuyển đổi tín hiệu số sang Analog  để điều khiển bảng trường và điều khiển mạng chuyển mạch kết nối. Phần cứng của tổng đài số được Anh Nguyễn Trung Chính thiết kế,  anh Hà Thế Minh và anh Hoàng Ngọc Hùng phụ trách thiết kế phần mềm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 84, tokens 264, triggered by: token limit\n",
      "\u001b[35mNếu những hình ảnh về tàu điện chạy trên phố, chiếc xe Honda màu  đỏ, thùng ti-vi JVC, tủ lạnh National là những hình ảnh nhắc nhớ  về một thời Hà Nội đã qua thì trong tâm trí của những người ADCOM  hồi đó, hình ảnh về một tập thể đoàn kết, gắn bó, hình ảnh anh em  hăng say trong công việc, những cuộc trao đổi thân tình hay hình  ảnh về hai người anh cả kiêm đủ thứ: vừa quản lý, hướng dẫn mọi  người sản xuất kinh doanh, vừa lái xe, vừa đi xuất nhập khẩu, thậm  chí còn bốc vác hàng… là những hình ảnh không thể nào quên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 85, tokens 126, triggered by: 0.11\n",
      "\u001b[31mTự hào ADCOM   .Hình ảnh số 0 tròn trĩnh được nhiều chuyên gia kinh tế sử dụng để  miêu tả về khu vực kinh tế tư nhân của Việt Nam cách đây hơn 30  năm. Sau Giải phóng miền Nam thống nhất đất nước, khu vực này vẫn  không được thừa nhận và tồn tại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 86, tokens 171, triggered by: 0.32\n",
      "\u001b[32mDoanh nghiệp nhà nước và tập thể  vẫn là hai loại hình sở hữu chính trong nền kinh tế. Sự tồn tại  của sở hữu tư nhân và cá thể bị kìm hãm phát triển do quan điểm sở  hữu tư nhân là nguồn gốc của chủ nghĩa tư bản. Chỉ đến khi bước  vào thời kỳ Đổi mới và có chủ trương phát triển kinh tế nhiều thành  phần, kinh tế tư nhân mới được nhắc đến.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 87, tokens 191, triggered by: token limit\n",
      "\u001b[34mMặc dù chính sách phát triển kinh tế nhiều thành phần đã được công  bố và thực hiện từ năm 1986, nhưng với những biến cố trong lịch sử  chính sách phát triển kinh tế cùng tình trạng chưa rõ ràng về chủ  trương và các chính sách cụ thể gây ra tâm lý dè dặt trong đầu tư  sản xuất kinh doanh, đầu tư lớn và dài hạn. Các hoạt động kinh tế,  kinh doanh vẫn được thực hiện phần đa bởi các doanh nghiệp nhà  nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 88, tokens 167, triggered by: token limit\n",
      "\u001b[35m“Con số 0 tròn trĩnh” chỉ dần biến mất khi Hiến pháp Việt Nam công  nhận thành phần kinh tế tư nhân vào năm 1990 và Luật Doanh nghiệp  tư nhân được ban hành vào năm 1990 tạo ra hành lang thể chế cho  khu vực tư nhân, đây là bước ngoặt lớn trong phát triển kinh tế tư  nhân ở Việt Nam. Số doanh nghiệp tư nhân đăng ký thành lập tăng  dần, tạo ra một làn sóng mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 89, tokens 178, triggered by: token limit\n",
      "\u001b[31mNăm 1993, quan hệ Việt Nam – Mỹ đạt  bước tiến mới trên quá trình hòa giải, tiến tới dỡ bỏ lệnh cấm vận,  mở ra cánh cửa giao lưu, phát triển kinh tế, thương mại. Đây cũng  là năm có số doanh nghiệp thành lập mới cao nhất giai đoạn 1991 –  1996: trên 7.800 doanh nghiệp. 0  tròn trĩnh Số  Thành công bắt đầu từ suy nghĩ “dám ước mơ”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 90, tokens 156, triggered by: 0.29\n",
      "\u001b[32mNazim Hikmet từng nói: ”Nếu  tôi không cháy lên, nếu chúng ta không cháy lên thì làm sao bóng tối có  thể trở thành ánh sáng”. Nếu ta không dấn thân đương đầu với trước muôn  vàn khó khăn và trăn trở, nếu ta không hành động, không bứt phá thực hiện  ước mơ; ta sẽ không thể biết trái ngọt thành quả tuyệt vời đến thế nào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 91, tokens 86, triggered by: 0.23\n",
      "\u001b[34mCách đây 30 năm, có hai người trẻ đã sẵn sàng từ bỏ “nghề danh giá” để  viết nên những điều lớn lao: phát triển những sản phẩm của chính mình,  những sản phẩm công nghệ thông tin Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 92, tokens 93, triggered by: 0.25\n",
      "\u001b[35m.Trong làn sóng mạnh mẽ ấy xuất hiện một công ty với tên gọi Công  ty Trách nhiệm Hữu hạn (TNHH) HT&NT – viết tắt tên gọi của 2 chàng  kỹ sư trẻ Hà Thế Minh & Nguyễn Trung Chính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 93, tokens 130, triggered by: 0.28\n",
      "\u001b[31mHai sáng lập viên đầu tiên đều là những cán bộ nghiên cứu thuộc  Viện Nghiên cứu Công nghệ Quốc gia. Ham muốn, hoài bão  của chúng tôi là nghiên cứu ứng dụng các công nghệ mới, sản phẩm  mới, tiến tới phát triển những sản phẩm của chính mình, những sản  phẩm công nghệ thông tin Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 94, tokens 91, triggered by: 0.09\n",
      "\u001b[32mTuy nhiên những mong ước  như vậy không dễ dàng được thực hiện trong cơ chế của các viện  nghiên cứu thời bấy giờ. Công ty HT&NT được thành lập nhằm  biến những giấc mơ của chúng tôi thành hiện thực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 95, tokens 200, triggered by: token limit\n",
      "\u001b[34m(Trích Hồi ký của Anh Hà Thế Minh) Quyết định này được coi là táo bạo. Luật Doanh nghiệp quy định:  công chức nhà nước chỉ có quyền góp vốn, không có quyền thành  lập và quản lý doanh nghiệp. Những người kỹ sư Trung tâm ADCOM –  Viện Khoa học Công nghệ đứng trước tình thế buộc phải lựa chọn:  ở lại viện nghiên cứu hay mạo hiểm đặt “chiếc áo” cán bộ nhà  nước lại, tham gia thử thách thành lập doanh nghiệp tư nhân.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 96, tokens 154, triggered by: 0.29\n",
      "\u001b[35mVới sự tự tin và khả năng nhạy bén, anh Nguyễn Trung Chính quyết  định rời khỏi Viện Khoa học Công nghệ, đứng tên thành lập công  ty HT&NT. Anh Hà Thế Minh tham gia với vai trò thành viên góp  vốn và xây dựng công ty. Đến năm 1997, anh Minh mới chính thức  rời Viện. “Thành lập doanh nghiệp là quyết định dũng cảm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 97, tokens 98, triggered by: 0.23\n",
      "\u001b[31mBởi không ai từ  nơi rất thanh cao, theo nghĩa của thời bao cấp là làm ở cơ quan  nhà nước, lại nhảy sang làm tư nhân, bị coi là con buôn” – Anh  Nguyễn Trung Chính nhớ lại khoảng thời gian đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 98, tokens 196, triggered by: token limit\n",
      "\u001b[32mQuyết định  “ngược dòng” .Hình ảnh: Anh Nguyễn Trung Chính và  nhân viên của Công ty TNHH HT&NT Hình ảnh: Anh Hà Thế Minh, Anh Tạ Hoàng  Linh và nhân viên của Công ty TNHH HT&NT HT&NT  ra đời  Với định hướng phân phối máy tính và theo quy định của Luật Doanh  nghiệp, đơn vị xuất nhập khẩu trực tiếp cần có số vốn tối thiểu 2  – 3 tỷ; căn nhà Tây Hồ được thế chấp và trở thành vốn ban đầu của  Công ty TNHH HT&NT.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 99, tokens 174, triggered by: token limit\n",
      "\u001b[34mHai thành viên sáng lập trẻ tuổi quyết tâm đặt  trọn niềm tin và hy vọng tuổi trẻ vào HT&NT. Ngày 26/05/1993, Công ty TNHH HT&NT được thành lập, câu chuyện của  CMC được bắt đầu từ ước mơ của những người kỹ sư quyết đoán ngày  ấy. Số nhà 30A Lý Nam Đế được lựa chọn để HT&NT bước những bước đi đầu  tiên, dù còn khiêm tốn nhưng rất quả quyết và tự tin.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 100, tokens 159, triggered by: 0.07\n",
      "\u001b[35mTrong bối  cảnh thị trường bắt đầu mở cửa, công ty mới thành lập, HT&NT gặp  rất nhiều khó khăn: vừa đảm bảo đời sống của cán bộ, vừa đầu tư  nghiên cứu những sản phẩm và dịch vụ mới. Những người thuyền  trưởng ngày ấy quyết định hướng đi của HT&NT: sản xuất, lắp ráp,  kinh doanh, xuất nhập khẩu sản phẩm điện tử và tin học.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 101, tokens 112, triggered by: 0.13\n",
      "\u001b[31m.Hình ảnh: Anh Nguyễn Trung Chính đứng  trước cửa Công ty TNHH HT&NT Hình ảnh: Số nhà 30 Lý Nam Đế.Từ những nhà nghiên cứu, những kỹ sư tin học của HT&NT trở thành  những người lắp ráp, sửa chữa và cung cấp máy tính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 102, tokens 123, triggered by: 0.16\n",
      "\u001b[32mThời kỳ ấy,  người dùng thiếu kỹ năng tin học và rất cần tư vấn sử dụng máy  tính. Với đội ngũ nhân sự vừa có chuyên môn lại vừa nhiệt tình,  tận tâm, HT&NT đã nhanh chóng trở thành công ty uy tín trong việc  phân phối, sửa chữa máy tính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 103, tokens 151, triggered by: 0.27\n",
      "\u001b[34mMáy tính ngày ấy có hai loại: máy tính Đông Nam Á – nhập các linh  kiện rời từ các nước trong Đông Nam Á về lắp ráp và có giá thành  khá dễ chịu khoảng 1000$ đến 1500$ và máy tính Compaq có độ ổn định  hơn, cung cấp cho các đơn vị thiết kế chế bản điện tử hoặc văn  phòng nước ngoài, có giá khoảng 2000$ – 3000$.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 104, tokens 177, triggered by: token limit\n",
      "\u001b[35mHoạt động lắp ráp  được thực hiện ở kho 16A Lý Nam Đế. Sau khi lắp ráp xong, các thành viên trong công ty sẽ đi giao máy  tính. Thời đó máy tính là tài sản rất lớn nên khách hàng thường đi  kèm từ lúc mua đến lúc giao nhận. Máy tính sẽ được giao bằng những  chiếc xe lam đi thuê khi số lượng nhiều hoặc được buộc chặt trên  những chiếc xe máy, len lỏi khắp đường phố Hà Nội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 105, tokens 175, triggered by: token limit\n",
      "\u001b[31mMỗi khi đi giao  lắp máy cho khách hàng, anh em trong công ty luôn chuẩn bị chu đáo,  cẩn thận và luôn được người dân rất yêu quý. “Ổ cắm ngày xưa ở các  nhà đa số theo chuẩn Liên Xô là ổ cắm 2 chân, nhưng máy tính theo  chuẩn của Tây Âu và Mỹ thì lại là ổ cắm 3 chân. Khi cắt đi vẫn rất  rộng mà nếu cố gắng ấn vào thì vỡ ổ điện của người ta.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 106, tokens 165, triggered by: 0.16\n",
      "\u001b[32mCác anh luôn  luôn phải đặt vấn đề với người mua hàng và chuẩn bị sẵn một đầu  chuyển đổi mua ở Trần Phú, cắt đi và nối lại” – anh Tạ Hoàng Linh  chia sẻ. Có lẽ, dù chưa thành hình nhưng giá trị cốt lõi “Hướng khách hàng”  quen thuộc với bất kỳ người CMC nào đã được những thành viên tiên  phong nhen nhóm và ấp ủ từ những ngày ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 107, tokens 140, triggered by: 0.14\n",
      "\u001b[34mLắp ráp máy tính – lắp ráp một ước mơ .Sau 2 năm, đến năm 1995, công ty TNHH HT&NT chính thức được đổi  tên thành Công ty TNHH Máy tính Truyền thông CMC và có một bước  nhảy quan trọng khi lần đầu tiên thiết lập được mối quan hệ kinh  doanh với một hãng sản phẩm nước ngoài – hãng máy tính Acer của  Đài Loan.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 108, tokens 69, triggered by: 0.31\n",
      "\u001b[35mVào thời điểm đó, Việt Nam vẫn còn chịu ảnh hưởng cấm  vận của Hoa Kỳ nên sản phẩm tin học của Hoa Kỳ rất hiếm và rất đắt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 109, tokens 76, triggered by: 0.32\n",
      "\u001b[31mVì thế, các máy tính Acer với giá rẻ hơn và không nằm trong danh  mục “cấm vận” nên được người dùng hâm mộ nhiệt liệt, qua đó tạo  lực đẩy cho CMC phát triển.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 110, tokens 119, triggered by: 0.25\n",
      "\u001b[32mCMC: Cháy Mà Có hay Chính Minh và Cộng sự.Cái tên CMC khi được hình thành mang ý nghĩa: Chính –  Minh – Cường bởi khi xây dựng đề án thành lập, anh Cường  – một người bạn thân của anh Minh tại Liên Xô có tham gia   đặt những viên gạch đầu tiên cho CMC ngày nay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 111, tokens 62, triggered by: 0.32\n",
      "\u001b[34mTuy nhiên  sau đó anh Cường không tiếp tục đồng hành cùng dự án nữa. Bên cạnh đó, cái tên CMC cũng có ý nghĩa:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 112, tokens 56, triggered by: 0.25\n",
      "\u001b[35mChính – Minh  và Các cộng sự; hoặc nhắc nhớ về bước ngoặt của các thành viên  sáng lập: Cmc “Cháy – Mà – Có.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 113, tokens 120, triggered by: token limit\n",
      "\u001b[31mChủ tịch Nguyễn Trung Chính  hồi tưởng lại   Đám cháy ngày ấy tuy tước đi tương lai của “Máy tính Bác Tô” nhưng  ngọn lửa ấy đồng thời cũng thổi bùng lên những ước mơ cháy bỏng  của hai người kỹ sư trẻ ươm mầm xanh CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 114, tokens 107, triggered by: token limit\n",
      "\u001b[32mMỗi cách hiểu đều có ý nghĩa riêng và dù hiểu theo cách nào, CMC  đã, đang và sẽ luôn là cái tên thân thương, đầy tự hào của hàng  nghìn thế hệ Người CMC! .Với trăn trở: “Làm thế nào để hài lòng khách hàng?\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 115, tokens 188, triggered by: token limit\n",
      "\u001b[34mLàm thế nào để dẫn đầu  trong lĩnh vực mình tham gia?”, CMC xác định cho mình chiến lược ngay từ  những ngày đầu. Đó là đầu tư nghiêm túc, bài bản và phải thu hút được những  người tài giỏi nhất để tạo ra những sản phẩm dịch vụ chất lượng cao, có  giá trị nổi bật. CMC luôn coi con người là tài sản lớn nhất của doanh nghiệp,  năng  lực cốt lõi để phát triển chính là nguồn nhân lực chất lượng cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 116, tokens 147, triggered by: token limit\n",
      "\u001b[35mNgay từ những ngày đầu, Ban lãnh đạo CMC đã tập hợp quanh mình  những chuyên viên giỏi, những kỹ sư tin học lành nghề, sáng tạo,  ham hiểu biết để triển khai nhanh chóng các hoạt động khoa học,  kinh doanh; lấy nghiên cứu khoa học phục vụ cho kinh doanh, lấy  kinh doanh để thúc đẩy nghiên cứu khoa học.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 117, tokens 95, triggered by: token limit\n",
      "\u001b[31mNhững nhân sự chủ chốt làm việc trong bộ phận kinh doanh hay kỹ  thuật đều là những nhân sự tài năng, đúng chuyên ngành, tốt nghiệp  đại học nước ngoài hoặc những đại học có tiếng trong nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 118, tokens 166, triggered by: token limit\n",
      "\u001b[32mAnh  Nguyễn Phước Hải, anh Nguyễn Hồng Sơn, anh Nguyễn Kim Cương đều  học ở Liên Xô cũ về, chị Hoàng Thị Lai học ở Đức, anh Tạ Hoàng  Linh, anh Hoàng Ngọc Hùng hay một số anh em cán bộ chủ chốt đều  học bài bản tại Hungary. Với đội ngũ nhân sự trẻ, tài năng và lăn  xả hết mình, CMC đã gặt hái được nhiều thành công.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 119, tokens 179, triggered by: 0.29\n",
      "\u001b[34mNhân tài hội tụ .Sau hơn 2 năm hoạt động và có tiếng trên thị trường, đến cuối năm  1995, hai nhà lãnh đạo CMC nhận thấy cần phải hoàn thiện tổ chức,  hệ thống hóa các bộ phận trong công ty để làm việc chuyên nghiệp  và hiệu quả hơn. Nếu như trước kia, các bộ phận chưa được phân tách  và gọi tên rõ ràng thì đến thời kỳ này, công ty phân chia các bộ  phận với các chức năng riêng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 120, tokens 126, triggered by: token limit\n",
      "\u001b[35mPhòng Kinh doanh chịu trách nhiệm  phân phối, bán hàng, chinh phục các dự án lớn. Phòng Kỹ thuật lắp  ráp, giao hàng, bảo hành, đảm bảo dịch vụ cho khách hàng khi sử  dụng. Phòng Nhân sự phụ trách tuyển người, tính lương, đảm bảo công  tác hồ sơ, lưu trữ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 121, tokens 178, triggered by: token limit\n",
      "\u001b[31mPhòng Hệ thống và Phát triển phần mềm chịu  trách nhiệm nghiên cứu và phát triển các ứng dụng, phần mềm công  nghệ thông tin. Đến năm 1998, Phòng Hệ thống và Phát triển phần  mềm tách thành hai bộ phận riêng: Phòng Hệ thống tập trung các mảng  dự án lớn và phức tạp về mặt công nghệ của CMC, Phòng Phần mềm định  hướng vào xây dựng các giải pháp phần mềm phục vụ cho quản lý.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 122, tokens 177, triggered by: 0.18\n",
      "\u001b[32mPhòng Tích hợp hệ thống tập hợp được nhiều nhân sự giỏi như anh Đỗ  Minh Nam, anh Nguyễn Danh Lam, anh Hứa Tuấn Anh, đứng đầu phòng là  anh Tạ Hoàng Linh. Phòng Phần mềm có anh Nguyễn Kim Cương đứng đầu phòng; bên cạnh là  anh Vũ Thành Nam, anh Nguyễn Việt Thắng, anh Nguyễn Linh Giang…  đều học nước ngoài về toán ứng dụng và viết chương trình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 123, tokens 82, triggered by: 0.17\n",
      "\u001b[34mLần đầu tiên, các bộ phận được gắn biển tên phòng, mọi người trong  công ty cũng thấy mình “chuyên nghiệp” hẳn lên, tự tin khi có các  đối tác trong và ngoài nước đến trao đổi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 124, tokens 53, triggered by: token limit\n",
      "\u001b[35mCũng từ đó, CMC đã tạo  nên nhiều điểm nhấn và khẳng định được vị thế của mình tại thị  trường Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 125, tokens 163, triggered by: token limit\n",
      "\u001b[31mHoàn thiện  cơ cấu tổ chức   .Bản hòa ca sắc màu  Những chuyến xe vượt lũ đưa tri thức đến muôn nơi Sau một thời gian hoạt động, nhận thấy tầm quan trọng của con người  trong tổ chức, bên cạnh vai trò là Giám đốc dự án, anh Nguyễn Hồng  Sơn nhận thêm nhiệm vụ phụ trách tuyển dụng nhân sự và xây dựng  đội ngũ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 126, tokens 150, triggered by: token limit\n",
      "\u001b[32mAnh Sơn đề xuất mở rộng chuyên ngành đối với các ứng viên  của CMC, không còn giới hạn yêu cầu bắt buộc có chuyên môn về công  nghệ thông tin. Lần đầu tiên, CMC xây dựng được quy trình tuyển  dụng nhân sự, đánh giá ứng viên qua bài test IQ bằng tiếng Anh, kỹ  năng làm báo giá và đào tạo nhân sự bài bản.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 127, tokens 151, triggered by: 0.26\n",
      "\u001b[34mCác bộ phận “nở ra”  nhanh chóng, hàng loạt account manager, cán bộ kỹ thuật, trợ lý,  thư ký dự án được lựa chọn từ những trường đại học top đầu trên cả  nước. Trong mái nhà chung CMC, tài năng được khuyến khích và nuôi  dưỡng, thông tin và tri thức được chia sẻ ở mức tối đa, giúp tăng  năng suất và hiệu quả công việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 128, tokens 137, triggered by: token limit\n",
      "\u001b[35mChế độ đãi ngộ và công việc được  trao đúng cho người thực tài. Với phương châm: phát triển nguồn  nhân lực có trình độ cao là yếu tố sống còn của công ty; những con  người xuất sắc từ khắp nơi, mọi lĩnh vực cùng góp sắc màu tạo nên  bản hòa ca đưa CMC đến những thành công rực rỡ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 129, tokens 141, triggered by: 0.12\n",
      "\u001b[31mVới đội ngũ nhân sự chất lượng, CMC tạo được thành công vang dội  trên cả 3 lĩnh vực chính: tích hợp hệ thống - phát triển phần mềm  và phân phối, lắp ráp, sản xuất máy tính. Tháng 11 năm 1999 xảy ra đợt lũ lụt miền Trung Việt Nam được biết  đến với tên gọi Đại Hồng thủy 1999.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 130, tokens 73, triggered by: 0.27\n",
      "\u001b[32mTỉnh chịu thiệt hại nặng nhất  là Thừa Thiên Huế. Trận lũ lụt đã đi vào ký ức không thể nào quên  với người dân miền Trung cũng như cả nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 131, tokens 91, triggered by: 0.22\n",
      "\u001b[34mLượng mưa trong một ngày  tại Huế được ghi nhận lớn chưa từng thấy trong chuỗi số liệu 100  năm tại Việt Nam. Lũ lụt làm ngập trắng 10 tỉnh, thành phố tại miền  Trung, 20 huyện thị bị nhấn chìm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 132, tokens 203, triggered by: token limit\n",
      "\u001b[35mHình ảnh cụ già ngồi trên mái  nhà giữa biển nước mênh mông, giơ tay xin cứu trợ một gói mì tôm  sau bao ngày mưa lũ đói rét vẫn còn ám ảnh trong tâm trí mỗi người  thời kỳ ấy. .Đúng lúc đó, Phòng Kỹ thuật CMC có 15 chàng trai đang ở Thanh Hóa  phục vụ dự án của Kho bạc Nhà nước: cung cấp dịch vụ ứng dụng kế  toán kho bạc, đảm bảo kết nối thông tin cho các hệ thống các tỉnh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 133, tokens 162, triggered by: 0.27\n",
      "\u001b[31mTừ Hà Nội, 15 chàng trai mang theo những chiếc máy tính đại diện  cho tiến bộ khoa học tới Thanh Hóa, bàn giao cho tỉnh và tiếp tục  chia về các huyện, hỗ trợ lắp ráp, cài đặt. Khổ nỗi, đường từ Thanh  Hóa đến các huyện Quan Sơn, Bá Thước toàn đường núi, xe ô tô không  thể đi vào. Các anh phải chở từng chiếc máy tính trên con xe Minsk.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 134, tokens 68, triggered by: 0.26\n",
      "\u001b[32mTrận lũ lụt khiến con đường gian nan thêm khó khăn, trời mưa khiến  đất nhão, vừa đi vừa chạy đua với thời gian và dòng nước lũ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 135, tokens 158, triggered by: token limit\n",
      "\u001b[34mHàng  hóa buộc chặt 2 bên xe, chiếc ba-lô trên vai căng phồng với đủ thứ  “hầm lằng nhằng”: ổ đĩa cứng có sẵn dữ liệu để thao tác, băng dính  chuyên dụng, keo con voi, dây thun cao su, đèo thêm một chiếc khoan  tròng ra bên ngoài… sẵn sàng xử lý bất cứ tình huống nào xảy ra  với sản phẩm và khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 136, tokens 186, triggered by: 0.13\n",
      "\u001b[35mGiữa tình thế khó khăn và địa hình xa xôi, cách trở bởi những cơn  mưa cùng dòng nước lũ nhưng 15 chàng kỹ sư trẻ vẫn phơi phới niềm  tin, tràn đầy hạnh phúc, hoàn thành nhiệm vụ đưa tri thức đến muôn  nơi. Hình ảnh ấy đại diện rõ nét cho những con người CMC nhiệt  huyết, say mê công việc, không ngại khó khăn vất vả để mang lại  giá trị cho khách hàng và cộng đồng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 137, tokens 61, triggered by: 0.25\n",
      "\u001b[31m.Tuổi trẻ có một đặc quyền là được thử, được sai và không sợ sai. Chính đặc quyền “sai thì sửa” đã mở ra một bước đi mới  cho CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 138, tokens 50, triggered by: 0.15\n",
      "\u001b[32mTrải qua 3 năm hoạt động, CMC đã có chỗ đứng vững chắc trên thị  trường lắp ráp và phân phối máy tính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 139, tokens 180, triggered by: 0.16\n",
      "\u001b[34mThời điểm này, Cố Chủ tịch  Hà Thế Minh nhận ra “Mình phải tính đến giai đoạn sẽ chuyển đổi  dần sang công ty làm về hệ thống.” Thời đó, tại Việt Nam chưa có nhiều công ty tin học, những người  làm về tích hợp hệ thống thông tin lại càng hiếm. Nghề này đòi hỏi  người làm không chỉ cần có năng lực kinh doanh mà còn cần hiểu rất  rõ về công nghệ, cả phần cứng lẫn phần mềm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 140, tokens 160, triggered by: 0.18\n",
      "\u001b[35mVới mảng tích hợp hệ  thống, hai nhà lãnh đạo tự tin giao cho anh Tạ Hoàng Linh phụ trách  và anh Nguyễn Hồng Sơn làm Giám đốc dự án. Sau này, anh Nguyễn Hồng  Sơn nhớ lại buổi trao đổi về hướng đi cho việc phát triển mảng tích  hợp hệ thống với anh Hà Thế Minh: “Tuổi trẻ có một đặc quyền là  được thử, được sai và không sợ sai”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 141, tokens 121, triggered by: 0.24\n",
      "\u001b[31mChính đặc quyền “sai thì sửa”  đã tạo nên thành một bước đi mới cho CMC. TỪNG BƯỚC KHẲNG ÐỊNH  VỊ THẾ CMC.Tròn một phần tư thế kỷ, Internet từ một công nghệ lạ lẫm, nay được  70 triệu người Việt sử dụng trong cuộc sống hàng ngày.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 142, tokens 106, triggered by: 0.16\n",
      "\u001b[32mNếu những  năm 1995, điện thoại là phương thức liên lạc từ xa duy nhất của  người Việt thì chỉ một năm sau đó, năm 1996, với sự xuất hiện phổ  biến của máy tính và các công ty giải pháp đã đưa công nghệ Việt  Nam tiến thêm một bước mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 143, tokens 151, triggered by: 0.24\n",
      "\u001b[34mNhững người có máy tính dần kết nối  với nhau bằng hệ thống mạng máy tính nội bộ (Local LAN Network). CMC nhanh chóng đón đầu xu hướng, bên cạnh việc lắp ráp máy tính  thương hiệu riêng, các kỹ sư phát huy những kiến thức đã được đào  tạo, tập trung nghiên cứu xây dựng mạng kết nối phục vụ nhu cầu  thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 144, tokens 192, triggered by: 0.23\n",
      "\u001b[35mBan đầu Local LAN Network chỉ được sử dụng để thay thế việc sao  chép thông tin ra đĩa DISC và đĩa từ để in ấn. Sau này khi thị  trường phát sinh nhu cầu “nhắn tin”, trao đổi qua lại giữa 2 máy  tính, các kỹ sư Phòng Hệ thống (sau này là Trung tâm Tích hợp hệ  thống CMC) đã cùng nhau nghiên cứu xây dựng mạng máy tính có thể  chia sẻ file, trao đổi thông tin. Đây được coi là một bước tiến  lớn trong ngành công nghệ thông tin.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 145, tokens 187, triggered by: token limit\n",
      "\u001b[31mNăm 1999 - 2000, sau chuyến công tác nước ngoài, Anh Hà Thế Minh  mang về quyển sách Khái niệm Nguồn mở (Linux) và mong muốn bản địa  hóa hệ điều hành bao gồm Việt hóa để có giao diện phù hợp với người  dân Việt Nam, có thể nhập liệu được bằng ngôn ngữ Việt Nam, lưu  trữ và sắp xếp, tìm kiếm theo bảng chữ cái tiếng Việt. Đây là một  nhiệm vụ rất khó thời bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 146, tokens 174, triggered by: 0.23\n",
      "\u001b[32mCả năm 2000, nhóm kỹ sư trẻ của Trung tâm Tích hợp hệ thống có nhiệm  vụ chính là tập trung việc bản địa hóa hệ điều hành Linux. Sau nhiều  nỗ lực nghiên cứu và thử nghiệm, tháng 12/2002, Việt Nam lần đầu  tiên đã có một hệ điều hành riêng bằng tiếng mẹ đẻ - hệ điều hành  Linux của CMC và được cài đặt trên máy tính CMS tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 147, tokens 184, triggered by: token limit\n",
      "\u001b[34mKhông  còn những thuật ngữ tiếng Anh khó hiểu, tất cả những gì hiển thị  trên máy tính cá nhân được thay thế bằng tiếng Việt. Bước đi   sơ khai  CMC và Hệ điều hành Tiếng Việt đầu tiên trên máy tính .Đi xa hơn thế nữa, việc CMC hợp tác cùng CMS trong việc đưa bản  quyền phần mềm tiếng Việt vào máy tính được báo chí khẳng định là  sự đầu tư lâu dài tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 148, tokens 146, triggered by: 0.26\n",
      "\u001b[35mNgười Việt Nam đã được dùng tiếng  mẹ đẻ tự hào trên máy tính của mình, CMC Group đã thổi hồn Việt vào  máy tính Việt. Đây được đánh giá là 1 trong 10 sự kiện Công nghệ  thông tin quan trọng nhất trong năm 2002. Trung tâm Tích hợp hệ thống và CMC tự hào là công ty đầu tiên đưa  ra sản phẩm hệ điều hành Linux Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 149, tokens 107, triggered by: 0.04\n",
      "\u001b[31mCác dịch vụ Linux được  phát triển và cung cấp tới khách hàng rất đa dạng: cài đặt cấu  hình, chuyển đổi các hệ thống trên các platform khác nhau sang  Linux, tích hợp Linux với các hệ thống khác, bản địa hóa các ứng  dụng trên nền tảng Linux.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 150, tokens 118, triggered by: 0.08\n",
      "\u001b[32mThành quả này được xã hội trân trọng đón  chào không chỉ đem lại niềm tự hào riêng cho tập thể CMC Group mà  còn là niềm tự hào chung của những người Việt Nam yêu nước, luôn  khao khát đóng góp 1 phần nhỏ bé cho sự phát triển tổ quốc thân yêu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 151, tokens 96, triggered by: 0.13\n",
      "\u001b[34mOutside sales  “bất đắc dĩ”   Trong ba hạt nhân đầu tiên của phòng Kinh doanh Dự án là: anh  Nguyễn Hồng Sơn, chị Hoàng Thị Lai, anh Nguyễn Việt Thắng thì có  đến hai người xuất phát từ dân công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 152, tokens 68, triggered by: 0.27\n",
      "\u001b[35mNhững ngày đầu tiên tại  Lý Nam Đế, phòng chỉ đủ chỗ cho 2 người ngồi. Vì muốn nhường chỗ  cho nhau nên các anh chị toàn lao ra đường “tìm khách”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 153, tokens 55, triggered by: 0.27\n",
      "\u001b[31mCó lẽ nhờ  “bí quyết thiếu chỗ” đó mà phòng Kinh doanh Dự án liên tục gặt hái  được những trái ngọt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 154, tokens 194, triggered by: 0.27\n",
      "\u001b[32mHai tháng sau, phòng được chuyển sang 16A Hàm Long, văn phòng  thênh thang 100m2. Ban đầu, mỗi người chọn 1 góc do ai cũng muốn  được nhìn ra cửa sổ, sau nhớ không khí ấm cúng của Lý Nam Đế, mọi  người ngồi dồn lại cùng nhau thành một góc. Dù đã chuyển sang văn  phòng lớn hơn, nhưng tinh thần thực chiến outside sales đã trở  thành giá trị cốt lõi của phòng Kinh doanh Dự án, giúp CMC nhận  những thành công vang dội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 155, tokens 100, triggered by: 0.27\n",
      "\u001b[34m.Tin vui  nối tiếp tin vui Năm 1998, chỉ sau khoảng một năm hoạt động, anh Hồng Sơn - với vai  trò Giám đốc dự án, cùng đồng đội đã giúp doanh thu mảng tích hợp  hệ thống của CMC tăng gấp 5 lần.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 156, tokens 69, triggered by: 0.25\n",
      "\u001b[35mPhía sau thành quả này là những  đêm sáng đèn làm thầu của anh em trong phòng. “Làm thầu ngày xưa vất vả, phương tiện công cụ không đầy đủ như  bây giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 157, tokens 130, triggered by: 0.25\n",
      "\u001b[31mMãi sau bọn anh mới mua được máy dập đóng gáy xoắn, chứ  còn ngày xưa cứ phải đục 2 cái lỗ xong xỏ vào hộp, máy in thì chậm  lắm. Làm thầu thường đến 12h đêm mới xong hết tài liệu, cả phòng  đi ăn và quay lại văn phòng ngủ để sáng sớm hôm sau đi nộp thầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 158, tokens 55, triggered by: 0.20\n",
      "\u001b[32mHồi đấy còn đi xe đạp nhiều, đi xe đạp giao hồ sơ, giấy tờ chứ  không có xe máy đâu.” – Anh Sơn nhớ lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 159, tokens 94, triggered by: 0.21\n",
      "\u001b[34mNhờ sự quyết tâm và say mê ấy, liên tiếp những tin vui được báo  về. Một trong những dự án lớn đầu tiên của CMC là trúng thầu của  Kho bạc và Tổng cục Đầu tư Phát triển (nay là Ngân hàng Phát  triển).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 160, tokens 156, triggered by: 0.24\n",
      "\u001b[35mCánh cửa đầu tiên được mở giúp CMC tự tin chinh phục thêm  nhiều cánh cửa khác nữa. Anh Sơn vẫn nhớ rõ kỷ niệm và ấn tượng  về người thuyền trưởng luôn đồng hành cùng anh em: “Nói về thầu  Ngân hàng Phát triển, lần đó họ có con dấu đồng hồ chính xác đến  từng giây, chỉ cần chậm 1 giây là không được vào thầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 161, tokens 140, triggered by: 0.27\n",
      "\u001b[31mAnh và anh  Chính đi nộp thầu, hôm đó lạnh tê tái chỉ khoảng dưới 10 độ. Đi  xe ô tô thì không kịp, anh phải lấy xe máy “tổ lái” chở anh Chính  ngồi sau ôm thùng hồ sơ thầu. Đi trên đường còn thấy có bên vừa  ngồi trên xe ô tô vừa dán băng dính thùng hồ sơ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 162, tokens 166, triggered by: token limit\n",
      "\u001b[32mSếp mình mặc không  đủ ấm, đi về ốm luôn. Nhưng nhận tin trúng thầu thì lại cười khà”. Có những ngày cả anh Minh và anh Chính trực tiếp làm dự  án. Anh Chính phải lọ mọ ban đêm đến làm hồ sơ thầu rồi đi  nộp thầu tận Thái nguyên. Dù vất vả nhưng anh em ai cũng vui  và tràn đầy khí thế, quyết tâm cao độ trong từng dự án.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 163, tokens 166, triggered by: token limit\n",
      "\u001b[34mChị Hoàng Thị Lai Phụ trách quản lý kinh doanh của CMC thời bấy giờ xúc động kể lại  .Tin vui nối tiếp tin vui, hàng loạt những gói thầu “lừng lẫy” lần  lượt về tay CMC: gói thầu Danida cung cấp máy tính, máy in, dịch  vụ thư điện tử trong hệ thống, cung cấp domain riêng, truy cập  Internet trong mức độ đơn giản cho 3 cơ quan chính phủ:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 164, tokens 79, triggered by: token limit\n",
      "\u001b[35mViện Kiểm  sát, Văn phòng Quốc hội, Tòa án Nhân dân các tỉnh thành trong cả  nước. Hợp đồng có giá trị đến đơn vị triệu đô la – một con số khổng  lồ khi ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 165, tokens 210, triggered by: token limit\n",
      "\u001b[31mBên cạnh đó, CMC cũng khẳng định được vị thế trong lĩnh vực giáo  dục với gói thầu ADB cung cấp 5000 máy tính cho các trường THCS,  được ghi nhận ở cấp khu vực về số lượng máy tính bán ra nhiều nhất  trong 1 gói thầu; thầu cho Đại học Kinh tế Quốc dân trị giá 5 triệu  đô do World Bank tài trợ, cung cấp hệ thống mạng tốt nhất Việt Nam  thời bấy giờ… Chính các dự án này đã tạo đà cho CMC bứt tốc trong  những năm tiếp theo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 166, tokens 76, triggered by: token limit\n",
      "\u001b[32mVới sự phát triển vững mạnh, đến năm 2006, Trung tâm Tích hợp hệ  thống và một số bộ phận được chuyển đổi thành Công ty TNHH Tích  hợp hệ thống CMC (CMC SI).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 167, tokens 132, triggered by: token limit\n",
      "\u001b[34mHai Lãnh đạo của CMC SI – “người nhóm  lửa” mát tay cho nghề tích hợp hệ thống CMC - anh Tạ Hoàng Linh  và anh Nguyễn Hồng Sơn đã cùng CBNV của mình mở ra chương mới cho  CMC Group, đưa CMC trở thành một nhà cung cấp giải pháp, tích hợp  hệ thống hàng đầu tại Việt Nam. .Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 168, tokens 167, triggered by: token limit\n",
      "\u001b[35mCMC tham gia Lễ ký kết Hợp đồng  cung cấp thiết bị cho 630 trường THCS  .Trong suốt hành trình lịch sử hình thành và phát triển của mình, người CMC  luôn trăn trở với hoài bão tạo ra các sản phẩm - dịch vụ chất lượng và hiệu  quả, giúp đất nước phát triển. CMC đã và đang từng bước thực hiện sứ mệnh  cao cả ấy trong lĩnh vực phát triển phần mềm tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 169, tokens 249, triggered by: token limit\n",
      "\u001b[31mTrải qua thời gian mở cửa thị trường, nền kinh tế thế giới có xu  hướng chuyển dịch từ ngành công nghiệp dựa trên tài nguyên, nhân  công sang các nền công nghiệp dựa trên tri thức ở nhiều mức độ khác  nhau. Đầu năm 1996, nhận thấy chiến lược phát triển kinh tế xã hội  chú trọng hơn đến ứng dụng công nghệ thông tin trong tất cả lĩnh  vực kinh tế, anh Hà Thế Minh đã trăn trở về việc xây dựng những  phần mềm của CMC nhằm tạo ra sự chuyển biến rõ rệt về năng suất,  chất lượng và hiệu quả, hình thành mạng thông tin quốc gia.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 170, tokens 273, triggered by: token limit\n",
      "\u001b[32mPhát triển phần mềm – Cánh cửa đến với  thế giới công nghệ hiện đại Phát Triển PHẦN MỀM  HÀNH TRÌNH RỰC RỠ.Chính sự quyết tâm và nhiệt huyết của anh Hà Thế Minh đã giúp phòng  Phần mềm CMC ghi dấu những bước chân đầu tiên của mình trên thị  trường CNTT với các giải pháp: quản lý văn bản eDocman, văn phòng  điện tử OfficeMan. Đây là hệ thống quản lý tài liệu và quản lý quy  trình công việc được xây dựng trên các công nghệ tiên tiến, có khả  năng bảo mật cao, phục vụ nhiều đối tượng sử dụng và dễ dàng triển  khai trên nhiều mô hình tổ chức khác nhau.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 171, tokens 117, triggered by: 0.13\n",
      "\u001b[34mHệ thống cho phép quản  lý, lưu trữ, tra cứu toàn bộ tài liệu của tổ chức trong một cơ sở  dữ liệu duy nhất. Việc tổ chức lưu chuyển tài liệu trong tổ chức  cũng được theo dõi và lưu trữ trong cơ sở dữ liệu và được tập hợp  thành các hồ sơ công việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 172, tokens 114, triggered by: 0.22\n",
      "\u001b[35mCũng trong năm 1997, Internet bắt đầu xuất hiện tại Việt Nam, anh  Trần Bá Thái - Netnam (lúc bấy giờ là đơn vị thuộc Viện Khoa học  Công nghệ) đã liên hệ với một trường đại học bên Úc để thử nghiệm  kết nối Internet từ Úc về Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 173, tokens 70, triggered by: 0.19\n",
      "\u001b[31mLần đầu tiên, những người kỹ  sư trẻ CMC được trải nghiệm hoạt động trao đổi thông tin mà không  cần sử dụng mạng nội bộ trong phạm vi rộng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 174, tokens 86, triggered by: 0.22\n",
      "\u001b[32mCả nhóm bắt tay vào  nghiên cứu. Sau đó, anh Nguyễn Kim Cương quyết định thay mạng nội  bộ Netware bằng mạng Internet của Microsoft, thử nghiệm hệ thống  thư điện tử nội bộ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 175, tokens 113, triggered by: token limit\n",
      "\u001b[34mLần đầu tiên, tên miền @cmc.com.vn xuất hiện với những email như: htminh@cmc.com.vn,ntchinh@cmc.com.vn,nkcuong@cmc.com.vn, thể hiện  sự chuyên nghiệp, khẳng định thương hiệu của CMC trong các hoạt  động giao dịch trong nội bộ và với đối tác, khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 176, tokens 120, triggered by: token limit\n",
      "\u001b[35mSau khi CMC thử nghiệm một thời gian, nhiều cơ quan, doanh nghiệp  trong nước thấy dễ dùng, thuận tiện và tạo được dấu ấn riêng nên  đã đặt vấn đề mua, triển khai hệ thống và sử dụng dịch vụ thư điện  tử với tên miền được thiết kế riêng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 177, tokens 144, triggered by: token limit\n",
      "\u001b[31m“ @cmc.com.vn – Hệ thống email điện tử đầu tiên”  .Tại trụ sở mới, rất nhiều sản phẩm nổi bật dành cho các khách hàng  đã được phát triển, trong đó phải kể đến các sản phẩm đã đặt nền  móng, khẳng định tên tuổi của CMC như phần mềm Ilib, Dlib, Intelli- gent University. Ưu thế về sản phẩm giúp CMC liên tiếp chinh phục  các khách hàng lớn:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 178, tokens 197, triggered by: token limit\n",
      "\u001b[32mBảo Việt, VMS, Văn phòng Quốc Hội, Tòa án, Viện  kiểm sát, Thư viện Quốc gia… Cùng nhau tạo nên những   sản phẩm   phần mềm vượt trội  Năm 1997, phòng Phát triển Phần mềm CMC (CMC Soft sau này) đã xây  dựng được một phần mềm tự hào và gây tiếng vang lớn trên thị  trường, đó là CD Encyclopedia “Bách khoa thư Việt Nam”. Bách khoa  thư giúp người dùng sắp xếp dữ liệu theo ABC, theo các chủ đề và  thứ tự.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 179, tokens 177, triggered by: 0.19\n",
      "\u001b[34mNếu như từ điển bằng giấy thời đó chỉ sắp xếp được từ ngữ  theo vần ABC thì CD Bách khoa thư điện tử Việt Nam do CMC phát triển  có khả năng sắp xếp, chọn lọc, phân loại dữ liệu theo mong muốn. Ngoài việc tra từ, tìm kiếm thông tin, Bách khoa thư còn mô tả rất  nhiều vấn đề chuyên sâu, bao gồm các bài viết chi tiết về nhiều  lĩnh vực khác nhau để tra cứu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 180, tokens 118, triggered by: token limit\n",
      "\u001b[35mBên cạnh việc tra cứu hữu dụng và  đầy đủ, sản phẩm nhận được rất nhiều lời khen về tính thẩm mỹ khi  được minh họa với hình ảnh vô cùng đẹp mắt kết hợp cùng âm nhạc,  tạo nên trải nghiệm thú vị và hoàn toàn mới lạ ngày ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 181, tokens 127, triggered by: token limit\n",
      "\u001b[31mBách khoa thư điện tử đã trở thành người bạn không thể thiếu với  sinh viên, các cơ quan, giới tri thức Việt Nam; đưa tiếng tăm của  CMC lan rộng khắp cả nước, được in thành 4 tập sách và bán ra ngoài. Đây là một dự án phi lợi nhuận song có ý nghĩa to lớn với CMC thời  bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 182, tokens 227, triggered by: token limit\n",
      "\u001b[32mBách khoa thư điện tử Việt Nam – Sản   phẩm tự hào.ILib là giải pháp thư viện điện tử cho các thư viện, là một hệ thống  thư viện tích hợp với các module được thiết kế nhằm đáp ứng nhu cầu  của thư viện, từ các thư viện công cộng, thư viện trong các trường  học đến các thư viện chuyên ngành, trung tâm thông tin trong toàn  quốc. Đặc biệt phần mềm có khả năng hỗ trợ đa ngôn ngữ và xử lý  tiếng Việt, khả năng trao đổi thông tin thư mục và nội dung với  hàng trăm nghìn thư viện điện tử trên thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 183, tokens 132, triggered by: token limit\n",
      "\u001b[34mILib quản trị các quy trình nghiệp vụ theo chuẩn của một thư viện  hiện đại bao gồm: bổ sung, biên mục, tra cứu trực tuyến, quản lý  lưu thông tài liệu, quản lý thông tin về bạn đọc, mượn liên thư  viện, quản trị hệ thống – tất cả đều có thể kết hợp sử dụng thông  qua mã vạch.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 184, tokens 134, triggered by: token limit\n",
      "\u001b[35mNgoài lĩnh vực quản lý thư viện truyền thống, ILib còn có khả năng  phát triển để trở thành thư viện số, biến thư viện trở thành trung  tâm thông tin thực sự hiện đại, tạo cho người sử dụng một cổng vào  mọi dạng thông tin, dù là xuất bản phẩm, tài liệu điện tử hay âm  thanh, hình ảnh. Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 185, tokens 209, triggered by: token limit\n",
      "\u001b[31mLễ khai trương phòng ILIB - CMCSOFT   41  Ilib – Nâng cao năng lực hoạt động của các thư viện Việt Nam.Dlib – Mở ra một hướng đi mới cho hoạt động thông tin thư viện tại  Việt Nam Intelligent University – Giải pháp đại học thông minh Phần mềm thư viện số Dlib bao gồm nhiều giải pháp phục vụ cho hoạt  động số hóa các tài liệu truyền thống như sách, báo, tạp chí, vi  phim,… hỗ trợ biên mục và lưu trữ các tài liệu dưới dạng văn bản,  hình ảnh, âm thanh, phim.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 186, tokens 167, triggered by: token limit\n",
      "\u001b[32mPhần mềm này hỗ trợ xây dựng các giáo  trình sách điện tử, biến các loại tài liệu này trở thành tài nguyên  của thư viện để phục vụ bạn đọc như các tài liệu truyền thống khác. Từ đó cho phép người đọc truy cập và khai thác thông tin trực  tuyến. Hệ thống được xây dựng dựa trên các tiêu chuẩn mở do đó dễ  dàng nâng cấp mở rộng, trao đổi thông tin với các thư viện số khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 187, tokens 122, triggered by: token limit\n",
      "\u001b[34mILib và Dlib là một bước đột phá vượt bậc về mặt nghiệp vụ thư viện  hiện đại và ứng dụng công nghệ thông tin, đáp ứng các nhu cầu khắt  khe nhất của các thư viện và trung tâm thông tin. Là một giải pháp tổng thể cho hệ thống quản lý thông tin của trường  đại học.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 188, tokens 161, triggered by: token limit\n",
      "\u001b[35mGiải pháp này giúp các trường đại học Việt Nam từng bước  xây dựng một hệ thống quản lý thông tin hiệu quả trên cơ sở tích  hợp tất cả các hoạt động của toàn trường bao gồm: quản lý đào tạo,  quản lý hành chính và nghiên cứu khoa học. Phần mềm tích hợp IU  được thiết kế nhằm đem lại nhiều lợi ích thuận tiện cho người sử  dụng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 189, tokens 150, triggered by: token limit\n",
      "\u001b[31mGiải pháp IU của CMC Soft đã tạo tiền đề quan trọng để các  trường đại học vững bước tiến vào kỷ nguyên mới của công nghệ thông  tin và truyền thông hiện đại. .Bên cạnh các sản phẩm phục vụ lĩnh vực giáo dục đào tạo, CMC Soft  cũng tạo tiếng vang trên thị trường với các phần mềm giải pháp cho  khối cơ quan chính phủ, doanh nghiệp như:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 190, tokens 279, triggered by: token limit\n",
      "\u001b[32mCD-PUB – phần mềm xuất  bản CD-ROM thông tin cho phép người dùng xây dựng và xuất bản các  ấn phẩm thông tin trên CD-ROM theo nội dung tùy chọn, PDM - ứng  dụng quản lý tài liệu cá nhân được thiết kế phục vụ công việc tra  cứu tài liệu của các doanh nhân, luật gia, nhân viên văn phòng, Hệ  thống ứng dụng dịch vụ tài chính – đáp ứng nhu cầu nghiệp vụ liên  quan đến tài chính,… Không chỉ dừng lại ở hoạt động phát triển phần mềm, CMC Soft còn  trở thành đối tác của Microsoft, Oracle, SAP, ISTQB, TeamViewer,  Samsung SDS; lọt top 25 nhà cung cấp uy tín nhất của SAP năm 2017  và đạt các chứng chỉ ISO 9001-2000, ISO 27001,….\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 191, tokens 328, triggered by: token limit\n",
      "\u001b[34mTừ bộ phận nhỏ thuộc phòng Hệ thống và Phát triển Phần mềm vào năm  1996, sau đó tách thành Phòng Phần mềm năm 1998 và trở thành Trung  tâm Phát triển Phần mềm vào năm 1999 với xuất phát chưa đầy 20  người; đến thời điểm 2003, Trung tâm Phát triển Phần mềm đã xây  dựng được nguồn nhân lực trình độ cao, kinh nghiệm dày dặn, nhiệt  huyết, đưa CMC trở thành đối tác uy tín của nhiều tổ chức, doanh  nghiệp trong và ngoài nước, cung cấp giải pháp hiệu quả cho hàng  ngàn doanh nghiệp trên khắp 63 tỉnh thành. Điều này đã tạo tiền đề  cho việc thành lập Công ty Cổ phần Giải pháp Phần mềm CMC (CMC  Soft) vào năm 2006, cùng viết nên những trang sử rực rỡ trong hành  trình Kiến tạo Di sản số của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 192, tokens 145, triggered by: token limit\n",
      "\u001b[35m.NHỮNG CƠN MƯA  NƠI GIỮA ÐẠI LỘ Mở rộng Câu chuyện bắt đầu từ THỊ TRƯỜNG KHU VỰC PHÍA NAM Ai cũng nói “Thời tiết Sài Gòn thất thường, sáng nắng, chiều  mưa”. Đó là 1 nét đặc trưng riêng của Sài Gòn mà không phải ở  đâu cũng có được.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 193, tokens 109, triggered by: token limit\n",
      "\u001b[31mCó rất nhiều kiểu mưa ở Sài Gòn như mưa vội,  mưa bất chợt và mưa mang theo nhiều cảm xúc… Những cơn mưa ấy  còn chứng kiến ước mơ và khát vọng cùng những nỗ lực chinh phục  thị trường phía Nam của Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 194, tokens 210, triggered by: token limit\n",
      "\u001b[32m.Đầu năm 1995, khi sản phẩm nghiên cứu khoa học và công nghệ trong  nước chưa nhiều, tỷ lệ ứng dụng vào sản xuất và đời sống còn thấp,  nền khoa học và công nghệ nước ta phát triển chậm, chưa tương xứng  với tiềm năng sẵn có, anh Hà Thế Minh và anh Nguyễn Trung Chính  mong muốn đưa những sản phẩm, dịch vụ của CMC “Nam tiến” để đóng  góp cho chiến lược phát triển khoa học công nghệ trong thời kỳ công  nghiệp hóa, hiện đại hóa đất nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 195, tokens 170, triggered by: token limit\n",
      "\u001b[34mGiữa những cơn mưa lớn của mùa  mưa Sài Gòn, hai anh lặn lội đi tìm địa điểm, hiện thực hóa mục  tiêu phát triển tốt trong nước trước khi phát triển ra thị trường  quốc tế. Quá trình tìm địa điểm rất vất vả vì đi lại không thuận  tiện như bây giờ và không có nhiều địa điểm phù hợp để lựa chọn,  thời tiết Sài Gòn lại mưa nắng bất chợt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 196, tokens 137, triggered by: token limit\n",
      "\u001b[35mCó những địa điểm ngay  giao lộ, vị trí đẹp nhưng lại không kịp ký hợp đồng, hai anh lại  đội mưa về nhà người thân: cô Phạm Thị Diệu Thanh - người nhà của  anh Minh tại Sài Gòn. Cô cũng là người giúp đỡ CMC để tìm kiếm địa  điểm và set-up chi nhánh từ những ngày đầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 197, tokens 86, triggered by: token limit\n",
      "\u001b[31mNgày qua ngày, các anh  vừa trực tiếp đi từng con phố, vừa đọc báo, vừa xem thêm các tờ  rơi cho thuê mặt bằng, không bỏ sót một chỗ nào tiềm năng. Đây rồi!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 198, tokens 199, triggered by: token limit\n",
      "\u001b[32mAnh Minh, đây, địa điểm này, 232  Nguyễn Thị Minh Khai Anh Chính  Mừng rõ reo lên khi thấy tin  cho thuê mặt bằng trên báo  Nhận thấy đường Nguyễn Thị Minh Khai có vị trí rất đẹp và thuận  lợi, là một trong những con đường cổ xưa nhất của Sài Gòn và cũng  là con đường quan trọng đi về phía Bắc. Không hề do dự, hai anh đã  chọn địa điểm 232 Nguyễn Thị Minh Khai làm trụ sở cho Công ty Máy  tính Truyền thông II.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 199, tokens 160, triggered by: 0.30\n",
      "\u001b[34mMở rộng thị trường –  xu thế tất yếu  .Sau khi sửa sang lại mặt bằng, tuyển dụng nhân sự cho các vị trí,  ngày 4/11/1996, CMC thành lập cơ sở tại TP HCM với tên gọi Công ty  TNHH Dịch vụ - Thương mại Máy tính Truyền thông II. Ngày đó, thị  trường còn mới nên chi nhánh Hồ Chí Minh nhận được sự hỗ trợ tích  cực của anh em Hà Nội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 200, tokens 108, triggered by: 0.09\n",
      "\u001b[35mKhi đi vào hoạt động, hàng hóa, linh kiện  được chuyển từ Hà Nội vào Thành phố Hồ Chí Minh mỗi tháng. “Mỗi  lần đi nhận hàng là một lần hồi hộp” , anh Lê Quang Thành - Giám  đốc của Công ty Máy tính Truyền thông II ngày đó chia sẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 201, tokens 124, triggered by: 0.24\n",
      "\u001b[31mVào mùa  nắng nóng, các anh em phải chạy xe dưới lòng đường cùng với những  thùng hàng nặng phía sau. Hơn nữa, họ phải di chuyển đến nhiều địa  điểm khác nhau và đứng chờ người nhận. Đôi khi, quãng thời gian  chờ đợi này lên đến cả tiếng đồng hồ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 202, tokens 83, triggered by: 0.37\n",
      "\u001b[32mLinh kiện, máy móc nóng quá  cũng sợ bị ảnh hưởng lúc lắp ráp. Mùa mưa Sài Gòn cũng là cơn “ác mộng” với các anh em kho vận, giao  hàng, lắp đặt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 203, tokens 172, triggered by: 0.25\n",
      "\u001b[34mCứ mỗi buổi chiều tà, những cơn mưa bất chợt ập đến  lúc nào không hay. Hàng hóa được chở bằng xe máy hoặc xe lam, ngược  xuôi các con phố. Những người CMC Sài thành lúc ấy đôi khi còn dành  cả chiếc áo mưa mình có trong cơn mưa bất chợt để che cho những  thùng hàng, những bộ máy, linh kiện khỏi ướt; còn người mình thì  ướt nhẹp đi đến nhà khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 204, tokens 51, triggered by: 0.33\n",
      "\u001b[35mNét đẹp lao động bình dị ấy là hình  ảnh đáng quý của Người CMC Sài Gòn chất phác, hồn hậu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 205, tokens 191, triggered by: token limit\n",
      "\u001b[31mNgang qua những tuyến đường, con hẻm ở nơi được mệnh danh là “Hòn  ngọc Viễn Đông”, ước mơ mang những sản phẩm, dịch vụ của người CMC  luôn mạnh mẽ. Giữa những bộn bề lo toan, tất bật mưu sinh, ước mơ  mang thương hiệu của CMC phát triển rộng khắp phía Nam lớn mạnh  hơn nữa, gia tăng số lượng, chất lượng, quy mô và mang các dự án  uy tín đến khách hàng và đối tác luôn trong suy nghĩ mỗi người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 206, tokens 120, triggered by: token limit\n",
      "\u001b[32mNhững viên gạch đầu tiên trên đất Sài Gòn ấy đã đưa CMC lên một  tầm cao mới, khẳng định sự phát triển CMC rộng khắp cả nước, đảm  bảo chiến lược của những nhà lãnh đạo CMC: làm thật tốt trong nước  để tiến quân ra thị trường nước ngoài.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 207, tokens 86, triggered by: token limit\n",
      "\u001b[34mNhững viên gạch  đầu tiên.Hình ảnh Workshop’97 tại Ho Chi Minh City .Blue Sky – cái tên mà sau này khi nhắc lại vẫn  rung lên niềm tự hào và cảm xúc bồi hồi đối với  những người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 208, tokens 149, triggered by: token limit\n",
      "\u001b[35mKhi máy tính còn là một món đồ  xa xỉ, là ước mơ của nhiều người mong được một  lần trải nghiệm hoặc khách hàng chỉ có thể tìm  hiểu qua sách báo chứ không có cơ hội thử trước  khi quyết định mua; Blue Sky của CMC – siêu thị máy tính đầu tiên tại  Việt Nam ra đời như một điểm tụ hội của các tín  đồ yêu công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 209, tokens 147, triggered by: token limit\n",
      "\u001b[31mSiêu thị  máy tính  đầu tiên của  Việt Nam Bước lội  ngược dòng  BLUE  KY.Trải qua 5 năm phát triển, hoạt động phân  phối máy tính giúp CMC có chỗ đứng vững  chắc trên thị trường. Năm 1998, Blue Sky –  siêu thị bán lẻ hàng điện tử đầu tiên tại  Việt Nam được thành lập và nhanh chóng tạo  dựng được danh tiếng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 210, tokens 117, triggered by: token limit\n",
      "\u001b[32mBlue Sky đã khẳng  định quyết tâm lớn của những người sáng  lập công ty: đầu tư một cách bài bản và  vươn lên vị trí dẫn đầu trong các lĩnh vực  mà công ty tham gia. Blue Sky cung cấp máy  tính Toshiba, Compaq, máy in, USB và các  thiết bị điện tử khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 211, tokens 155, triggered by: 0.25\n",
      "\u001b[34mToà nhà 16A Hàm Long bao gồm siêu thị máy  tính Blue Sky ở tầng 1 do Công ty Nội thất  Sáng tạo thiết kế và thi công; tầng 2 và  tầng 3 là văn phòng của CMC và CMS, kho,  khu vực bảo hành. Blue Sky có diện tích khoảng 400m2 bao gồm  khu vực tư vấn bán hàng, quầy thu ngân, khu  vực trưng bày và trải nghiệm sản phẩm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 212, tokens 135, triggered by: token limit\n",
      "\u001b[35mHiện nay, mô hình cửa hàng này là phổ biến  nhưng tại thời điểm đó, đây là nơi bán hàng  đầu tiên có thiết kế hiện đại và mang tính  đón đầu thời đại. Đặc biệt, các bệ đỡ của  sản phẩm được thiết kế rất sáng tạo với  nhiều hình thù và màu sắc, tạo nên phong  cách đặc trưng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 213, tokens 200, triggered by: token limit\n",
      "\u001b[31mSau Blue Sky, một số đơn  vị cũng mở siêu thị máy tính và có báo với  bên thiết kế “Cứ làm đúng như Blue Sky của  anh Minh, anh Chính là được”. Thời gian  thi công khoảng 6 tháng với rất nhiều kỷ  niệm đáng nhớ. Những điều đầu tiên  Trong cơn bão ấy, có doanh nghiệp lội  ngược dòng, đầu tư tiền tỉ mở văn phòng  mới, mở siêu thị máy tính Blue Sky  to nhất cả nước Anh Tạ Hoàng Linh chia sẻ   Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 214, tokens 110, triggered by: 0.23\n",
      "\u001b[32mAnh Hà Thế Minh phát biểu  trong Lễ Khai trương Siêu thị Máy tính  Blue Sky   .Những ngày đầu tiên khởi công, xe cát vận chuyển từ bãi cát sông  Hồng về Hàm Long. Khi chiếc xe lùi đổ vào công trường, một “vật  thể lạ” rơi xuống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 215, tokens 66, triggered by: 0.30\n",
      "\u001b[34mNhững người công nhân trực đêm hôm đó giật mình  hoảng hốt: nguyên một quả pháo 12 ly 7 còn nguyên dầu mỡ và ngòi  nổ từ chiến tranh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 216, tokens 137, triggered by: 0.23\n",
      "\u001b[35mAnh em công trường vội vàng gọi công an phường  đến xử lý thu hồi. “Hồi đó sợ hết hồn mà giờ nghĩ lại thành kỷ niệm  đáng nhớ” – Anh Tô Sơn nhớ lại. Đội ngũ thi công ngày ấy làm việc không kể ngày đêm để kịp tiến độ  khai trương siêu thị và chuyển văn phòng từ Lý Nam Đế về.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 217, tokens 57, triggered by: 0.19\n",
      "\u001b[31mVới đặc  thù văn phòng công nghệ cùng hệ thống mạng phức tạp, các đường dây  bạt ngàn khiến anh em thi công “đau đầu”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 218, tokens 185, triggered by: token limit\n",
      "\u001b[32mViệc đấu mạng mất nhiều  thời gian và rất căng thẳng. Trước ngày khai trương 1 tuần là những  đêm thức trắng. Đêm cuối cùng, công tác chuẩn bị gần như đã sẵn  sàng, đội kỹ thuật rủ nhau đi ăn rồi quay lại hoàn thiện nốt. Câu  chuyện rôm rả cứ kéo dài mãi đến tận khuya, cả đội về văn phòng  hẹn nhau “chợp mắt một tí” rồi dậy hoàn thiện nốt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 219, tokens 101, triggered by: 0.33\n",
      "\u001b[34mCái chợp mắt  đến tận 5 giờ sáng hôm sau, may mắn đội ngũ Blue Sky đến sớm chuẩn  bị khai trương gọi cả đội dậy. Anh em nháo nhào hoàn thiện hệ thống  mạng và kịp lễ khai trương hoành tráng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 220, tokens 123, triggered by: 0.41\n",
      "\u001b[35mKỷ niệm  khó quên 8h sáng, con phố Hàm Long tấp nập và náo nhiệt khác hẳn mọi ngày. Tuy chương trình 9 giờ mới bắt đầu nhưng trước cửa Siêu thị Máy  tính Blue Sky đã đông kín người, một số người phải đứng tràn sang  cả những dãy nhà đối diện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 221, tokens 104, triggered by: token limit\n",
      "\u001b[31mKhông chỉ là lễ khai trương siêu thị  máy tính đầu tiên tại Việt Nam, ngày hôm đó người dân Hà Nội còn  được chứng kiến sự kiện lớn hiếm có với những màn múa lân hoành  tráng và lượng người đổ về đông đến như vậy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 222, tokens 220, triggered by: token limit\n",
      "\u001b[32mNhững tín đồ công nghệ  đến để cập nhật các sản phẩm hiện đại, những sinh viên đến để được  tự mình trải nghiệm chiếc máy tính trong mơ, các gia đình dẫn con  cái đến để lựa chọn món quà đặc biệt,… Lễ khai trương Siêu thị Máy  tính Blue Sky của CMC vinh dự được đón tiếp 7 Thứ trưởng cùng Chủ  tịch Thành phố Hà Nội đến tham dự và chúc mừng. Đến tận mấy ngày  sau, người ta vẫn kháo nhau đang là ngày khai trương của Blue Sky  do số lượng người đến quá đông, kéo dài cả con phố.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 223, tokens 137, triggered by: 0.19\n",
      "\u001b[34mLễ khai trương đáng nhớ.Hai năm đầu, Blue Sky hoạt động khá suôn sẻ. Song những khó khăn  ập đến vào những năm 2000, Luật Thuế giá trị gia tăng (VAT) được  áp dụng khiến Blue Sky không thể cạnh tranh với những doanh nghiệp  lách luật trốn thuế. Sau đó Blue Sky buộc phải dừng hoạt động.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 224, tokens 122, triggered by: -0.01\n",
      "\u001b[35mNguyên nhân thất bại được  chỉ ra không phải do đầu tư trái ngành mà do đi sớm hơn thị trường  và do những thay đổi của chính sách của Nhà nước. Tuy nhiên, Blue  Sky vẫn in dấu trong trái tim người dân Thủ đô và là một dấu mốc  đáng nhớ của CMC và nền tin học nước nhà.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 225, tokens 88, triggered by: 0.16\n",
      "\u001b[31mHình ảnh: Khai trương Siêu thị Máy tính Blue Sky   .Niềm ấp ủ về chiếc máy tính mang thương hiệu Made in Vietnam chưa  bao giờ thôi cháy bỏng trong trái tim những người kỹ sư công nghệ  CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 226, tokens 125, triggered by: 0.31\n",
      "\u001b[32mNăm 1998 cũng là thời điểm cuốn “sách trắng” đầu tiên về “Khoa  học và Công nghệ” được xuất bản ngày 7/4/1998 bởi Bộ Khoa học và  Công nghệ Trung Quốc đưa ra các mục tiêu cho các nhà nghiên cứu là  thúc đẩy tiến bộ công nghệ trong mọi lĩnh vực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 227, tokens 87, triggered by: 0.20\n",
      "\u001b[34mTừ “công nghệ” xuất  hiện khắp mọi nơi, mọi văn bản. Để đẩy mạnh phát triển công nghệ,  Trung Quốc mở cửa cho các hãng máy tính thế giới du nhập và phát  triển thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 228, tokens 121, triggered by: 0.38\n",
      "\u001b[35mTuy nhiên, trong bối cảnh đó, khi được tham gia  vào chương trình học tập và khảo sát tại Trung Quốc, anh Nguyễn  Trung Chính lại thấy rằng Trung Quốc chỉ có máy tính lắp ráp Legend  (sau này là Lenovo), còn lại tất cả công nghệ lõi vẫn do Mỹ làm  chủ và sản xuất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 229, tokens 93, triggered by: 0.38\n",
      "\u001b[31m“Vậy tại sao, ở thị trường Việt Nam, mình không tự tạo nên một công  ty có thể vừa kinh doanh và lắp ráp máy tính thương hiệu Việt mà  không cần phụ thuộc vào các nước khác” - anh Chính suy nghĩ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 230, tokens 109, triggered by: 0.25\n",
      "\u001b[32mNgay  sau khi trở về nước, anh cùng các cộng sự đã đưa ra một quyết định  lớn: hiện thực hóa ước mơ sản xuất “máy tính thương hiệu Việt”,  thành lập Công ty TNHH Sản xuất và Dịch vụ máy tính Thế Trung (nay  là CMS) vào năm 1999.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 231, tokens 50, triggered by: 0.27\n",
      "\u001b[34mCái tên Thế Trung được lấy từ tên đệm của  hai nhà sáng lập là anh Hà Thế Minh và anh Nguyễn Trung Chính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 232, tokens 71, triggered by: 0.38\n",
      "\u001b[35mSau  này, cái tên thân thương ấy cũng được đặt cho con trai thứ 2 của  anh Minh với tất cả tình yêu và sự nâng niu như tình cảm dành cho  CMC và CMS.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 233, tokens 122, triggered by: 0.38\n",
      "\u001b[31mNhững điều  đầu tiên Canh cánh giấc mơ ghi tên Việt Nam lên bản đồ công nghệ thế giới, những  chàng trai trẻ Viện Vi điện tử ngày ấy tiếp tục viết tiếp chương ước mơ  dang dở mang tên: Xây dựng thương hiệu máy tính Made in Việt Nam, máy tính  của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 234, tokens 152, triggered by: 0.09\n",
      "\u001b[32mGIẤC MƠ MÁY TÍNH THƯƠNG HIỆU NHÀ MÁY LẮP RÁP SẢN XUẤT MÁY TÍNH  LỚN NHẤT VIỆT NAM - HIỆN THỰC HÓA .Thời kỳ đầu, “Khu đất vàng” 67 Ngô Thì Nhậm được lựa chọn làm trụ  sở của CMS và tầng 4 được đặt xưởng lắp ráp máy tính và phòng phát  triển sản phẩm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 235, tokens 81, triggered by: 0.31\n",
      "\u001b[34mViệc bê vác những thùng máy tính, thùng linh kiện  mỗi ngày diễn ra vài ba bận, khi từ tầng 1 lên tầng 4 nhập kho,  lúc lại từ tầng 4 xuống tầng 1 giao hàng cho khách.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 236, tokens 56, triggered by: token limit\n",
      "\u001b[35mCũng bởi lẽ  vậy, anh em CMS lúc nào cũng trong tình trạng tất bật và được rèn  luyện thể lực mỗi ngày.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 237, tokens 203, triggered by: token limit\n",
      "\u001b[31mCông việc tuy bận rộn nhưng không khí trong  công ty luôn tấp nập, vui vẻ; anh em tràn đầy hứng khởi, vẻ rạng  ngời hiện rõ trên từng khuôn mặt khi ngày càng có nhiều sản phẩm  chất lượng được giao tới tay khách hàng. Đặc biệt, vào mỗi dịp có  cơ hội thi đấu thể thao ở Tập đoàn, đội quân CMS đều ôm trọn các  giải thưởng ở thứ hạng cao, có lẽ đây là kết quả của quá trình rèn  luyện thể lực mỗi ngày.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 238, tokens 134, triggered by: 0.32\n",
      "\u001b[32mLao động  hăng say Hình ảnh: Anh Hà Thế Minh - Cố CT HĐQT CMC  trong sự kiện ra máy tính CMS với Hệ điều  hành tiếng Việt   .Nhà máy sản xuất & lắp ráp máy tính lớn nhất Việt Nam  Năm 2003, CMS định hướng tăng tỷ lệ nội địa hóa theo hai hướng:  phần cứng và phần mềm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 239, tokens 157, triggered by: token limit\n",
      "\u001b[34mVề phần cứng, CMS cộng tác với các đơn vị  có khả năng sản xuất, đầu tiên với LG là một hợp tác OEM. Riêng  nguồn, case, chuột và bàn phím làm việc với các hãng nội địa để có  một số thử nghiệm. Về phần mềm, CMS làm việc với các công ty phần  mềm nội địa để cài đặt sẵn các phần mềm trên máy tính xuất xưởng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 240, tokens 177, triggered by: 0.28\n",
      "\u001b[35mĐể hiện thực hóa mục tiêu này, CMS phối hợp cùng Công ty Điện tử  Hanel xây dựng nhà máy sản xuất và lắp ráp máy tính thương hiệu  Việt Nam tại Khu Công nghiệp Sài Đồng (Gia Lâm, Hà Nội). Cơ sở có công suất 10.000 máy/tháng với số vốn đầu tư 25 tỷ đồng  - một số tiền rất lớn thời ấy. Nhà máy là cơ sở sản xuất máy tính  OEM (Original Equipment Manufacturer) đầu tiên của Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 241, tokens 140, triggered by: token limit\n",
      "\u001b[31mDây  chuyền sản xuất khép kín từ công đoạn tạo sản phẩm mẫu, lắp ráp  linh kiện, khống chế môi trường nhiệt độ, lắc rung, kiểm tra chất  lượng đến sản xuất hàng loạt. Việc có dây chuyền giúp CMC sản xuất  quy mô lớn thay vì chỉ lắp ráp được vài chục trăm bộ một ngày khi  ở xưởng Hàm Long.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 242, tokens 149, triggered by: token limit\n",
      "\u001b[32mVào mùa cao điểm cuối năm, có đợt 1 tháng, dây  chuyền sản xuất làm ra khoảng 20 nghìn máy tính với số lượng công  nhân ở xưởng lúc đó khoảng 50  - 60 người. .Máy tính CMS được nhiều cơ quan Đảng từ Trung ương đến địa phương,  các Sở Tài chính, Sở Giáo dục và Đào tạo nhiều tỉnh thành tin dùng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 243, tokens 118, triggered by: token limit\n",
      "\u001b[34mRiêng trong lĩnh vực giáo dục và đào tạo, CMC đã có 20 năm đồng  hành từ những ngày đầu tiên sơ khai ra mắt thị trường với dòng máy  CMS Powercom, CMS Olympia và sau đó là thế hệ máy tính CMS X-Media,  tích hợp hệ điều hành Windows bản quyền, phần mềm Office 365….\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 244, tokens 146, triggered by: 0.18\n",
      "\u001b[35mBên  cạnh đó, các sản phẩm CMS với tính đồng bộ cao, hoạt động tốt trong  điều kiện điện áp không ổn định, thay đổi nhiệt độ lớn đã phục vụ  hiệu quả các nhu cầu nghiên cứu, giảng dạy và học tập. Năm 2003, CMS triển khai dự án cung cấp hơn 5000 máy tính cho 630  trường THCS ở 61 tỉnh thành.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 245, tokens 139, triggered by: 0.35\n",
      "\u001b[31mChương trình thuộc Dự án Phát triển  giáo dục THCS do Ngân hàng Phát triển Châu Á ADB tài trợ. CMS đã  thắng thầu cung cấp lô máy tính Powercom với cấu hình bộ xử lý  Intel Celeron 1,7GHz, bo mạch chủ Intel, sử dụng hệ điều hành mã  nguồn mở RedHat Việt hóa của Cty CMC với bộ ứng dụng Star Office.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 246, tokens 147, triggered by: token limit\n",
      "\u001b[32mGiá trị của hợp đồng là 2 triệu USD - chỉ đủ mua 1.700 máy trong  các dự án thông thường sử dụng phần mềm thương mại. Được biết riêng  việc sử dụng phần mềm mã nguồn mở tiếng Việt đã tiết kiệm khoảng  630.000 USD. Đây là hợp đồng cung cấp máy tính thương hiệu Việt  Nam lớn nhất tại thời điểm đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 247, tokens 189, triggered by: token limit\n",
      "\u001b[34mNhững chiếc máy tính CMS có mặt trên mọi miền tổ quốc đã từng ngày,  từng giờ hỗ trợ hiệu quả cho các giáo viên nâng cao phương pháp  giảng dạy, nghiên cứu, tìm kiếm tư liệu; giúp học sinh, sinh viên  khai thác nguồn kiến thức vô tận qua Internet, tham gia hiệu quả  các lớp học trực tuyến… CMS sau 4 năm gây dựng, đã khánh thành nhà máy sản xuất có quy mô  tương đương Legend của Trung Quốc (tiền thân của Lenovo ngày nay).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 248, tokens 143, triggered by: 0.29\n",
      "\u001b[35mThế nhưng, khi giấc mơ tạo nên chiếc máy tính “Made in Vietnam”  sắp thành hiện thực thì vấn đề về chính sách đã giáng một đòn nặng  nề lên CMS non trẻ. Máy tính nhập nguyên chiếc được hưởng thuế 0%,  còn linh kiện phải chịu thuế 5%, điều đó khiến cho việc lắp ráp  máy tính không thành công như mong đợi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 249, tokens 63, triggered by: token limit\n",
      "\u001b[31mTuy nhiên, những gì mà CMC  làm được đã tạo bước ngoặt lớn, đánh dấu sự thành công và gây tiếng  vang của CMC trên thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 250, tokens 370, triggered by: token limit\n",
      "\u001b[32mMáy tính CMS đồng hành  cùng sự phát triển của Việt Nam Những con đường không trải hoa hồng   .10 Cùng với viễn thông, ngành công nghệ thông tin đã có nhiều thay đổi trong thập  kỷ vừa qua.Ngày hôm nay, chúng ta có thể nhìn thấy những thành tựu rất to  lớn của công nghệ thông tin nhưng tôi có thể kết luận rằng những gì chúng ta  biết ngày hôm nay thì ngày mai đã trở nên lạc hậu.Chính vì vậy, những người  làm công nghệ thông tin phải đứng trước một thách thức rất lớn: đó là luôn luôn  phải tự đổi mới chính mình, luôn luôn phải học và tiếp thu những thành tựu  mới.Chúng ta luôn luôn phải Hướng tới tương lai của Thế giới số. Đó là  những điều mà chúng tôi muốn gửi tới tất cả các anh chị em trong Công ty  CMC cũng như đó là tâm nguyện của Ban lãnh đạo Công ty CMC đối  với sự nghiệp của mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 251, tokens 148, triggered by: token limit\n",
      "\u001b[34mChia sẻ của Cố Chủ tịch Hà Thế Minh  nhân dịp Kỷ niệm 10 năm thành lập CMC Group  năm một chặng đường “HƯỚNG TỚI   TƯƠNG LAI SỐ”.Với khởi đầu ở căn nhà nhỏ trên phố Lý Nam Đế, trải qua mười năm nỗ lực  và say mê, số lượng 20 nhân viên ban đầu đã phát triển lên tới con số  hơn 400 Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 252, tokens 139, triggered by: token limit\n",
      "\u001b[35mTừ tiền thân là Trung tâm ADCOM, sau 10 năm, Công  ty TNHH HT&NT ngày nào đã trở thành CMC Group – một tập hợp các công ty tin học lớn của Việt Nam. CMC Group được biết đến như một trong  những công ty hàng đầu trong các lĩnh vực cung cấp sản phẩm, giải pháp,  dịch vụ trong lĩnh vực công nghệ thông tin và phát triển phần mềm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 253, tokens 167, triggered by: token limit\n",
      "\u001b[31mHoài  bão của hai thành viên sáng lập: ước mơ nghiên cứu ứng dụng các công  nghệ mới, sản phẩm mới, tiến tới phát triển những sản phẩm của chính  mình – những sản phẩm công nghệ thông tin Việt Nam đã trở thành mục  tiêu của tất cả cán bộ nhân viên CMC Group. Phía sau thành công ấy là những nỗ lực miệt mài và say mê cống hiến,  từng bước chinh phục các dấu mốc quan trọng của tập thể Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 254, tokens 226, triggered by: token limit\n",
      "\u001b[32mNăm 1996, CMC Group đã thành lập Công ty CMC Sài Gòn (Công ty TNHH Dich  vụ Thương mại Máy tính Truyền thông II), Trung tâm Phát triển Phần mềm  (CMC Soft), Trung tâm Tích hợp Hệ thống (CMC SI). Đầu năm 1998, với sự  thành lập Công ty TNHH Nhật Quang, CMC Group đã đánh dấu những bước đầu  tiên vào giai đoạn 2 trong chiến lược của mình: giai đoạn định hướng  vào các sản phẩm và dịch vụ chuyên nghiệp với sự chuyên nghiệp hoá các  hoạt động của trong nội bộ công ty Tự hào 10 năm cmc Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 255, tokens 188, triggered by: 0.36\n",
      "\u001b[34mKỷ niệm 10 năm CMC Group  .“Con người” tài sản lớn nhất Một năm sau đó, CMS (Công ty TNHH Thế Trung) ra đời nhằm thúc đẩy việc  xây dựng thương hiệu Máy tính Việt Nam CMS. Các hoạt động chính trong  CMC Group đã được từng công ty và trung tâm riêng biệt phụ trách: phân  phối, sản xuất máy tính, tích hợp hệ thống & cung cấp thiết bị, phát  triển phần mềm, dịch vụ bán lẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 256, tokens 185, triggered by: token limit\n",
      "\u001b[35mViệc kết hợp chặt chẽ giữa các công ty  thành viên không chỉ đem lại sức mạnh cho các đơn vị mà góp phần hình  thành một khối các công ty công nghệ thông tin có tiềm lực mạnh mẽ. Dịch vụ tích hợp hệ thống và cung cấp thiết bị do Trung tâm CSI, Công  ty Nhật Quang và Công ty CMC Sài Gòn cung cấp được đánh giá là những  dịch vụ có chất lượng cao, có trình độ kỹ thuật tốt, được các đối tác  công nghệ tin cậy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 257, tokens 109, triggered by: token limit\n",
      "\u001b[31mHoạt động bán lẻ cho người dùng với siêu thị máy tính  đầu tiên tại Hà Nội và tiên phong trong việc xây dựng website thương  mại điện tử của CMC đã đem lại một trải nghiệm mới cho những khách hàng  quan tâm đến dịch vụ tin học chất lượng cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 258, tokens 169, triggered by: token limit\n",
      "\u001b[32mTại thời điểm những năm  2000, máy tính CMS là máy tính hàng đầu Việt Nam nhờ ứng dụng các công  nghệ tiên tiến nhất, khả năng đảm bảo chất lượng qua dây chuyền sản xuất  hiện đại tại Khu công nghiệp Sài Đồng, quy trình kiểm soát chất lượng  ISO 9000-2000 cùng mạng lưới bảo hành rộng khắp toàn quốc và những phần  mềm có bản quyền được cài đặt trong máy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 259, tokens 165, triggered by: token limit\n",
      "\u001b[34mCác phần mềm như quản lý văn bản và quy trình công việc eDocMan, quản  lý thư viện điện tử và thư viện số iLib, quản lý đại học IU và những  phần mềm CMC đóng gói được ứng dụng rộng rãi. Các ứng dụng lớn trong  lĩnh vực tài chính bảo hiểm cũng như trong một số lĩnh vực khác đã được  phát triển thành công, đem lại sự tin cậy cho khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 260, tokens 178, triggered by: 0.25\n",
      "\u001b[35mCác sản phẩm và giải pháp này được phát triển từ những tri thức được  tích lũy nhiều năm của các chuyên gia đầu ngành trong lĩnh vực công nghệ  thông tin, kết hợp với công nghệ tiên tiến nhất của các đối tác hàng  đầu cùng khả năng chuyên nghiệp của đội ngũ CMC. Họ là những thanh niên  trẻ, có tri thức, có nhiệt huyết và khao khát thực hiện những điều có  ý nghĩa cho sự phát triển của đất nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 261, tokens 189, triggered by: 0.17\n",
      "\u001b[31mCMC Group, với quan niệm con  người là tài sản quý nhất của mình, đã tạo điều kiện cho tất cả mọi  người biến những giấc mơ của mình thành hiện thực. Vấn đề nguồn nhân lực công nghệ thông tin luôn là vấn đề lớn trong mọi  thời kỳ phát triển của lĩnh vực này, những công ty như CMC muốn có được  giá trị gia tăng trong sản phẩm và hệ thống của mình cần thu hút được  những người tài giỏi – đó là nhiệm vụ và thách thức của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 262, tokens 76, triggered by: 0.34\n",
      "\u001b[32mNhân sự  trong 10 năm đầu được tuyển chọn kỹ lưỡng: 50% cử nhân, 27% kỹ sư, 12%  thạc sỹ, 10% tiến sĩ, 1% thuộc đối tượng khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 263, tokens 150, triggered by: 0.40\n",
      "\u001b[34mTrong đó, nhiều nhân sự  chủ chốt được học từ các trường top đầu của Việt Nam và quốc tế. .Luôn cùng chung một trăn trở suy nghĩ: làm thế nào để khách hàng hài  lòng, làm thế nào để tập thể CMC phải dẫn đầu trong những lĩnh vực mình  tham gia, Ban Giám đốc CMC Group thường có những buổi trao đổi thân tình  và sôi nổi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 264, tokens 133, triggered by: 0.18\n",
      "\u001b[35mBan Lãnh đạo công ty đã nhanh chóng tập hợp những chuyên  viên giỏi, những kỹ sư tin học lành nghề và ham hiểu biết, sáng tạo;  triển khai nhanh chóng các hoạt động kinh doanh, lấy nghiên cứu khoa  học phục vụ cho kinh doanh và lấy kinh doanh để thúc đẩy nghiên cứu khoa  học.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 265, tokens 81, triggered by: 0.36\n",
      "\u001b[31mDoanh thu trong những năm đầu tiên có sự nhảy vọt với các doanh  nghiệp thời bấy giờ: 10 tỷ VNĐ (1994), 22 tỷ VNĐ (1995); 165 tỷ VNĐ (1998),  450 tỷ VNĐ (2003).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 266, tokens 176, triggered by: token limit\n",
      "\u001b[32mTập thể Người CMC Group đã cùng nhau xây dựng một môi trường làm việc  chuyên nghiệp, bầu không khí đoàn kết gắn bó có tác động lớn đến từng  nhân viên và nâng cao hiệu quả công việc của mỗi người. Các buổi đào  tạo, chia sẻ tri thức trong CMC là những hoạt động quan trọng để Người  CMC có thể bắt kịp nhanh chóng những tiến bộ của khoa học, công nghệ và  kỹ thuật.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 267, tokens 120, triggered by: token limit\n",
      "\u001b[34mBên cạnh đó, CMC Group còn đẩy mạnh các hoạt động văn hóa, thể thao,  văn nghệ nhằm nâng cao đời sống tinh thần cho nhân viên. CMC Group đã  trở thành ngôi nhà thứ hai, không chỉ với tập thể cán bộ nhân viên mà  còn với người thân và gia đình của họ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 268, tokens 148, triggered by: token limit\n",
      "\u001b[35mĐặc biệt trong những ngày kỷ niệm 10 năm thành lập CMC Group, Người CMC  đã có những phút giây bên nhau, bù lại phần nào những phút “lao tâm khổ  tứ”, để rồi những ngày sau đó họ lại miệt mài trên bàn làm việc, bên  chiếc máy tính, gửi gắm vào những sản phẩm của mình hàm lượng trí tuệ  Việt Nam cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 269, tokens 139, triggered by: token limit\n",
      "\u001b[31m.“Hội nghị Diên Hồng”  Năm 2003, bên cạnh những thành công vượt trội sau 10 năm thành lập, nhu  cầu đa dạng và biến động của thị trường đòi hỏi CMC cần xem xét toàn  diện lại chính mình, suy nghĩ về hướng đi, cách thức tổ chức, phát triển  phù hợp hơn ở giai đoạn tiếp theo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 270, tokens 88, triggered by: token limit\n",
      "\u001b[32mMột “Hội nghị” mà các anh ngày đó  thường nói vui là “Hội nghị Diên Hồng” của CMC, đã được tổ chức tại  Dream Hotel - Hạ Long với sự tham dự của lãnh đạo Công ty, lãnh đạo các  khối.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 271, tokens 141, triggered by: 0.11\n",
      "\u001b[34mThành phần tham dự gồm: anh Hà Thế Minh; anh Nguyễn Trung Chính;  anh Nguyễn Kim Cương; anh Tạ Hoàng Linh, anh Nguyễn Hồng Sơn; anh Nguyễn  Phước Hải; anh Phạm Hồng Hải; chú Phạm Ngọc Thụ; anh Lê Quang Thành;  anh Bùi Văn Hiệp và cán bộ quản lý chủ chốt của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 272, tokens 85, triggered by: 0.34\n",
      "\u001b[35mHội nghị diễn ra  2 ngày, trong khung cảnh tách biệt hẳn với gia đình và xã hội. Không  khí thảo luận tập trung, sôi nổi, nhiều phân tích và đóng góp tích cực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 273, tokens 75, triggered by: 0.20\n",
      "\u001b[31mTừ hội nghị này, nhiều quyết sách đã được đưa ra. Các nhóm vấn đề lớn  đã được đặt trọng tâm, ưu tiên cho suốt giai đoạn hoạt động tiếp theo:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 274, tokens 195, triggered by: 0.11\n",
      "\u001b[32mCon người; Giải pháp công nghệ; Hợp lực (Synergy). Khi đó tuy số lượng  đơn vị thành viên của CMC Group chưa nhiều nhưng trước tình hình thực  tế đặt ra một số thách thức, đòi hỏi CMC cần hợp lực để thực hiện được  nhiều chương trình phối hợp theo vùng địa lý giữa Hà Nội và Sài Gòn,  giữa các đơn vị CMC và CMS, CMS với Nhật Quang/Bluesky… Đây cũng là tiền  đề cho những Hội nghị chiến lược về sau của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 275, tokens 82, triggered by: 0.28\n",
      "\u001b[34mMười năm là một chặng đường ngắn với một đời người, một công ty; nhưng  là một chặng đường dài so với tốc độ phát triển như vũ bão của công nghệ  thông tin trong thời đại ngày nay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 276, tokens 157, triggered by: 0.10\n",
      "\u001b[35mMười năm với những bước đi dài và  vững chắc, CMC đã trở thành Tập đoàn tin học hàng đầu Việt Nam, được  công nhận với nhiều sản phẩm và dịch vụ công nghệ có giá trị, đội ngũ  nhân viên xuất sắc. CMC đã từng bước tạo dựng những “Di sản số” đầu  tiên, là tiền đề cho những bước đi tiếp theo và đóng góp vào sự phát  triển của Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 277, tokens 133, triggered by: 0.32\n",
      "\u001b[31m.  67  2000 - Bằng khen của Thủ tướng Chính phủ về những thành tích xuất sắc trong hoạt động kinh doanh, năng động sáng tạo, quản lý điều hành doanh nghiệp có hiệu quả năm 2000 cho Tổng Giám đốc Nguyễn Trung Chính (Quyết định số 690/TTg, cấp ngày 4/6/2001).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 278, tokens 148, triggered by: token limit\n",
      "\u001b[32m2000 - Giải thưởng Sao đỏ của TW đoàn TNCS HCM và Ủy ban TW Hội LH Thanh niên Việt Nam cho Giám đốc Nguyễn Trung Chính. (Quyết định số 178 QĐ-KTTWH cấp ngày 31/12/2000). 2003 - Bằng khen của UBND Thành phố cho Giám đốc Công ty CMC Nguyễn Trung Chính đạt danh hiệu Giám đốc doanh nghiệp giỏi năm 2003.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 279, tokens 176, triggered by: token limit\n",
      "\u001b[34m2003 - Bằng khen của UBND Thành phố cho Giám đốc Công ty CMC Nguyễn Trung Chính là một trong mười người đạt danh hiệu “Doanh nhân Thăng Long năm 2003”. 2003 - Giải thưởng Sao Khuê do Vinasa trao tặng cho các sản phẩm phần mềm: eDocman, iLib, IU. 2002 & 2003 - Cúp Sản phẩm Công nghệ Thông tin tiêu biểu. 2003 - Giải thưởng Sao Vàng Đất Việt do Hội các nhà doanh nghiệp trẻ Việt Nam trao tặng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 280, tokens 107, triggered by: 0.18\n",
      "\u001b[35m2002 & 2003 - Huy chương Vàng ICT Việt Nam dành cho Đơn vị phần cứng, phần mềm, tích hợp hệ thống có doanh số cao do HCA trao tặng tại Computerworld Expo. .66  DẤU MỐC LỊCH SỬ DẤU ẤN CHƯƠNG I 20/07/1991:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 281, tokens 123, triggered by: 0.26\n",
      "\u001b[31mThành lập Trung tâm ADCOM 26/05/1993: Thành lập Công ty TNHH HT&NT 08/07/1995: Đổi tên thành Công ty TNHH Máy tính Truyền thông CMC 10/1996: Thành lập Phòng Hệ thống và Phát triển phần mềm (sau này trở thành Trung tâm Phát triển Hệ thống & Trung tâm Phần mềm) 04/11/1996:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 282, tokens 169, triggered by: 0.34\n",
      "\u001b[32mThành lập Chi nhánh tại TP. Hồ Chí Minh: Công ty TNHH Dịch vụ - Thương mại Máy tính Truyền thông II 1998: Thành lập Trung tâm Tích hợp Hệ thống CMC SI và Trung tâm Giải pháp Phần mềm CMC Soft 08/04/1998: Thành lập Công ty TNHH Nhật Quang với Siêu thị bán lẻ và dịch vụ Blue Sky 17/05/1999: Thành lập TNHH Thế Trung (Sau này đổi tên thành Công ty TNHH CMS) 06/05/2003:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 283, tokens 158, triggered by: 0.29\n",
      "\u001b[34mKhánh thành Nhà máy và Dây chuyền sản xuất máy tính lớn nhất Việt Nam .Tiếp tục những câu chuyện về thành tựu phát triển từ 10 năm hình thành, Chương  2 – KHÁT bắt đầu với tham vọng mới của Tập đoàn CMC khi quyết định thay đổi  cách thức quản trị, chuyển đổi mô hình từ một nhóm các công ty thành viên  (Group of Companies) trở thành mô hình Tập đoàn (Corporation).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 284, tokens 67, triggered by: 0.33\n",
      "\u001b[35mVới việc kiện toàn bộ máy quản trị và chiến lược đúng đắn, từ doanh thu chỉ khoảng  450 tỷ đồng, CMC đã phát triển lên con số vài ngàn tỷ đồng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 285, tokens 139, triggered by: token limit\n",
      "\u001b[31mBên cạnh đó, CMC còn  mạnh dạn tham gia các lĩnh vực mới là Viễn thông và Bảo mật thông tin, từng  bước khẳng định vị thế top đầu trong ngành Công nghệ thông tin. Nhưng ngay trên đà phát triển, cơn sóng khủng hoảng ập đến, CMC chịu những  đòn giáng mạnh với khoản lỗ cả trăm tỷ đồng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 286, tokens 179, triggered by: token limit\n",
      "\u001b[32mGiữa những khó khăn và thách thức  của thị trường, những bài học lớn trong cách thức quản trị, “những người cầm lái”  của CMC đã nhìn nhận ra vấn đề và quyết tâm thay đổi. Toàn Tập đoàn bắt đầu quá trình tái cơ cấu tổ chức, tập trung xây dựng và phát  triển nguồn nhân lực chất lượng, tìm ra các hướng đi mới và tự tin vượt qua khủng  hoảng để phát triển mạnh mẽ trở lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 287, tokens 158, triggered by: token limit\n",
      "\u001b[34mLĩnh vực Tích hợp hệ thống phát triển mạnh mẽ, vươn lên vị trí dẫn đầu trong cung  cấp giải pháp cho thị trường giáo dục, tài chính công, khẳng định tên tuổi và vị thế  của CMC. Lĩnh vực Phát triển phần mềm có chỗ đứng vững chắc trong thị trường  giáo dục và quản lý tri thức với những sản phẩm phần mềm mang thương hiệu  CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 288, tokens 143, triggered by: token limit\n",
      "\u001b[35mLĩnh vực Viễn thông và Bảo mật thông tin đạt được nhiều thành tựu bước  đầu, khẳng định chiến lược đúng đắn. Chương 2- KHÁT chính là khát khao, là tinh thần không lùi bước, là ý chí liên tiếp  chinh phục những đỉnh cao mới của Người CMC trong 10 năm xây dựng đầy tự hào  (2003 – 2013).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 289, tokens 171, triggered by: token limit\n",
      "\u001b[31mChương 2 – KHÁT thể hiện quyết tâm, khát khao và từng bước chinh phục mục  tiêu “Hướng tới tương lai số” của CMC trong 10 năm xây dựng Tập đoàn (2003  – 2013) KHÁT .Chuyển đổi mô hình Tập đoàn  Chúng tôi đã có một quyết định hết sức khó khăn và có tính bước ngoặt khi  lựa chọn mô hình Công ty Cổ phần Tập đoàn thay cho mô hình TNHH 2  thành viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 290, tokens 200, triggered by: token limit\n",
      "\u001b[32mTôi và anh Hà Thế Minh đã có nhiều đêm không ngủ, nhiều ngày  quên ăn, tranh luận gay gắt trước khi quyết định lựa chọn, rất may là chúng  tôi đã có quyết định sáng suốt. Theo CT HĐQT/CTĐH Nguyễn Trung Chính.Hướng tới tương lai số - Tầm nhìn chiến lược  Sau 10 năm hình thành (1993 – 2003), với những bước đi vững chắc của  mình, CMC đã phát triển nhanh chóng và rực rỡ trong các lĩnh vực mà công  ty tham gia:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 291, tokens 138, triggered by: token limit\n",
      "\u001b[34mTích hợp hệ thống, Phát triển phần mềm, Sản xuất và Phân phối  thiết bị Công nghệ thông tin. Với những sản phẩm và dịch vụ chất lượng, CMC  đã vươn lên vị trí thứ 2 về doanh thu Tích hợp hệ thống, thành công trong  nhiều dự án Phát triển Phần mềm và trở thành thương hiệu máy tính lớn nhất  Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 292, tokens 148, triggered by: token limit\n",
      "\u001b[35mCMC đã khẳng định được vị thế quan trọng của mình trên thị  trường công nghệ thông tin, quy mô hoạt động mở rộng, tốc độ tăng trưởng  vượt trội, năm sau thường có mức tăng trưởng cao gấp đôi năm trước… Bên  cạnh đó, Công ty ngày càng nhận được sự tín nhiệm lớn của đối tác, khách  hàng và cộng đồng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 293, tokens 166, triggered by: 0.22\n",
      "\u001b[31mNếu như thời kì trước đó, đối tác chính của CMC là Acer  thì giai đoạn này, CMC được hàng loạt các các hãng công nghệ lớn bổ nhiệm  làm đại lý cấp cao, như: HP, Compaq, IBM (Lenovo)… Năm 2003, đứng trước thời kỳ phát triển mới, Cố Chủ tịch Hà Thế Minh và  Tổng Giám đốc Nguyễn Trung Chính (lúc bấy giờ) đưa ra chiến lược cho CMC:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 294, tokens 151, triggered by: token limit\n",
      "\u001b[32mTowards the digital future - Hướng tới tương lai số. Nếu như hiện nay, khái  niệm chuyển đổi số, thông tin số đã len lỏi vào đời sống của mỗi người dân và  trở nên quen thuộc, thì tại thời điểm đó, những khái niệm này vẫn còn rất xa  lạ. Điều này thể hiện tầm nhìn và chiến lược vượt thời đại của những người  sáng lập CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 295, tokens 196, triggered by: token limit\n",
      "\u001b[34mTương lai số với CMC chính là Cuộc sống số (digital life) ở tất cả các cá  nhân, gia đình và cộng đồng; là Nền tảng số (digital infrastructure) ở tất cả  các doanh nghiệp; là Hành chính số (digital servant) ở các tổ chức, cơ  quan và chính phủ. CMC tin rằng, đây là kim chỉ nam dẫn đường cho sứ mệnh  “xây dựng cây cầu công nghệ thông tin và viễn thông” nhằm xóa bỏ “khoảng  cách số” giữa Việt Nam và các nước phát triển trên thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 296, tokens 169, triggered by: 0.31\n",
      "\u001b[35mBên cạnh đó,  CMC cũng xác định cho mình mục tiêu mang lại sự hài lòng cho khách hàng  và cuộc sống phong phú về cả vật chất và tinh thần cho toàn thể cán bộ  nhân viên. KHÁT .Chuyển đổi mô hình Tập đoàn Bước ngoặt quyết định Khát vọng Hướng tới tương lai số là động lực giúp CMC liên tục phấn đấu để  phát triển mạnh mẽ ở ba trụ cột chiến lược:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 297, tokens 100, triggered by: token limit\n",
      "\u001b[31mCông nghệ thông tin, Viễn thông  và Kinh doanh điện tử; bằng việc không ngừng sáng tạo, đổi mới trong nghiên cứu, ứng dụng các giải pháp công nghệ cao, góp phần đưa xã hội Việt Nam tiến nhanh vào Thế giới số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 298, tokens 174, triggered by: token limit\n",
      "\u001b[32mĐứng trước định hướng chiến lược mới với các mục tiêu rất tham vọng và  thách thức, lãnh đạo CMC nhận ra: mặc dù các công ty đang phát triển  nhanh, tăng trưởng tốt nhưng lại có tính chất rời rạc, liên kết lỏng lẻo, chủ  yếu thông qua 2 cổ đông là anh Minh và anh Chính. Việc này có thể cản trở  CMC bứt phá, tiến nhanh, tiến xa và mở rộng quy mô đầu tư.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 299, tokens 89, triggered by: token limit\n",
      "\u001b[34mVì vậy, CMC cần  sự chuyển đổi bứt phá để cộng hưởng sức mạnh, hợp nhất thành một tổ chức  lớn và có sự liên kết bền chặt về chiến lược, tổ chức, tài chính và nhân lực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 300, tokens 141, triggered by: token limit\n",
      "\u001b[35mViệc chuyển đổi này sẽ giúp CMC phát triển tiềm lực mới về sản phẩm và dịch  vụ; tăng sức cạnh tranh trên thị trường quốc gia và khu vực; nâng cao khả  năng huy động vốn; tạo động lực làm việc, thu hút những nhà quản lý giỏi,  những chuyên gia tài năng cùng góp sức xây dựng CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 301, tokens 150, triggered by: token limit\n",
      "\u001b[31m74  Theo cố Chủ tịch Hà Thế Minh  Việc thực hiện nhũng thay đổi lớn trong công ty (liên quan đến cấu trúc, chiến  lược, cơ cấu chủ sở hữu và quy chế…) đều không dễ dàng. Cần có sự chuẩn bị  kỹ lưỡng, tuyên truyền thay đổi nhận thức và đặc biệt là cần sự quyết tâm rất  cao của Ban lãnh đạo công ty.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 302, tokens 149, triggered by: 0.35\n",
      "\u001b[32m.KHÁT  75  Vào thời điểm chuyển đổi mô hình công ty, hình thức quản trị tập đoàn kinh tế  đang được tranh luận rất nhiều nhưng lại không có một mô hình chuẩn mực,  nhất là cho khu vực doanh nghiệp tư nhân. Các công ty tư vấn có tầm cỡ như  E&Y, PwC cũng chỉ thực hiện được một phần trong bức tranh tổng thể này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 303, tokens 110, triggered by: token limit\n",
      "\u001b[34mChính vì thế, các anh lựa chọn con đường tự nghiên cứu đồng thời kết hợp  cùng chuyên gia tư vấn để đáp ứng tốt nhất những yêu cầu thực tế mà CMC  đang đối mặt cũng như những chiến lược mà CMC đã lựa chọn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 304, tokens 133, triggered by: 0.16\n",
      "\u001b[35mBan lãnh đạo công ty đã tranh luận rất gay gắt ngày này qua tháng khác để  nhận định “Mô hình nào phù hợp?” “Nên lựa chọn mô hình công ty trách  nhiệm hữu hạn hay công ty cổ phần/công ty đại chúng?”, “Điểm lợi của các  loại hình công ty này là gì?”, “ Nó giúp CMC phát triển ra sao?”. . .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 305, tokens 150, triggered by: 0.35\n",
      "\u001b[31mNhững tập  tài liệu phân tích chất chồng ngày một cao trên bàn làm việc của anh Minh  và anh Chính. “Chúng tôi đã có một quyết định hết sức khó khăn và có tính bước ngoặt khi  lựa chọn mô hình công ty Cổ phần Tập đoàn thay cho mô  hình công ty TNHH  & Quyết tâm của Người lãnh đạo sự đấu tranh với chính mình.2 thành viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 306, tokens 201, triggered by: token limit\n",
      "\u001b[32mTôi và anh Hà Thế Minh đã có nhiều đêm không ngủ, nhiều ngày  quên ăn, tranh luận gay gắt trước khi quyết định lựa chọn, rất may là chúng  tôi đã có quyết định sáng suốt.” (Anh Nguyễn Trung Chính nhớ lại) Khi thực hiện chuyển đổi, đối với nhà sáng lập CMC lúc bấy giờ, bên cạnh  những khó khăn về hệ thống, khó khăn lớn nhất chính là sự thay đổi về nhận thức, là sự đấu tranh ở “chính mình”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 307, tokens 115, triggered by: 0.31\n",
      "\u001b[34mAnh Chính tâm sự: “Mình là người  có tính sở hữu rất cao, tính kiểm soát của mình lớn. Ở mô hình công ty TNHH,  mình toàn quyền quyết định. Nhưng khi có nhiều thành viên tham gia hơn, trở thành công ty đại chúng thì cơ chế ra quyết định phải khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 308, tokens 91, triggered by: token limit\n",
      "\u001b[35mThay vì tự quyết định như trước kia thì bây giờ phải dàn xếp, thương thảo, thảo luận,  phải làm sao thuyết phục được tất cả mọi người cùng đồng thuận cho một  quyết định nào đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 309, tokens 235, triggered by: token limit\n",
      "\u001b[31mKhi đấy, mình phải đấu tranh với chính mình, đôi lúc mình  e dè mất quyền lực, thậm chí có thể mất quyền kiểm soát công ty.”  Ngoài ra, khi trở thành một công ty đại chúng, tính kiểm soát của Nhà nước  và yêu cầu về sự công khai minh bạch rất cao, do đó cần có sự chuẩn mực  trong các hoạt động quản trị. Điều này đòi hỏi công ty phải có đủ những năng  lực và điều kiện nhất định cả về trình độ, tư duy và sự hiểu biết… thì mới dám  chấp nhận mô hình kinh tế mới, mô hình phát triển mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 310, tokens 80, triggered by: token limit\n",
      "\u001b[32mThêm vào đó, ngoài  việc chia sẻ quyền lợi của bản thân với người khác, nhà sáng lập công ty cần  phải chịu trách nhiệm đảm bảo quyền lợi cho các cổ đông tham gia.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 311, tokens 125, triggered by: token limit\n",
      "\u001b[34mViệc đưa ra quyết định không phải điều dễ dàng nhưng đứng trước sự cần  thiết phải chuyển đổi và mong muốn tập hợp đội ngũ nhân sự tài năng,  .chung một chí hướng đưa CMC lên một tầm cao mới đã khiến những người  lãnh đạo quyết tâm chuyển đổi mô hình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 312, tokens 172, triggered by: 0.33\n",
      "\u001b[35mTừ năm 2005 - 2006, CMC chính thức khởi động tái cấu trúc các công ty và  thành lập mô hình Tập đoàn (theo hình thức công ty mẹ - con), thay đổi  phương thức quản lý: từ đầu tư của các cá nhân sang mô hình quản lý đầu tư  tập trung. Ngay lập tức, Lãnh đạo của các Công ty/ Đơn vị được phân công  chỉ đạo từng tổ công tác, thực hiện quyết liệt từng nhiệm vụ đã đặt ra.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 313, tokens 62, triggered by: 0.29\n",
      "\u001b[31mNgày 2/7/2007, Công ty TNHH Máy tính Truyền thông CMC chính thức chuyển  đổi thành Công ty Cổ phần Tập đoàn Công nghệ CMC (CMC Corporation).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 314, tokens 129, triggered by: token limit\n",
      "\u001b[32mTập đoàn có vốn điều lệ 300 tỷ đồng, bao gồm các công ty thành viên có mối liên kết chặt chẽ với nhau: Công ty Tích hợp hệ thống CMC (CMC SI),  Công ty Máy tính CMS, Công ty Giải pháp Phần mềm CMC (CMC Soft) hoạt  động dưới sự quản trị và định hướng của CMC Corporation.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 315, tokens 178, triggered by: token limit\n",
      "\u001b[34mKhi chuyển đổi mô hình, với trăn trở xây dựng tinh thần làm chủ cho tất cả  thành viên và tập hợp đội ngũ tài năng, cùng chung mục tiêu và sứ mệnh;  CMC đã phát hành cổ phiếu cho 13 cổ đông sáng lập viên đầu tiên - 13 lãnh  đạo của CMC. Đây chính là quá trình thay đổi nhận thức quan trọng và là tiền  đề phát triển chương trình ESOP cho cán bộ nhân viên được CMC thực hiện về  sau này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 316, tokens 113, triggered by: token limit\n",
      "\u001b[35mKHÁT  77  Hình ảnh: 13 lãnh đạo của Công ty theo mô hình ESOP.Quá trình chuyển đổi mô hình của CMC được coi là cuộc “đại phẫu thuật”  mang đến thành công lớn, là một bước ngoặt chiến lược quan trọng, từ đó  mới có Tập đoàn CMC ngày nay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 317, tokens 141, triggered by: token limit\n",
      "\u001b[31mThay vì hoạt động còn rời rạc trước đó, sau khi tái cấu trúc, các công ty liên  kết chặt chẽ với nhau phát triển sản phẩm dịch vụ, cùng tham gia vào các dự  án, hỗ trợ nhau chinh phục các gói thầu lớn của Chính phủ, Bộ Tài chính, Bộ  Giáo dục cũng như các doanh nghiệp lớn trong nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 318, tokens 124, triggered by: token limit\n",
      "\u001b[32mNgay sau khi chuyển đổi, CMC như được tiếp thêm sức mạnh mới và bắt đầu  phát triển siêu nóng với những thành tích gây ấn tượng. Năm 2007, Tập đoàn  đã tăng trưởng vượt trội với doanh thu tăng gấp đôi và lợi nhuận gấp gần 4  lần so với năm 2006.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 319, tokens 136, triggered by: token limit\n",
      "\u001b[34mNgoài ra, đến 2008, nhân dịp Kỷ niệm 15 năm thành lập, doanh thu Tập đoàn  CMC  ghi nhận tăng gấp 230 lần, lợi nhuận tăng gấp 300 lần, nhân lực tăng  gấp 70 lần và vốn sở hữu tăng gấp 1,300 lần so với khi thành lập. Sức mạnh hợp lực sau chuyển đổi Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 320, tokens 188, triggered by: token limit\n",
      "\u001b[35mLễ kỷ niệm 15 năm thành lập Tập đoàn CMC.Chìa khóa mở cánh cửa huy động vốn  Ngay từ những ngày đầu chuyển đổi mô hình trở thành công ty Cổ phần,  những người lãnh đạo CMC đã chuẩn bị các thủ tục để đưa CMC trở thành  công ty đại chúng, niêm yết trên thị trường chứng khoán để có thể huy động  nguồn vốn từ cộng đồng đầu tư, tạo nền tảng để mở rộng quy mô và phát  triển Tập đoàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 321, tokens 194, triggered by: token limit\n",
      "\u001b[31mQuá trình chuẩn bị niêm yết trên sàn chứng khoán được thực hiện từ năm  2007 với sự đồng hành của Công ty Cổ phần Chứng khoán Bảo Việt trong việc  tư vấn định giá doanh nghiệp, tư vấn phát hành cổ phiếu, tư vấn niêm yết  chứng khoán và bảo lãnh phát hành. Ngày 17/12/2009, Sở giao dịch Chứng khoán Thành phố Hồ Chí Minh đã chấp  thuận nguyên tắc niêm yết hơn 63,5 triệu cổ phiếu của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 322, tokens 159, triggered by: token limit\n",
      "\u001b[32mTháng  1/2010, CMC chính thức niêm yết và trở thành một trong những công ty công  nghệ tiên phong trên sàn giao dịch chứng khoán với mã CMG. Với 4 cổ đông  cũ, sau sự kiện này, CMC đã có hơn 1,000 cổ đông cùng 3 cổ đông chiến lược  lớn là Tập đoàn Geleximco, Tập đoàn Bảo Việt cùng Ngân hàng Nông nghiệp  và Phát triển Nông thôn Agribank.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 323, tokens 135, triggered by: token limit\n",
      "\u001b[34mDấu mốc chuyển đổi mô hình Tập đoàn và niêm yết trên thị trường chứng  khoán là một “bệ phóng quan trọng trên bước đường phát triển của Tập đoàn  CMC” (theo cố Chủ tịch Hà Thế Minh). Điều này giúp cho CMC bứt phá và trở  thành công ty lớn về Công nghệ Thông tin tại thị trường Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 324, tokens 94, triggered by: token limit\n",
      "\u001b[35mSự tăng  trưởng tốc độ cả về quy mô, lĩnh vực, số lượng, chất lượng trong giai đoạn  này đã tạo nên tiền đề quan trọng cho sự phát triển ở các giai đoạn tiếp theo. KHÁT  79  Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 325, tokens 190, triggered by: 0.24\n",
      "\u001b[31mCMC chính thức niêm yết trên sàn chứng khoán.Từng bước  Năng lực Không chỉ phát triển mạnh mẽ về quy mô và thị trường, CMC bước vào giai  đoạn mới với sự quyết tâm nâng cao năng lực, hiệu suất làm việc nhằm  mang lại những sản phẩm, dịch vụ uy tín và chất lượng tới khách hàng. Các  hệ thống, quy trình làm việc được xây dựng và áp dụng bài bản giúp người  CMC làm việc chuyên nghiệp và hiệu quả.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 326, tokens 168, triggered by: 0.33\n",
      "\u001b[32m.Đối với một doanh nghiệp, khi mô hình công ty còn nhỏ, anh em có thể “đóng  cửa bảo nhau”, tự đánh giá, tự kiểm tra. Nhưng để vươn tầm cao mới, mọi thứ  cần được hệ thống hóa, từ chiến lược đến hệ thống chính sách, quản trị chất  lượng công việc, quản trị quy trình để đưa ra những sản phẩm tốt nhất cho  khách hàng đồng thời nâng cao năng suất làm việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 327, tokens 169, triggered by: token limit\n",
      "\u001b[34mHệ thống ấy không thể  “con hát mẹ khen hay” mà cần đảm bảo theo những tiêu chuẩn uy tín quốc  tế, được kiểm nghiệm và đánh giá bởi một tổ chức uy tín bên ngoài. Trong quá trình thực hiện tái cấu trúc và chuyển đổi mô hình Tập đoàn, việc  xây dựng hệ thống quản trị chất lượng theo tiêu chuẩn quốc tế là một bước đi vô cùng quan trọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 328, tokens 199, triggered by: token limit\n",
      "\u001b[35mBan lãnh đạo CMC đã quyết tâm chinh phục ISO 9001-2000 từ những năm 2003. Đây là một trong những tiêu chuẩn đánh  giá phổ biến nhất trên toàn thế giới, đưa ra các yêu cầu về hệ thống quản lý  chất lượng trong tổ chức. Lần đầu chinh phục tiêu chuẩn quốc tế  ISO 9001 - 2000 Theo nhận định của anh Nguyễn Trung Chính Việc áp dụng và đạt được chứng nhận ISO 9001:2000 nằm trong định hướng  phát triển lâu dài của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 329, tokens 145, triggered by: token limit\n",
      "\u001b[31mViệc áp dụng này góp phần nâng cao ý thức của  nhân viên, khẳng định thêm niềm tin cho khách hàng đối với các các sản  phẩm, dịch vụ của công ty và là cơ sở cho CMC trong việc cam kết phục vụ  phục vụ khách hàng tốt hơn nữa theo các chuẩn mực quốc tế, cũng như làm  tăng tính cạnh tranh của công ty trong quá trình hội nhập.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 330, tokens 188, triggered by: 0.18\n",
      "\u001b[32mKHÁT .Không khí chuẩn bị  rộn ràng, háo hức  82  Lần đầu tiên làm ISO, trái với suy nghĩ thông thường sẽ gặp nhiều khó khăn thì  ngược lại, anh em CMC rất hào hứng. Với những gì đã đạt được trong giai  đoạn trước đó,  Người CMC tin rằng tiêu chuẩn ISO, những quy trình, chính  sách, hệ thống quản lý đúng đắn sẽ giúp CMC làm việc chuyên nghiệp và  hiệu quả hơn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 331, tokens 65, triggered by: 0.21\n",
      "\u001b[34mSau khi nghiên cứu và làm việc với đơn vị tư vấn, anh Chính, anh Minh cùng  các lãnh đạo chủ chốt đã thống nhất kế hoạch thực hiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 332, tokens 51, triggered by: 0.32\n",
      "\u001b[35mChủ trương vừa  được đưa ra, toàn bộ các hoạt động ngay lập tức được triển khai đồng bộ  trong tất cả công ty:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 333, tokens 129, triggered by: 0.22\n",
      "\u001b[31mCMC SI, CMC SOFT, CMS. Bộ phận QA, Quản lý chất lượng ngay lập tức được thành lập, các quy trình  chính sách được liệt kê và đánh giá, hệ thống văn bản được đưa ra và rà soát  kỹ lưỡng, thiếu chỗ nào bổ sung ngay chỗ đó, chưa chuẩn chỗ nào thì chuẩn  hóa ngay chỗ đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 334, tokens 115, triggered by: token limit\n",
      "\u001b[32mCông việc cứ thế cuốn chiếu theo từng đơn vị. Để đảm bảo mọi cán bộ nhân viên đều hiểu đúng - làm đúng, công ty tổ chức  các buổi đào tạo bài bản, hướng dẫn nhận thức chung về ISO cũng như  hướng dẫn chi tiết cách làm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 335, tokens 155, triggered by: token limit\n",
      "\u001b[34mMỗi cá nhân trong toàn công ty sau khi đào tạo đều phải hoàn thành bài test  trong vòng 60 phút để đảm bảo hiểu được lý do cần xây dựng quy trình, hệ  thống chất lượng; nắm được sổ tay chất lượng của công ty, các bước thực  hiện, địa chỉ truy cập tài liệu tham khảo, … Các bài test được in ra giấy, ký tên  và nộp cẩn thận cho Phòng Quản lý chất lượng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 336, tokens 113, triggered by: 0.08\n",
      "\u001b[35mNếu có cá nhân, phòng ban  nào không hiểu, Phòng Quản lý chất lượng sẽ giải thích, hướng dẫn cụ thể và  cung cấp thêm tài liệu tham khảo. Từng tập tài liệu liên tiếp được gửi về,  không khí rộng ràng, tấp nập khắp các văn phòng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 337, tokens 104, triggered by: token limit\n",
      "\u001b[31m.KHÁT  83  Hình ảnh: Không khí chuẩn bị tài liệu, đào tạo, hướng dẫn về ISO tại CMC.Kỷ luật - Yếu tố thành công 84  Bộ phận Quản lý chất lượng làm việc hết năng suất, xác định bộ phận, cá  nhân làm sai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 338, tokens 192, triggered by: 0.19\n",
      "\u001b[32mTừng bản báo cáo được ghi chép lại đều có phân tích rất rõ từ  những công việc nhỏ của cá nhân và bộ phận: họ đã làm như thế nào, kết quả  là gì, sai ở đâu và đề nghị sửa chi tiết. Đơn vị hoặc cá nhân nào không thực  hiện đúng yêu cầu trong phiếu đánh giá sẽ bị “xử trảm” ngay lập tức. Toàn bộ công việc phải theo quy trình, biểu mẫu. Từng email được gửi qua lại,  ký nhận sau kiểm tra.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 339, tokens 73, triggered by: 0.18\n",
      "\u001b[34mMột điều ngạc nhiên và rất đỗi tự hào đó là anh em  không thấy khó chịu mà trái lại, rất tập trung làm việc, đánh giá, điều chỉnh  và hoàn thiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 340, tokens 177, triggered by: 0.29\n",
      "\u001b[35mĐến năm 2006, CMC vinh dự nhận chứng chỉ Hệ thống Quản lý chất lượng  theo tiêu chuẩn ISO 9001:2000 về Tích hợp hệ thống và Phát triển Phần mềm  do tổ chức chứng nhận TÜV Rheinland Group (CHLB Đức) cấp. Để có thể hoàn thiện và chuẩn hóa tất cả các quy trình và hoạt động theo  đúng bộ tiêu chuẩn ISO 9001-2000 trong một thời gian thì kỷ luật là yếu tố  sống còn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 341, tokens 74, triggered by: token limit\n",
      "\u001b[31mTừ lãnh đạo đến quản lý, CBNV tại CMC đều rất quyết liệt. Công ty  đưa ra chính sách kỷ luật có thể nói là “mạnh tay” khi kiểm tra đánh giá.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 342, tokens 145, triggered by: token limit\n",
      "\u001b[32mViệc áp dụng và đạt được chứng nhận ISO 9001:2000 nằm trong định hướng  phát triển lâu dài của Công ty CMC trong việc thống nhất được cách làm chung,  đảm bảo cung cấp sản phẩm, dịch vụ đồng nhất theo tiêu chuẩn Quốc tế, thỏa  mãn và cố gắng vượt hơn nữa so với yêu cầu, mong đợi của khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 343, tokens 197, triggered by: token limit\n",
      "\u001b[34mViệc  áp dụng này góp phần nâng cao ý thức của nhân viên, khẳng định thêm niềm  tin cho khách hàng đối với các các sản phẩm, dịch vụ của Công ty cũng như  làm tăng tính cạnh tranh của Công ty trong quá trình hội nhập. Phát biểu của anh Nguyễn Trung Chính tại sự kiện nhận chứng chỉ ISO.KHÁT  85  Ngay từ những ngày đầu hoạt động, CMC luôn tạo dựng văn hóa công bằng,  tôn trọng năng lực và sự cống hiến của từng CBNV.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 344, tokens 200, triggered by: token limit\n",
      "\u001b[35mHàng năm, công ty đều có  đánh giá A-B-C-D để tôn vinh và khen thưởng xứng đáng những cá nhân, bộ  phận tiêu biểu, có nhiều đóng góp cho công ty. Tuy nhiên, những năm 1995 -  1999, CMC ghi nhận kết quả đánh giá chủ yếu qua mô tả công việc, qua thỏa  ước thi đua và đôi lúc bị ảnh hưởng bởi những kết quả gần nhất với thời điểm  đánh giá, thiếu góc nhìn tổng quan trong cả một quá trình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 345, tokens 128, triggered by: 0.19\n",
      "\u001b[31mBan lãnh đạo quyết định cần có một hệ thống ghi nhận xuyên suốt quá trình  làm việc. Anh Hà Thế Minh sau những đêm dài thao thức, đọc và nghiên cứu,  quyết định đưa KPI vào CMC với phương châm “đóng góp nhiều hưởng nhiều,  đóng góp ít hưởng ít”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 346, tokens 58, triggered by: 0.31\n",
      "\u001b[32mViệc chuẩn bị từ những năm 2003 và nhận được chứng  chỉ ISO vào năm 2006 đã giúp hệ thống quản trị công ty hoàn thiện và đầy đủ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 347, tokens 70, triggered by: 0.19\n",
      "\u001b[34mViệc này giúp cho các tiêu chí đánh giá KPI được rõ ràng hơn. Các chỉ tiêu  được giao theo quý, theo tháng, đo trong kỳ chứ không phải cuối kỳ nữa.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 348, tokens 89, triggered by: 0.38\n",
      "\u001b[35mKhi  đưa một phương pháp, công cụ mới vào sẽ không hề đơn giản. Các tài liệu lại được phân tích và đưa ra. Bản thân anh Minh là người đứng ra  đào tạo, hướng dẫn tận tình cho đội ngũ quản lý.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 349, tokens 61, triggered by: 0.28\n",
      "\u001b[31mTừ đó các quản lý sẽ đào tạo  cặn kẽ xuống từng cán bộ nhân viên, đảm bảo không bỏ sót một ai không  biết, không hiểu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 350, tokens 56, triggered by: 0.27\n",
      "\u001b[32mTheo lời anh em CMC miền Nam kể lại: “Ngày đó, đích thân  anh Minh bay vào tận vào Sài Gòn để đào tạo mấy lớp KPI.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 351, tokens 121, triggered by: 0.28\n",
      "\u001b[34mAnh rất giản dị,  nhiệt huyết và say sưa hướng dẫn cho mọi người trong mỗi buổi chia sẻ”. KPI - Tính chuyên nghiệp công bằng dần hoàn thiện.Những bộ KPI  đầu tiên Trong những bộ KPI hoàn chỉnh đầu tiên, khung tiêu chí rất đơn giản gồm 3 phần:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 352, tokens 220, triggered by: token limit\n",
      "\u001b[35mKỷ luật lao động (10%) Trách nhiệm công việc (10%) Chất lượng công việc (80%) Bên cạnh việc đảm bảo chất lượng công việc, việc tuân thủ kỷ luật lao động,  trách nhiệm với công việc như: không vi phạm thời gian làm việc, tuân thủ  quy định của công ty, thực hiện đúng tiến độ công việc (liệt kê rõ số lượng  công việc, số lượng báo cáo chậm hàng tháng) được đưa vào đánh giá. Đây  cũng là cơ sở hình thành thói quen và tạo nên giá trị Cam kết của Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 353, tokens 127, triggered by: 0.29\n",
      "\u001b[31mĐến khoảng năm 2007, sau khi hoàn thiện quá trình tái cấu trúc, CMC mới áp  dụng BSC vào đánh giá để đảm bảo sự phát triển của công ty được cân bằng  và đúng định hướng chiến lược theo 4 khía cạnh: Tài chính - Khách hàng -  Quy trình nội bộ - Học hỏi & phát triển.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 354, tokens 128, triggered by: token limit\n",
      "\u001b[32mTuy khi bắt đầu áp dụng đánh giá hiệu  suất bài bản gặp một số khó khăn: khối lượng công việc tăng lên vì những  công đoạn phát sinh, việc đo đếm kiểm tra chặt chẽ hơn dẫn đến có đơn vị  đạt, có đơn vị không đạt khiến tâm lý lo lắng, e ngại xuất hiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 355, tokens 173, triggered by: token limit\n",
      "\u001b[34mTuy nhiên, “với  đội ngũ những người trẻ, kết quả làm việc tốt cùng hàng loạt các chương  trình truyền động lực, thái độ nghiêm túc và việc tuân thủ kỷ luật đã tạo đà  để việc quá trình đánh giá công việc tại CMC như luồng nước mạnh dần” –  Anh Nguyễn Hồng Sơn – người lãnh đạo được giao phụ trách triển khai chi tiết  chương trình KPI tại CMC nhớ lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 356, tokens 144, triggered by: token limit\n",
      "\u001b[35mThông qua việc triển khai hệ thống kiểm soát chất lượng trong toàn Tập  đoàn, hoàn thiện hệ thống quản trị nhân sự thông qua BSC và KPI, Ban lãnh  đạo CMC dễ dàng theo dõi được tình hình, đánh giá được toàn diện hệ thống,  chất lượng nhân sự, quy trình để đưa ra những điều chỉnh kịp thời, nâng cao  hiệu suất của tổ chức.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 357, tokens 193, triggered by: 0.40\n",
      "\u001b[31mBên cạnh đó, BSC và KPI còn là công cụ khách quan  giúp mỗi cán bộ nhân viên CMC vừa thấy được bức tranh tổng thể, vừa thấy  rõ vai trò của cá nhân trong kết quả và sự thành công chung của công ty. Điều  này đã giúp CMC củng cố hệ thống và tạo đà cho phát triển bùng nổ vào giai  đoạn tiếp theo. .CMC bước vào giai đoạn tiếp theo với nhiều hoài bão và ước mơ vươn xa  hơn nữa trong lĩnh vực Công nghệ thông tin.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 358, tokens 148, triggered by: token limit\n",
      "\u001b[32mVới thế mạnh và những năng  lực tích lũy trong giai đoạn xây dựng hình thành, các lĩnh vực truyền thống  của CMC bao gồm: Tích hợp hệ thống, Phát triển Phần mềm, Sản xuất &  Phân phối đã cùng tạo nền móng vững chắc, giúp CMC khẳng định vị thế  trên thị trường và tự tin vững bước trong thập kỷ mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 359, tokens 135, triggered by: token limit\n",
      "\u001b[34m.Nếu ở những năm 1996 của giai đoạn trước, khi Tích hợp hệ thống chỉ là cụm  từ mới mẻ trong ngành công nghệ thông tin tại Việt Nam, những người  thuyền trưởng của CMC đã quyết tâm chinh phục lĩnh vực tiềm năng này  cùng tâm niệm “Tuổi trẻ có một đặc quyền là được thử, được sai và không sợ  sai”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 360, tokens 182, triggered by: 0.30\n",
      "\u001b[35mThì ngay khi CMC bước vào giai đoạn mới, sự phát triển vững mạnh của  lĩnh vực Tích hợp hệ thống đã khẳng định quyết tâm ngày ấy của những  người đứng đầu CMC là hoàn toàn đúng đắn. Với tiền thân là phòng Kinh doanh dự án, CMC đã đặt những viên gạch nền  móng đầu tiên trong lĩnh vực kinh doanh Tích hợp hệ thống cùng mục tiêu trở  thành một đơn vị tích hợp chuyên nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 361, tokens 246, triggered by: token limit\n",
      "\u001b[31mNăm 1999, Trung tâm Tích hợp hệ  thống được thành lập. Cùng nhiều kinh nghiệm được tích lũy khi triển khai  lĩnh vực này từ sớm, CMC đã trở thành đối tác trọng yếu của các hãng Công  nghệ thông tin – Viễn thông hàng đầu thế giới, đồng thời là doanh nghiệp  luôn đi tiên phong và thành công trong các giải pháp hạ tầng công nghệ  thông tin cũng như các giải pháp chuyên ngành. Đến những năm đầu tiên  của giai đoạn 2003 – 2013, CMC đã trở thành một trong những nhà cung cấp  giải pháp và dịch vụ Tích hợp hệ thống hàng đầu tại Việt Nam khi ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 362, tokens 159, triggered by: token limit\n",
      "\u001b[32mNăm 2006, trong quá trình tái cơ cấu và chuyển đổi mô hình Tập đoàn, Trung  tâm Tích hợp hệ thống được chuyển thành Công ty TNHH Tích hợp hệ thống  CMC (CMC SI). CMC SI là một trong ba thành viên lớn nhất của Tập đoàn  Công nghệ CMC thời kỳ này, là đầu mối của CMC trong cung cấp giải pháp  Công nghệ thông tin - Viễn thông tổng thể và trọn gói.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 363, tokens 286, triggered by: token limit\n",
      "\u001b[34mVới mục tiêu đem đến  cho khách hàng các hệ thống thông tin hiệu quả nhất, CMC SI cung cấp một  tập hợp các sản phẩm và dịch vụ đa dạng từ cung cấp thiết bị, tư vấn xây  dựng giải pháp đến cung cấp các giải pháp tổng thể có hàm lượng công  nghệ và kỹ thuật cao tới khách hàng bao gồm: các hệ thống thông tin điện tử,  các dịch vụ đào tạo và chuyển giao công nghệ tiên tiến trên thế giới, các dịch  vụ sau bán hàng trên toàn quốc… Những “người nhóm lửa” mát tay cho nghề Tích hợp hệ thống CMC ngày ấy đã  xây dựng cho mình đội ngũ có năng lực, được đào tạo bài bản về chuyên môn  và quản lý dự án.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 364, tokens 201, triggered by: token limit\n",
      "\u001b[35mCác thành viên CMC SI luôn phát huy lợi thế nhiều kinh  nghiệm trong các dự án lớn, có độ phức tạp cao về nghiệp vụ đồng thời  thường KHÁT .Phát triển phần mềm - Tiếp nối hành trình  thực hiện sứ mệnh cao cả xuyên “nằm vùng” nghiên cứu sâu về nghiệp vụ của khách hàng, đau đáu  cùng mong muốn xây dựng những giải pháp thiết thực nhất, bám sát nhu  cầu thực tế của khách hàng để đem đến những sản phẩm hiệu quả.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 365, tokens 234, triggered by: token limit\n",
      "\u001b[31mVới kinh nghiệm dày dạn và năng lực vững chắc cùng tiềm lực mạnh mẽ, tinh  thần không ngừng nâng cao tính chuyên nghiệp của mình, CMC đã cắm lá cờ  tiên phong dẫn đầu lĩnh vực Tích hợp hệ thống, chiếm lĩnh các thị trường  trọng điểm có mức đầu tư và ứng dụng công nghệ thông tin lớn nhất Việt Nam: khối Chính phủ, thị trường Tài chính – Bảo hiểm – Ngân hàng, thị  trường Giáo dục và không ngừng khai thác thế mạnh sang các thị trường  tiềm năng khác như khối Doanh nghiệp vừa và nhỏ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 366, tokens 168, triggered by: token limit\n",
      "\u001b[32mSong hành cùng sự phát triển lớn mạnh của CMC, những cái tên như eDoc- man (Giải pháp quản lý tài liệu và quy trình công việc), iLib (Giải pháp tổng  thể cho thư viện), Intelligence University (Giải pháp tổng thể cho hệ thống  quản lý thông tin tại trường Đại học, Cao đẳng)… đã trở thành người bạn  đồng hành quen thuộc với thị trường giáo dục, quản lý thông tin doanh  nghiệp tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 367, tokens 82, triggered by: token limit\n",
      "\u001b[34mTrong giai đoạn này, lĩnh vực Tích hợp hệ thống CMC luôn giữ mức tăng  trưởng mạnh mẽ về doanh thu và thị phần, là hoạt động chiến lược và là  “đầu tàu” của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 368, tokens 167, triggered by: token limit\n",
      "\u001b[35mSự nỗ lực bền bỉ đã giúp CMC SI tự tin trở thành nhà cung  ứng dịch vụ công nghệ thông tin lớn cho thị trường Ngân hàng (theo Báo cáo  tài chính CMC năm 2007), đưa CMC đứng thứ 2 trong Top 5 Doanh nghiệp  Tích hợp hệ thống hàng đầu Việt Nam (theo đánh giá của HCA - 2009) và  chiếm 16% thị phần Tích hợp hệ thống toàn Việt Nam (theo BVSC- 2009).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 369, tokens 159, triggered by: 0.41\n",
      "\u001b[31mĐây là những thành quả cho sự nỗ lực và kiên trì của đội ngũ Tích hợp hệ  thống CMC, là minh chứng cho đường lối đúng đắn của những người đứng  đầu CMC và là lời hồi đáp ngọt ngào cho sự dũng cảm nắm lấy “đặc quyền  tuổi trẻ” để bắt đầu hướng đi mới cho CMC từ những ngày xưa ấy. .KHÁT  91  Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 370, tokens 117, triggered by: 0.30\n",
      "\u001b[32mMột số sản phẩm lĩnh vực Phát triển phần mềm.92  Ngoài các giải pháp phần mềm cho thị trường truyền thống, trong giai đoạn  này, CMC bắt đầu nỗ lực thúc đẩy thị trường gia công phần mềm với mục tiêu  chinh phục các khách hàng lớn ở Nhật Bản và Châu Âu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 371, tokens 105, triggered by: token limit\n",
      "\u001b[34mCơ duyên đưa CMC hợp tác với đất nước khởi nguồn của những câu truyện cổ  Andersen – Đan Mạch là Dự án Danida - dự án của chính phủ Đan Mạch tài  trợ cho các doanh nghiệp Việt Nam để phát triển kinh doanh ở cả hai nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 372, tokens 181, triggered by: token limit\n",
      "\u001b[35mCái bắt tay của Segmenta và CMC được thực hiện vào ngày 24/04/2008 với  việc thành lập Công ty Cổ phần Liên doanh Segmenta – CMC, đưa CMC trở  thành công ty đầu tiên tại Việt Nam có liên doanh xuất khẩu phần mềm cho  thị trường Châu Âu với đối tác Đan Mạch. Segmenta – CMC đã đóng vai trò  quan trọng trong việc cung cấp nguồn lực để tư vấn, triển khai giải pháp ERP  tại Việt Nam và các thị trường nước ngoài.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 373, tokens 109, triggered by: token limit\n",
      "\u001b[31mBên cạnh đó, năm 2009, CMC thành lập Công ty Phần mềm Thống Nhất tại  Nhật Bản (dựa trên cơ sở liên doanh giữa CMC Soft và Jupiter Com, Ltd) và  Công ty CMC Blue France tại Pháp để nâng cao chất lượng dịch vụ và tăng  doanh thu từ outsourcing. Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 374, tokens 168, triggered by: token limit\n",
      "\u001b[32mLễ ra mắt Cô.KHÁT  93  Định hướng quyết tâm mang tới cho khách hàng những sản phẩm và dịch vụ  với giá trị cao nhất dựa trên công nghệ tiên tiến hàng đầu trên thế giới cùng  đội ngũ sáng tạo, tâm huyết, có nghiệp vụ chuyên môn cao đã đưa CMC trở  thành Top 2 Công ty Phần mềm hàng đầu Việt Nam (theo bình chọn của HCA  liên tục từ năm 2007 – 2011).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 375, tokens 91, triggered by: token limit\n",
      "\u001b[34mLĩnh vực Phát triển phần mềm của CMC dẫn  đầu trong thị trường phần mềm đóng gói tại thị trường giáo dục, quản lý  thông tin doanh nghiệp (chiếm khoảng 40% thị phần so với các sản phẩm  cùng loại).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 376, tokens 175, triggered by: token limit\n",
      "\u001b[35mHành trình rực rỡ của lĩnh vực Phát triển phần mềm tại CMC đã  được tiếp nối, giúp cánh cửa đến với thế giới công nghệ hiện đại tới gần hơn  với người Việt Nam và góp phần khẳng định trí tuệ Việt Nam trên bản đồ công  nghệ thế giới. ông ty Segmenta - CMC   CMC trở thành Top 2  Công ty Phần mềm hàng  đầu Việt Nam  (theo bình chọn của HCA liên tục  từ năm 2007 – 2011).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 377, tokens 79, triggered by: token limit\n",
      "\u001b[31m.94  Là một trong những doanh nghiệp đầu tiên tham gia vào thị trường sản xuất  máy tính thương hiệu Việt, CMC đã khẳng định được tên tuổi và vị thế của  mình với dòng máy tính CMS.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 378, tokens 133, triggered by: token limit\n",
      "\u001b[32mLuôn tự hào là thương hiệu đi đầu trong việc  ứng dụng công nghệ cao, sản xuất trên quy mô công nghiệp, CMS khi ấy là  thương hiệu máy tính duy nhất đạt tiêu chuẩn quốc tế ISO/IEC 17025 - đảm  bảo chất lượng sản phẩm tốt nhất, sẵn sàng cạnh tranh với các thương hiệu  nước ngoài.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 379, tokens 131, triggered by: token limit\n",
      "\u001b[34mLĩnh vực sản xuất và phân phối của CMC với thế mạnh nghiên cứu cùng khát  khao góp sức cho trí tuệ Việt đã khẳng định vị thế của mình với những sản  phẩm thương hiệu Việt uy tín, cạnh tranh cao về chất lượng và có mức giá  phù hợp để người Việt Nam có cơ hội tiếp cận tri thức.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 380, tokens 126, triggered by: token limit\n",
      "\u001b[35mVới dây chuyền sản  xuất máy tính hiện đại, đồng bộ nhất Việt Nam, có công suất 12.000  chiếc/tháng, CMS đã cho ra đời những chiếc máy tính để bàn với những cái  tên mà giờ đây khi nhắc nhớ lại, người CMC thời ấy vẫn rung lên một cảm xúc  tự hào:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 381, tokens 188, triggered by: 0.32\n",
      "\u001b[31mCMS Powercom, CMS X-Media, CMS Thánh Gióng, Desktop JetSlim…  Bên cạnh đó, bắt kịp với xu thế di động ngày càng phát triển, CMS đã tập  trung nghiên cứu và  giới thiệu tới thị trường nhiều sản phẩm máy tính xách  tay, được khách hàng đánh giá cao như CMC X-Styles với mẫu mã thiết kế trẻ  trung và sành điệu. CMS Z-Light sử dụng bộ vi xử lý tiết kiệm năng lượng mới  nhất (CULV) của Intel với thiết kế cực mỏng và nhẹ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 382, tokens 246, triggered by: token limit\n",
      "\u001b[32m“Mong muốn cháy bỏng: làm sao thiết kế được một máy tính giá thành hạ,  làm chủ được công nghệ để phục vụ cho giáo dục, cho người tiêu dùng có thu  nhập vừa phải” dở dang vì vụ cháy bất ngờ khi nghiên cứu đề án Máy tính bác  Tô nay đã được những người kỹ sư ngày ấy hiện thực hóa với dòng máy tính  Sản xuất & Phân phối - Niềm tự hào  máy tính mang thương hiệu Việt.KHÁT  95  hướng tới phân khúc khách hàng sinh viên, học sinh và phân khúc khách  hàng bậc trung, đặc biệt là nhóm khách hàng ở nông thôn với mức giá hợp lý.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 383, tokens 145, triggered by: token limit\n",
      "\u001b[34mNhững chiếc máy tính được lắp ráp trên dây chuyền công nghiệp và được  kiểm nghiệm kỹ lưỡng trước khi tung ra thị trường đã góp phần quan trọng  tạo dựng tên tuổi máy tính CMS trên thị trường đại chúng, giúp CMS trở thành  thương hiệu máy tính Việt Nam duy nhất được gắn biểu tượng cao quý  Thương hiệu Quốc gia vào năm 2008.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 384, tokens 186, triggered by: 0.38\n",
      "\u001b[35mVới mục tiêu đẩy mạnh phân phối các sản phẩm, thiết bị công nghệ thông tin,  viễn thông và trở thành trung tâm bảo hành ủy quyền của các hãng công  nghệ hàng đầu thế giới, 03/10/2007, CMC thành lập Công ty TNHH Phân phối  CMC – CMC Distribution. CMC Distribution đã trở thành nhà phân phối chiến  lược của các hãng công nghệ uy tín trên thế giới như Acer, 3Com, HP,… và  thiết lập được hệ thống kênh phân phối gồm 220 đại lý trên toàn quốc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 385, tokens 158, triggered by: -0.03\n",
      "\u001b[31mNăm 2008, CMS vinh dự được đón nhận Huân chương Lao động Hạng Ba của  Chính phủ nước CHXHCN Việt Nam vì những thành tích xuất sắc trong công  tác xây dựng và phát triển, đóng góp vào công cuộc xây dựng CNXH và Bảo  vệ Tổ quốc. Đây là thành quả của sự nỗ lực không ngừng nghỉ với mục tiêu  đem tri thức đến muôn nơi của Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 386, tokens 74, triggered by: 0.42\n",
      "\u001b[32mHình ảnh: Biểu tượng Thương hiệu Quốc gia được gắn  trên Máy tính CMS.Những thành công của CMC trong suốt quá trình hình thành và xây dựng  không phải là sự ngẫu nhiên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 387, tokens 74, triggered by: 0.41\n",
      "\u001b[34mThành công ấy là kết quả của sự kiên trì, là  thành tựu của sự kiên định với đam mê, với lý tưởng và được viết nên bởi sự  đồng lòng của tất thảy người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 388, tokens 88, triggered by: 0.32\n",
      "\u001b[35mTừ những ngày đầu tiên với HT&NT hay  đến khi trở thành một Tập đoàn lớn mạnh, từ khóa “Hợp lực” luôn hiện hữu  trong mọi hành động, mọi quyết định, mọi dự án của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 389, tokens 141, triggered by: 0.32\n",
      "\u001b[31mTrong giai đoạn này, CMC liên tiếp trúng thầu những dự án có quy mô lớn, đòi  hỏi phạm vi và khối lượng công việc khổng lồ. Hợp lực để phát huy thế mạnh  và chinh phục những nhiệm vụ tưởng chừng bất khả thi là chìa khóa giúp  CMC thành công vang dội, ghi dấu ấn trên thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 390, tokens 99, triggered by: 0.16\n",
      "\u001b[32mNăm 2005, CMC trúng thầu dự án đồng hành cùng Ngân hàng Phát triển  Châu Á (ADB) cung cấp, trang bị phòng học ngoại ngữ cho các trường THCS  – THPT, quy mô dự án trải dài trên cả nước với hơn 300 điểm trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 391, tokens 220, triggered by: token limit\n",
      "\u001b[34mHợp lực cùng  phát triển Hình ảnh: CMC hợp lực cùng phát triển  .Sự hợp lực của mọi lĩnh vực trong CMC đã mang đến một dự án không chỉ đơn  thuần cung cấp máy tính mà còn mang đến tương lai cho các em học sinh  vùng sâu vùng xa: những chiếc máy tính CMS được đội ngũ Tích hợp hệ thống  không quản xa xôi vận chuyển và lắp đặt tới những điểm trường, phần đào  tạo hướng dẫn sử dụng được phụ trách bởi đội hỗ trợ đến từ lĩnh vực Phát  triển phần mềm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 392, tokens 196, triggered by: 0.42\n",
      "\u001b[35mKhi ấy, không còn phân biệt CMC SI, CMC Soft hay CMS, tất  cả đều chung màu áo xanh CMC, chung nỗ lực đem những tiến bộ khoa học  kỹ thuật tới các điểm trường, đem tương lai đến với những em học sinh. Thời điểm đó, máy tính là một thiết bị xa xỉ, nên khi dự án được triển khai  trên toàn quốc, đặc biệt là ở các vùng sâu vùng xa, các em học sinh được  chạm vào bàn phím, đánh những con chữ đầu tiên với sự háo hức.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 393, tokens 149, triggered by: token limit\n",
      "\u001b[31mTôi không  sao tả xiết những ánh nhìn sáng ngời và sự nắn nót của các em với chiếc  bàn phím thương hiệu Việt Nam - CMS made by CMC. Niềm vui của các  em học sinh, những kỷ niệm và tinh thần đoàn kết từ các thành viên đến từ  những công ty khác nhau trong CMC là phần thưởng ý nghĩa nhất cho  những nỗ lực của team dự án ngày ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 394, tokens 223, triggered by: token limit\n",
      "\u001b[32mChị Nguyễn Thị Luyên - Cán bộ kinh doanh CMC SI ngày ấy chia sẻ KHÁT .Mảnh ghép còn thiếu của logo CMC  -  Ấp ủ của những “chàng kỹ sư năm ấy” Bên cạnh Công nghệ thông tin, lĩnh vực Viễn thông luôn là một điều trăn trở  đối với hai nhà sáng lập CMC. “Chàng kỹ sư” khoa Điện tử Viễn thông, Đại học  Bách Khoa Hà Nội - anh Nguyễn Trung Chính luôn mong muốn áp dụng  những kiến thức của mình để đóng góp vào sự phát triển của xã hội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 395, tokens 163, triggered by: token limit\n",
      "\u001b[34mNgười  đồng đội của anh - anh Hà Thế Minh cũng có sự quan tâm đặc biệt đến lĩnh  vực này. Khi nhắc lại, chị Tường Vy (phu nhân cố Chủ tịch) vẫn nhớ hình ảnh  chồng mình ngồi bên bàn làm việc đến 2-3 giờ sáng cặm cụi nghiên cứu tài  liệu, thường ngày chỉ cần  tivi nhắc đến Viễn thông là bỏ mọi việc để xem.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 396, tokens 186, triggered by: 0.26\n",
      "\u001b[35mGia nhập thị trường viễn thông Ngày Đầu - Logo đầu tiên của CMC với dòng chữ Computer  - Communication không chỉ thể hiện tầm nhìn và định hướng của hai  nhà sáng lập mà còn truyền tải tình yêu và niềm đam mê của anh Minh  và anh Chính dành cho lĩnh vực Viễn thông. Những năm đầu, CMC tuy  tập trung vào hoạt động sản xuất và công nghệ thông tin nhưng hai anh  vẫn luôn ấp ủ về tương lai có thể khai thác lĩnh vực này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 397, tokens 110, triggered by: token limit\n",
      "\u001b[31m.Từ thời kỳ ADCOM, khi viễn thông vẫn thuộc thế độc quyền nhà nước, các anh  đã phối hợp cùng Bưu điện Hà Nội sản xuất tổng đài số bán cho các tỉnh và  địa phương với mong muốn góp sức vào sự phát triển của lĩnh vực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 398, tokens 169, triggered by: 0.25\n",
      "\u001b[32mChiếc logo đầu tiên của CMC với dòng chữ Computer - Communication  không chỉ thể hiện tầm nhìn và định hướng của hai nhà sáng lập mà còn  truyền tải tình yêu và niềm đam mê của hai anh dành cho lĩnh vực Viễn  thông. Những năm đầu, CMC tuy tập trung vào hoạt động sản xuất và công  nghệ thông tin nhưng hai anh vẫn luôn ấp ủ về tương lai có thể khai thác lĩnh  vực thú vị:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 399, tokens 119, triggered by: token limit\n",
      "\u001b[34mViễn thông. KHÁT .Viễn thông là một lĩnh vực kinh doanh hấp dẫn nhưng có điều kiện. Những  năm 1990, thị trường Viễn thông vốn được mặc định độc quyền nhà nước,  người tiêu dùng Việt Nam phải chịu một mức cước cao ngất ngưởng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 400, tokens 180, triggered by: token limit\n",
      "\u001b[35mTrước  khi Luật Viễn thông ra đời năm 2009, hoạt động kinh doanh trong lĩnh vực  Viễn thông được nhà nước kiểm soát một cách chặt chẽ. Điều này tạo ra tâm  thế dè dặt của các doanh nghiệp tư nhân khi mong muốn đầu tư, dẫn đến  thiếu cạnh tranh và kìm hãm sự phát triển trong lĩnh vực này. Năm 2007, thị trường viễn thông Việt Nam bắt đầu cuộc chạy đua cạnh tranh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 401, tokens 165, triggered by: 0.24\n",
      "\u001b[31mĐó là sự chuẩn bị nhập cuộc của viễn thông điện lực (mạng 099) cùng một số  nhà khai thác nước ngoài cũng đang ngấp nghé đầu tư vào lĩnh vực này để  phá vỡ thế độc quyền. Nhắc lại về thời kỳ này, anh Nguyễn Trung Chính hồi tưởng: “Khi đó, CMC ra đời  và phát triển được 15 năm, là bước trưởng thành đáng tự hào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 402, tokens 110, triggered by: 0.34\n",
      "\u001b[32mChúng tôi bắt  đầu có những đồng vốn tuy ít nhưng đáng quý và mơ những giấc mơ lớn hơn.” Hoàn chỉnh mảnh ghép của chiếc logo CMC   Khi đó, CMC ra đời và phát triển được 15 năm, là bước trưởng thành  đáng tự hào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 403, tokens 51, triggered by: 0.26\n",
      "\u001b[34mChúng tôi bắt đầu có những đồng vốn tuy ít nhưng đáng  quý và mơ những giấc mơ lớn hơn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 404, tokens 171, triggered by: 0.38\n",
      "\u001b[35mAnh Nguyễn Trung Chính hồi tưởng.Hình ảnh: Các sản phẩm lĩnh vực Viễn thông Chiều ngày 21/11/2007, rất nhiều trang báo đưa tin Tập đoàn Công nghệ CMC  công bố tham gia thị trường Viễn thông - vốn được mặc định độc quyền nhà  nước nhiều năm trước, với sự ra đời của đơn vị trực thuộc - Công ty Cổ phần  Dịch vụ Viễn thông CMC (CMC Telecom).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 405, tokens 156, triggered by: token limit\n",
      "\u001b[31mVới dấu mốc khai sinh CMC Telecom, Tập đoàn CMC phát đi thông điệp về  chiến lược kinh doanh tập trung vào nhóm dịch vụ hạ tầng mạng viễn thông. Những nhà sáng lập CMC đã hoàn chỉnh mảnh ghép còn thiếu của chiếc logo  CMC Computer - Communication năm nào, tiếp tục thực hiện ước muốn  mang kiến thức của mình đóng góp cho sự phát triển của xã hội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 406, tokens 189, triggered by: token limit\n",
      "\u001b[32mTrong những bước đi đầu tiên của mình tại thị trường viễn thông, CMC chọn  cách hợp tác với các nhà cung cấp hạ tầng truyền dẫn để cung cấp các dịch  vụ gia tăng cho khách hàng bao gồm: Dịch vụ hạ tầng mạng viễn thông  (BlueNet); Dịch vụ về chăm sóc khách hàng chuyên nghiệp dưới sự hỗ trợ của  công nghệ thông tin - truyền thông (BlueCare); Dịch vụ dữ liệu (BlueData);  Dịch vụ nội dung trên mạng (BlueLife).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 407, tokens 191, triggered by: token limit\n",
      "\u001b[34mVới nhiều chính sách ưu đãi về giá và chế độ chăm sóc khách hàng chu đáo,  dịch vụ viễn thông của CMC nhanh chóng thu hút được sự quan tâm của  khách hàng và có những bước đi nhanh chóng trong thị trường này. KHÁT .Sau một thời gian triển khai, mô hình thuê hạ tầng viễn thông bộc lộ những  hạn chế về việc phụ thuộc vào chất lượng, giá thuê và ảnh hưởng đến dịch vụ  mà CMC cung cấp tới khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 408, tokens 169, triggered by: 0.12\n",
      "\u001b[35mVới tâm niệm mang đến cho khách hàng  những sản phẩm dịch vụ tốt nhất, Ban Lãnh đạo CMC quyết định làm chủ hạ  tầng viễn thông càng nhanh càng tốt. Quyết tâm này thể hiện sự cam kết của  CMC trong chất lượng sản phẩm, đáp ứng những yêu cầu của khách hàng với  dịch vụ viễn thông chất lượng cao, hướng tới sự phát triển bền vững của CMC  trong lĩnh vực Viễn thông.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 409, tokens 55, triggered by: 0.25\n",
      "\u001b[31mQuyết định này không chỉ đòi hỏi sự đầu tư lớn mà còn là một thách thức  không hề nhỏ với những người đứng đầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 410, tokens 71, triggered by: 0.28\n",
      "\u001b[32mKhi ấy, Luật Viễn thông quy định,  giấy phép thiết lập hạ tầng viễn thông chỉ cấp cho các doanh nghiệp có vốn  nhà nước chiếm tối thiểu 51%.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 411, tokens 195, triggered by: 0.33\n",
      "\u001b[34mNhư vậy, để được cấp giấy phép hạ tầng, bắt  buộc một công ty tư nhân cần đi cùng một doanh nghiệp nhà nước. Với quyết tâm của mình và sự đồng lòng của CMC, anh Nguyễn Trung Chính  trong buổi gặp mặt với Nguyên Phó Thủ tướng Nguyễn Sinh Hùng đã bày tỏ  nguyện vọng đóng góp vào sự phát triển của lĩnh vực Viễn thông, đặc biệt là  hạ tầng viễn thông nhằm đem lại những giá trị cho khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 412, tokens 293, triggered by: token limit\n",
      "\u001b[35mTại thời điểm  ấy, chưa có một doanh nghiệp tư nhân nào mạnh dạn khai thác thị trường  khó này. Sự quyết tâm của CMC đã nhận được sự ủng hộ của Chính phủ, Bộ  Thông tin & Truyền thông thông qua việc chỉ đạo Tổng công ty Đầu tư và Kinh  doanh vốn nhà nước (SCIC) hợp tác cùng CMC thành lập công ty khai thác hạ  tầng viễn thông. Đi ngược lại với tiền lệ của SCIC, vốn trước đó chỉ quản lý các  tập đoàn nhà nước, đây là lần đầu tiên một công ty tư nhân có thể hợp tác với  SCIC để thành lập một công ty mới. Điều này khẳng định sự tin tưởng của  Chính phủ về năng lực đã được CMC chứng minh trong hơn 15 năm hình  thành và xây dựng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 413, tokens 177, triggered by: token limit\n",
      "\u001b[31mNgày 05/09/2008, Công ty Cổ phần Hạ tầng Viễn thông CMC (CMC Telecom- munication Infrastructure Corporation - CMC TI) được thành lập với 51% vốn  nhà nước (SCIC) và 49% vốn của Tập đoàn CMC. Sau một năm thành lập,  CMC TI đã được cấp giấy phép thiết lập hạ tầng viễn thông vào tháng  09/2009, hứa hẹn đem đến cho khách hàng dịch vụ viễn thông trọn gói với  băng thông lớn, chất lượng cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 414, tokens 184, triggered by: token limit\n",
      "\u001b[32mCon đường chinh phục lĩnh vực Viễn thông  của CMC đã bước thêm những bước mới đầy tự hào. Muốn tự quyết định vận mệnh   phải làm chủ hạ tầng .Với mục tiêu cung cấp tới khách hàng những dịch vụ viễn thông tốt nhất,  ngày 31/3/2010, CMC đã chính thức trở thành cổ đông chiến lược của Công  ty NetNam (nhà cung cấp dịch vụ Internet đầu tiên tại Việt Nam) với 43.8% cổ  phần.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 415, tokens 120, triggered by: token limit\n",
      "\u001b[34mViệc CMC đầu tư vào NetNam là một sự hợp lực để tạo dựng hệ thống  các nhà cung cấp có sự liên kết chặt chẽ về hạ tầng, dịch vụ, giải pháp, nhân  lực nhằm cung cấp tới các khách hàng những dịch vụ viễn thông - Internet  có chất lượng cao nhất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 416, tokens 98, triggered by: token limit\n",
      "\u001b[35mNhờ quyết tâm đầu tư vào dịch vụ và làm chủ hạ tầng viễn thông, CMC đã có  những bước tiến dài trong thời gian ngắn và đảm bảo lợi thế cạnh tranh dài  hạn trong thị trường Viễn thông đầy tiềm năng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 417, tokens 193, triggered by: token limit\n",
      "\u001b[31mNhững bước tiến dài trong lĩnh vực Viễn thông CMC xác định chiến lược trở thành doanh  nghiệp tiên phong và duy nhất tại thời điểm ấy  với kế hoạch xây dựng hệ thống hạ tầng 100%  cáp quang đồng thời thiết lập mô hình phát triển  tiên tiến - mô hình kinh doanh trung lập để có thể  hợp tác được với tất cả các nhà cung cấp nhằm thoả mãn  tối đa nhu cầu về các dịch vụ viễn thông cao cấp của khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 418, tokens 132, triggered by: 0.41\n",
      "\u001b[32mNăm 2010, dịch vụ chiến lược Internet cáp quang thương hiệu Giganet, tốc  độ lên tới 2,5Gbps được đánh giá cao nhờ chất lượng truyền dẫn ổn định  được ra mắt. Trên nền dịch vụ Internet cáp quang Giganet, các dịch vụ giá trị  gia tăng đa dạng, mang lại lợi ích toàn diện cho khách hàng:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 419, tokens 54, triggered by: 0.40\n",
      "\u001b[34mMạng riêng ảo  GigaWan, Hội nghị truyền hình, Giga Camera của CMC cũng nhận được sự  ủng hộ từ thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 420, tokens 84, triggered by: 0.32\n",
      "\u001b[35mKết thúc năm 2010, CMC có số lượng trung tâm dữ liệu  được xây dựng và vận hành thuộc top đầu các công ty viễn thông tại Việt  Nam với 4 Trung tâm dữ liệu đạt tiêu chuẩn quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 421, tokens 145, triggered by: 0.36\n",
      "\u001b[31mKHÁT .SỰ KỲ CMC 30   THAM GIA LĨNH VỰC BẢO MẬT MANH ĐAN ĐẶT BƯỚC CHÂN ĐẦU TIÊN  TRONG THỊ TRƯỜNG KHÓ  “Với tầm nhìn vượt thời đại, những người lãnh đạo CMC đã nhận thấy tiềm năng và cơ hội lâu dài nếu đầu tư vào lĩnh vực An toàn thông tin.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 422, tokens 187, triggered by: 0.36\n",
      "\u001b[32mTại thời điểm quyết định đầu tư, CMC là công ty thứ 2 tại Việt Nam có công nghệ và sản phẩm chống mã độc.”  Đặt cược vào sự phát triển của Internet tại Việt Nam  Năm 1997, với một lễ khai trường khiêm tốn, có phần trầm lắng tại tầng 2 Hội sở của Tổng cục Bưu điện và Tổng công ty Bưu chính viễn thông Việt Nam, số 18 Nguyễn Du - Hà Nội, Việt Nam đã chính thức kết nối vào mạng Internet toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 423, tokens 71, triggered by: 0.19\n",
      "\u001b[34mThời điểm ấy, tuy đây là móc dấu chân hành trình đi đến hội nhập nhưng người dân Việt Nam có rất ít hiểu biết về tính ưu việt của mạng thông tin này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 424, tokens 69, triggered by: token limit\n",
      "\u001b[35mNhưng chỉ 10 năm sau đó, năm 2007, số lượng thuê bao Internet quy đổi đã đạt con số 5 triệu, “con lọc” Internet bắt đầu len lỏi, phủ kín mọi ngõ ngách.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 425, tokens 133, triggered by: token limit\n",
      "\u001b[31mCũng năm đó, từ khóa “an toàn không gian mạng” (cybersecurity) trở thành  104 SỰ KỲ CMC 30.## Cuộc hội ngộ của những “nhân tài” trong làng bảo mật  Với chiến lược đầu tư nghiêm túc và bài bản vào lĩnh vực Bảo mật thông tin, CMC đã thu hút được nhiều nhân tài trong lĩnh vực này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 426, tokens 143, triggered by: token limit\n",
      "\u001b[32mMột trong số đó là Triệu Trần Đức - một chàng trai trẻ hoạt động có danh tiếng trong làng Công nghệ, Năm 2004, Anh Triệu Trần Đức  nhật cuộc thi Trí tuệ Việt Nam với sản phẩm Moon Secure - hệ thống giám sát thông việc sử dụng tài nguyên mạng và có chức năng của một bức tường lửa linh hoạt trước các cuộc tấn công từ tin tặc và virus.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 427, tokens 168, triggered by: 0.37\n",
      "\u001b[34mTiếng vang từ cuộc thi giúp anh càng trở nên nổi tiếng trong giới An ninh mạng và nhận được nhiều lời mời làm việc từ nhiều tổ chức lớn nhỏ. Nhưng chàng trai đã lựa chọn CMC bởi \"CMC có nguồn vốn đầu tư nghiêm túc và quan trọng hơn là có chuyên môn tốt về công nghệ nên sẽ thấu hiểu tầm quan trọng của bảo mật.\" (Anh Đức chia sẻ).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 428, tokens 151, triggered by: token limit\n",
      "\u001b[35mVậy là một nhóm dự án nhỏ nghiên cứu đề phát triển sản phẩm về phòng chống mã độc ra đời trong lòng CMC. Ban đầu, dự án chỉ có vài thành viên, là một phòng ban thuộc CMC Soft. Nhóm dự án  với 7 - 8 kỹ sư trẻ mang, thuộc \"hàng hiếm\" của ngành Công nghệ thông tin được kỳ vọng sẽ làm nên chuyện, mở ra lĩnh vực mới cho CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 429, tokens 131, triggered by: token limit\n",
      "\u001b[31mCMC có nguồn vốn đầu tư nghiêm túc và quan trọng hơn là có chuyên môn tốt về công nghệ nên sẽ thấu hiểu tầm quan trọng của bảo mật. Anh Triệu Trần Đức chia sẻ.CMC Infosec ra đời  Một thời gian sau khi thành lập, nhóm dự án có những thành công nhất định trong nghiên cứu sản phẩm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 430, tokens 89, triggered by: 0.38\n",
      "\u001b[32mNhóm kỳ sư trẻ với chuyên môn cao tu tin xin được thành lập công ty riêng chuyên về lĩnh vực Bảo mật An ninh mạng để có thể chủ động bồi toán kinh doanh và định hướng phát triển lâu dài.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 431, tokens 96, triggered by: 0.40\n",
      "\u001b[34mAnh Hà Thế Minh và anh Nguyễn Trung Chính cần nhắc thỏi cơ thị trường, bản bạc với tập đoàn và đồng ý tách nhóm dự án, thành lập công ty cổ phần An ninh An toàn thông tin CMC - CMC Infosec ngày 30/5/2008.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 432, tokens 107, triggered by: token limit\n",
      "\u001b[35mChỉ sau 3 tháng thành lập CMC Infosec, dòng sản phẩm phần mềm diệt virus mang thương hiệu CMC chính thức ra mắt thị trường bao gồm: CMC Internet Security – phiên bản trả phí dành cho khách hàng doanh nghiệp và CMC Antivirus – phiên bản miễn phí dành cho người dùng cá nhân.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 433, tokens 193, triggered by: token limit\n",
      "\u001b[31mNgày ra mắt, rất đông báo chí đến đưa tin, khách hàng chúc mừng. “Chúng tôi ngật ngừ như vào mùa gặt, tuy ai cũng mệt nhưng đều thấy vui thương hiệu CMC được nhiều người quan tâm.”. –  Chi Bùi Thị Hương Giang – Chuyên viên hành chính nhân sự CMC Infosec khi ấy nhớ lại. Sau ngày ra mắt đáng nhớ, cả công ty tất bật với những đơn hàng mới. Sản phẩm do CMC Infosec phát triển bán rất tốt ở thị trường bán lẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 434, tokens 99, triggered by: token limit\n",
      "\u001b[32mChỉ trong thời gian thử nghiệm 2 tháng đã có 1,1 triệu lượt tải phần mềm CMC Antivirus, trung bình 241 virus/ngày do người dùng cài đặt, khách hàng đều cảm cá ghi dấu ấn trong lĩnh vực Bảo mật An ninh mạng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 435, tokens 131, triggered by: token limit\n",
      "\u001b[34mNăm 2010, CMC Infosec chính thức trở thành thành viên Liên minh An ninh Máy tính Quốc tế ICSA và là hàng bảo mật duy nhất của Việt Nam tham gia hội nghị AVAR 2010, đánh dấu một bước tiến dài trên con đường hướng ra thị trường quốc tế trong lĩnh vực “Bảo mật thông tin của CMC ở Internet Việt Nam”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 436, tokens 171, triggered by: token limit\n",
      "\u001b[35mCMC đã mạnh dạn tham gia lĩnh vực “Bảo mật An toàn thông tin với những giải pháp bảo mật có tính hiệu quả cao cung giá cả phải chăng. và thành công bảo vệ an toàn cho người dùng, lan tỏa thông điệp người Việt Nam dùng phần mềm Việt Nam. .CMC Internet Security \"An toàn từng click\" Hotline: 1900 571 254 www.cmccybersecurity.com  CMC Antivirus Free \"Fast, Lightweight, Accuracy\" Hotline: 1900 571 244 www.cmcinfosec.com  Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 437, tokens 107, triggered by: token limit\n",
      "\u001b[31mSản phẩm CMC Internet Securcity, CMC Antivirus Free   107.CMC Tower đã trở thành một môi trường làm việc lý tưởng không chỉ cho Tập  đoàn Công nghệ CMC, mà còn là sự lựa chọn tối ưu của rất nhiều các công  ty công nghệ và viễn thông hàng đầu Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 438, tokens 131, triggered by: token limit\n",
      "\u001b[32mHơn thế nữa, cùng với các  tòa nhà khác, CMC Tower đã góp phần đưa Cụm Tiểu thủ công nghiệp và  Công nghiệp nhỏ quận Cầu Giấy trở thành một trong những không gian làm  việc tập trung ICT công nghệ cao, lớn nhất cả nước, trở thành khu vực trọng  điểm của nền kinh tế tri thức Thủ đô.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 439, tokens 217, triggered by: token limit\n",
      "\u001b[34mCMC Tower - nơi “An cư lạc nghiệp” Anh Nguyễn Trung Chính phát biểu tại lễ Khai trương CMC Tower  Sau một thời gian phát triển như vũ bão ở các mảng kinh doanh truyền thống;  tự tin mở rộng, khai thác các lĩnh vực mới; hoàn thiện hệ thống quản trị cũng  như nâng cao năng lực con người, Ban lãnh đạo CMC nhận thấy cần phải đầu  tư cơ sở vật chất tốt nhất để cán bộ nhân viên yên tâm làm việc và phát huy  tối đa khả năng, sức sáng tạo của  mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 440, tokens 155, triggered by: 0.21\n",
      "\u001b[35mCuối tháng 12 năm 2006, Tập đoàn CMC chính thức khởi công xây dựng tòa  nhà mang tên mình tại Duy Tân, Dịch Vọng Hậu, Hà Nội. CMC Tower được xây  của người CMC -  .dựng trên diện tích 3.000m2, trở thành một trong những tòa nhà đầu tiên  khai phá “cái nôi” phát triển của nhiều công ty công nghệ thông tin trong  nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 441, tokens 196, triggered by: token limit\n",
      "\u001b[31mNhững người dân xung quanh thời ấy chắc hẳn sẽ không thể hình dung  một khu mênh mông ruộng đất chỉ vài năm sau đã có sự lột xác hoàn toàn với  những tòa nhà cao tầng hiện đại và một lượng “tri thức khổng lồ” đổ về, được  ví như “Sillicon Valley” của Hà Nội. Việc xây dựng tòa nhà văn phòng riêng của mình là một bước đi mang tính  chiến lược và có ý nghĩa quan trọng đối với sự phát triển lâu dài của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 442, tokens 166, triggered by: token limit\n",
      "\u001b[32mSở  hữu một trụ sở văn phòng riêng sẽ giúp CMC có không gian làm việc độc lập,  mang dấu ấn văn hóa của riêng mình. Thay vì phải thuê văn phòng, CMC có  thể thiết kế và xây dựng cơ sở vật chất theo đúng yêu cầu, mong muốn của  mình, tạo ra một môi trường làm việc hiện đại, năng suất và thúc đẩy sự sáng  tạo của nhân viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 443, tokens 155, triggered by: token limit\n",
      "\u001b[34mVà hơn thế, Người CMC sẽ được quy tụ về một mối, không  còn tản mác ở nhiều địa điểm khác nhau; anh em quây quần một nhà, cùng  tập trung sức mạnh đưa Tập đoàn phát triển. KHÁT .Ngày 27/05/2010, con phố Duy Tân trước đó vắng lặng, ngổn ngang những  công trình xây dựng bỗng náo nhiệt hơn thường ngày.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 444, tokens 166, triggered by: 0.27\n",
      "\u001b[35mAnh em CMC ở các  công ty khác nhau đã rộn ràng chuẩn bị dọn dẹp, di chuyển văn phòng về Duy  Tân từ nhiều ngày trước đó và háo hức chờ đợi ngày khai trương. Tấm biển  CMC Tower - công trình Kỷ niệm 1000 năm Thăng Long Hà Nội chính thức  được gắn lên tầng 1 của tòa tháp 19 tầng hiện đại, ghi dấu một hành trình  mới của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 445, tokens 122, triggered by: 0.19\n",
      "\u001b[31mTòa nhà được thiết kế hiện đại với kỹ thuật thi công, các thiết bị nhập khẩu từ  nước ngoài như thang máy Mitsubishi, máy biến áp ABB, máy phát điện  Cummins, hệ kính hộp chân không, đảm bảo được các tiêu chuẩn quốc tế về  môi trường làm việc cao cấp và linh hoạt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 446, tokens 161, triggered by: token limit\n",
      "\u001b[32mTrong đó, điểm đặc biệt nhất là  việc sử dụng kính hộp Ashiya hai lớp chống nhiệt dày 24mm giúp các văn  phòng giảm được chi phí vận hành điều hòa nhiệt độ, chống lãng phí năng  lượng, tăng tuổi thọ, độ bền cho nội thất, các thiết bị văn phòng và quan  trọng nhất là bảo đảm sức khỏe cho nhân viên trong những ngày nắng nóng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 447, tokens 114, triggered by: token limit\n",
      "\u001b[34mĐây là một trong những ưu điểm nổi trội của CMC Tower, đi đầu trong việc  Tòa nhà hiện đại nhất -   “Sillicon Valey” tại Hà Nội”.ứng dụng những công nghệ tiết kiệm năng lượng mới nhất đang được sử  dụng tại các cao ốc cao cấp trên thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 448, tokens 125, triggered by: token limit\n",
      "\u001b[35mNgoài ra, tòa nhà còn bố trí thêm  khu vực nghỉ ngơi, thư giãn; khu vực bar, café, đồ ăn trên tầng mái nhằm đảm  bảo đời sống tinh thần cho những thành viên làm việc trong tòa nhà. Sự đầu  tư này ở giai đoạn đó là rất hiếm tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 449, tokens 248, triggered by: token limit\n",
      "\u001b[31mNgay khi ra đời, CMC Tower đã trở thành một hình mẫu lý tưởng về văn phòng  thông minh, được các chuyên gia bất động sản đánh giá là một trong những  tòa nhà thông minh nhất Hà Nội với thiết kế chuẩn mực gói gọn trong một tòa  cao ốc hiện đại, đem lại những dịch vụ và tiện ích tốt nhất dành cho các hoạt  động kinh doanh trong kỷ nguyên số. Đây không chỉ là mái nhà chung, thể  hiện tinh thần hợp lực, niềm tự hào của Người CMC mà còn là điểm đến, là  văn phòng đáng mơ ước của nhiều công ty khác trong thủ đô lúc bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 450, tokens 50, triggered by: token limit\n",
      "\u001b[32mCMC Tower đã góp phần khẳng định vị thế, uy tín và quy mô của doanh  nghiệp trên thị trường. Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 451, tokens 251, triggered by: token limit\n",
      "\u001b[34mCMC Tower -  ngôi nhà mới của anh  em CMC KHÁT .112  Với tầm nhìn xa về vai trò quan trọng của Data Center trong bối cảnh công  nghệ phát triển mở ra làn sóng bùng nổ thông tin số, tạo ra nhu cầu lưu trữ  và xử lý dữ liệu hiệu quả, an toàn của khách hàng; ngay từ quá trình thiết kế  CMC Tower, anh Nguyễn Trung Chính – khi đó là Tổng Giám đốc Tập đoàn, đã  cho xây dựng bốn tầng (từ tầng G đến tầng 3) có mặt sàn chịu tải trọng lớn  và độ cao hơn các tầng khác với mục tiêu lắp đặt hệ thống Data Center của  CMC chuẩn quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 452, tokens 182, triggered by: 0.39\n",
      "\u001b[35mTrước đó, từ những năm 2008, Tập đoàn CMC đã triển khai Trung tâm Dữ liệu  tại Khu Công nghiệp Sài Đồng (Long Biên, Hà Nội). Tuy nhiên do vị trí địa lý xa  trung tâm, trong quá trình vận hành, Data Center Sài Đồng rất khó tiếp cận  khách hàng. Bên cạnh đó, việc triển khai Data Center với thử nghiệm cải tạo  phòng NOC (Network Operations Center) của CMC TI đã chứng minh được  tính hiệu quả của Data Center trong nội đô.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 453, tokens 70, triggered by: 0.32\n",
      "\u001b[31m10h đêm ngày 23/09/2011, gần một năm sau khi khánh thành CMC Tower,  những chiếc thùng đựng thiết bị Data Center cuối cùng được chuyển ra xe tải  chở về Duy Tân.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 454, tokens 87, triggered by: 0.26\n",
      "\u001b[32mDo tính chất quan trọng của một trung tâm dữ liệu, kế hoạch  di dời được lên thật chi tiết, chia ra làm các hạng mục khác nhau để đảm bảo  thời gian gián đoạn dịch vụ thấp nhất có thể.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 455, tokens 78, triggered by: 0.36\n",
      "\u001b[34mHệ thống được sắp xếp vào đêm  thứ Sáu và đêm thứ Bảy để đảm bảo an toàn dữ liệu và có một khoảng thời  gian dự phòng nếu có bất kỳ sự cố nào xảy ra.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 456, tokens 100, triggered by: 0.34\n",
      "\u001b[35mAnh Vũ Thành Nam, Trưởng phòng NOC – CMC Telecom tự tay ngắt cầu dao  điện tại CMC Data Center Sài Đồng, cả căn phòng chìm trong bóng đen. Ánh  đèn ấy tắt đi nhưng bật lên ánh sáng mới rực rỡ hơn tại CMC Tower.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 457, tokens 131, triggered by: 0.41\n",
      "\u001b[31mNhóm  thợ vác thùng đựng thiết bị chuyển xuống xe tải, đi qua các khoảng sáng tối  của những ánh đèn còn sót lại rồi bước xuống sân khi cả khu công nghiệp Sài  Đồng đã chìm vào bóng đêm và thoang thoảng hương hoa sữa. Ba năm vận  hành của CMC Data Center Sài Đồng đã chính thức khép lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 458, tokens 151, triggered by: 0.34\n",
      "\u001b[32mData Center - Trái tim của CMC Tower.KHÁT  113  Niềm kiêu hãnh và tự hào -  trong trái tim Người CMC Từ những ngày đầu khai trương cho đến hiện nay, CMC Tower không chỉ là  một văn phòng để làm việc mà nơi đây chính là nhà, là nơi gắn bó, là hình  ảnh ghi khắc trong tim, là niềm tự hào và kiêu hãnh của mỗi Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 459, tokens 104, triggered by: token limit\n",
      "\u001b[34mCMC Tower đã trở thành biểu tượng của Tập đoàn CMC, biểu tượng sự hợp  lực, biểu tượng của đam mê và khát vọng vươn cao trong hành trình Chinh  phục Thế giới số, mong muốn cống hiến cho sự phát triển của Tổ quốc Việt  Nam thân yêu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 460, tokens 169, triggered by: token limit\n",
      "\u001b[35mSuốt quãng đường từ Sài Đồng về Duy Tân - Cầu Giấy, từng tốp nhân sự của  Trung tâm Kỹ thuật vận hành CMC Telecom chia nhau túc trực khắp nơi để  giám sát các thiết bị trên đường vận chuyển, “thắp sáng những ngọn đèn”  trên đường tới tầng 3 CMC Tower - ngôi nhà mới của CMC Data Center. Cho đến nay, CMC Data Center Duy Tân luôn được khách hàng tin tưởng lựa  chọn là điểm đến.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 461, tokens 188, triggered by: token limit\n",
      "\u001b[31mCMC Telecom đã liên tục tối ưu, mở rộng, đặt thêm các  racks để phục vụ nhu cầu ngày càng lớn của khách hàng, đặt nền móng  vững chắc cho sự phát triển lĩnh vực cung cấp dịch vụ hạ tầng của CMC. .SUY SỤP  TRÊN ĐÁ CHIẾN THẮNG  Năm 2011, dưới tác động của khủng hoảng kinh tế và một phần sự thiếu hụt đường lối trong hệ thống quản trị, CMC gặp khủng hoảng nghiêm trọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 462, tokens 72, triggered by: token limit\n",
      "\u001b[32mCon thuyền trên đã tăng tốc bỗng “khựng” lại đột ngột, CMC đứng trước tình thế khó khăn vô cùng khiến những người thuyền trưởng “gần như suy sụp”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 463, tokens 145, triggered by: token limit\n",
      "\u001b[34m.\"Hồn nhiên\" tăng trưởng & cúi sóc bất ngờ   Những năm 2007 - 2008, trên thế giới diễn ra cuộc khủng hoảng kinh tế được đánh giá là “tồi tệ nhất trong lịch sử” bắt đầu với sự sụp đổ của ngành công nghiệp tài chính của Mỹ và lan rộng toàn cầu với sự đổ vỡ hàng loạt hệ thống ngân hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 464, tokens 159, triggered by: token limit\n",
      "\u001b[35mTại Việt Nam, môi trường kinh doanh có nhiều diễn biến bất lợi: nhập siêu cao, lạm phát leo thang, tỷ giá tăng mạnh, lãi suất tăng cao vượt kỷ lục trên 20% vào năm 2010 khiến Chính phủ phải điều chỉnh chính sách kinh tế từ thúc đẩy tăng trưởng sang giai đoạn kiểm chế lạm phát, thất chất tiền tệ, giảm chi tiêu đầu tư.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 465, tokens 127, triggered by: 0.18\n",
      "\u001b[31mCũng trong giai đoạn này, năm 2008, sau khi chuyển đổi mô hình, tăng nguồn lực; Tập đoàn CMC phát triển nhanh và mạnh với việc mở rộng lĩnh vực kinh doanh (Viễn thông, Bảo mật An toàn thông tin), đồng thời tiến quân ra thị trường quốc tế: Châu Âu, Nhật Bản.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 466, tokens 79, triggered by: 0.28\n",
      "\u001b[32mBén cạnh đó, các lĩnh vực truyền thông: Tích hợp hệ thống, phát triển phần mềm, sản xuất và Phân phối sản phẩm đã có chỗ đứng vững chắc trên thị trường, song ngành Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 467, tokens 118, triggered by: 0.38\n",
      "\u001b[34mVới mức tăng trưởng thần tốc, đội ngũ lãnh đạo CMC \"hồn nhiên\" nghĩ rằng, với cách quản trị đó, mô hình kinh doanh của Tập đoàn tiếp tục phi mã, miễn nhiễm với cơn \"nhấn chìm\" con tàu đang trên đà phát triển CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 468, tokens 171, triggered by: token limit\n",
      "\u001b[35mTuy nhiên, hai năm sau đó, cơn bão khủng hoảng chính thức ập đến với nguy cơ \"nhấn chìm\" con tàu đang trên đà phát triển CMC. .Trong cơn bão khủng hoảng  Do không có sự chuẩn bị và dự báo cập nhật biến động của thị trường kịp thời, năm 2011, kết quả kinh doanh của CMC bị sụt giảm nghiêm trọng về cả doanh thu và lợi nhuận so với những năm trước đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 469, tokens 157, triggered by: 0.36\n",
      "\u001b[31mChính sách cắt giảm đầu tư ở khổi Chính sách kiểm chế lạm phát của Nhà nước trong thị trường này bị trì hoãn, ảnh hưởng trực tiếp tới thu dự án công nghệ mạnh của lĩnh vực Tích hợp hệ thống là thế mạnh của CMC. Sự mua của thị trường cộng thêm nghành giảm sút và cạnh tranh cao khiến CMC cũng gặp khó khăn trong kinh doanh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 470, tokens 179, triggered by: token limit\n",
      "\u001b[32mTrong khi đó, lĩnh vực Viễn thông và Bảo mật tuy có sự phát triển nhanh chóng sau khi thành lập nhưng vẫn đang trong chu kỳ đầu tư. Lĩnh vực Bảo mật đối mặt với sự cạnh tranh của CMC Antivirus sụt giảm doanh số. Những chính sách quản lý chặt Internet, chủ trương ngầm hoá cấp, việc thay đổi chiến lược của các nhà mạng khiến lĩnh vực Viễn thông của CMC gặp không ít những thách thức.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 471, tokens 74, triggered by: 0.17\n",
      "\u001b[34mĐặc biệt, năm 2011 là năm rất khó khăn đối với lĩnh vực Sản xuất và Phân phối tại CMC bởi những khó khăn từ thị trường cũng như trong nội tại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 472, tokens 169, triggered by: token limit\n",
      "\u001b[35mDoanh thu. KHÁT  suy giảm mạnh, hàng tồn kho tăng cao tạo sức ép lớn về giá khiến lại góp giảm mạnh, chi phí tài chính và chi phí hoạt động ở mức cao khiến lĩnh vực này đứng trước “báo động đỏ”. Bên cạnh đó, dự án điện thoại Bluefone không đạt kế hoạch đề ra và lỗ tăng cao do ảnh hưởng từ cạnh tranh của đối thủ Nokia ở phân khúc giá rẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 473, tokens 129, triggered by: token limit\n",
      "\u001b[31mVới đặc thù là mặt hàng công nghệ, việc tồn kho càng lâu, sản phẩm càng lỗi thời, không đáp ứng được yêu cầu trên thị trường và trượt giá là điều tất yếu. Những ảnh hưởng cùng lúc ở mọi lĩnh vực khiến CMC phải chịu ảnh hưởng nặng nề của khủng hoảng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 474, tokens 105, triggered by: token limit\n",
      "\u001b[32mVừa niêm yết chứng khoán năm 2009 thì đến năm 2011, cổ phiếu CMG bị đưa vào diện kiểm soát đặc biệt vì kết quả kinh doanh ghi nhận lỗ gần 105 tỷ đồng trong khi cả hàng chục tỷ hàng tồn kho chất đống, nợ xấu tăng cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 475, tokens 166, triggered by: 0.08\n",
      "\u001b[34mViệc gồng gánh khoản lỗ lên tới con số trăm tỷ, bị đưa vào diện kiểm soát đặc biệt trên sàn chứng khoán không chỉ ảnh hưởng tới tài chính, danh tiếng mà còn có tác động mạnh mẽ tới hồ sơ năng lực đầu tư dự án. Khó khăn chất đống khó khăn đã khiến Minh Anh cùng các cộng sự bị “sốc” và gần như suy sụp trước tình thế của Tập đoàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 476, tokens 88, triggered by: 0.23\n",
      "\u001b[35m117.Trường Sa có nửa số ngày trong năm là những ngày nắng chang chang,  nắng đến nhức mắt. Ngoài cây bàng vuông trên đảo, chỉ có 2 loài cây dại  sống được trên đá san hô, đó là cây Phong ba và Bão táp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 477, tokens 52, triggered by: 0.23\n",
      "\u001b[31mNghe cái tên thôi  cũng đủ thấy dữ dội và vất vả đến thế nào! Có những đảo còn không có cây.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 478, tokens 149, triggered by: 0.01\n",
      "\u001b[32mBóng râm duy nhất tỏa xuống mặt cát bỏng là bóng dáng người lính. . . Lá đơn xin từ chức - Trách nhiệm của người đứng đầu  “Năm 2011 là một năm khó khăn nhất từ năm 1991 trở lại đây, tức là trong 20  năm gần đây” – theo đánh giá của chuyên gia kinh tế Việt Nam về tình hình  kinh tế Việt Nam bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 479, tokens 231, triggered by: token limit\n",
      "\u001b[34mThời điểm ấy, kết quả kinh doanh của CMC tụt giảm  nghiêm trọng cả về doanh thu và lợi nhuận. Đứng trước tình trạng vô cùng khó khăn với những vấn đề trong hệ thống  quản trị và khoản lỗ 100 tỉ đồng của năm tài chính 2011 – mức lỗ vô cùng lớn  sau 19 năm thành lập, anh Nguyễn Trung Chính - Tổng Giám đốc Tập đoàn  CMC trong giai đoạn đó, đã hứa trước Hội đồng Quản trị sẽ từ chức nếu không  vực dậy tình hình kinh doanh, đưa Tập đoàn CMC thoát khỏi khó khăn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 480, tokens 134, triggered by: 0.03\n",
      "\u001b[35mLá đơn  xin từ chức Tổng Giám đốc ngay sau đó được gửi cho Chánh văn phòng Tập  đoàn như thể hiện sự quả quyết và tinh thần chịu trách nhiệm của người  đứng đầu. Anh dặn dò chị Trần Mỹ Lê cất lá đơn này đi, nếu như kết quả của  CMC không tốt, anh sẽ chủ động từ chức.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 481, tokens 312, triggered by: token limit\n",
      "\u001b[31m.Hình ảnh: Lá cờ với lời nhắn gửi của Người CMC Hình ảnh: Anh Nguyễn Trung Chính  đại diện Người CMC gửi tặng tiền  và hiện vật tới các chiến sĩ Quay ngược thời gian, trở lại trước đó, với Giải thưởng Sao đỏ do TW Đoàn  Thanh viên Cộng sản Hồ Chí Minh trao tặng, Huân chương Lao động Hạng Ba  và hàng loạt bằng khen, giải thưởng cao quý do Chủ tịch nước và Thủ tướng  Chính phủ trao tặng cho Doanh nhân có thành tích xuất sắc, đóng góp tích  cực trong hoạt động doanh nghiệp trẻ, hoạt động thanh niên góp phần xây  dựng Tổ quốc, anh Chính đã tham gia Hội Thanh niên Việt Nam, Hiệp hội  Doanh nhân trẻ và nhận được lời mời đi Trường Sa.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 482, tokens 168, triggered by: token limit\n",
      "\u001b[32mTại thời điểm rơi vào bế tắc trong việc tìm hướng đi cho CMC, anh Chính nhận  lời mời ấy, một phần vì mong muốn thách thức bản thân trên hành trình đến  với vùng đất xa xôi và gian khó, phần vì mong mỏi được mang theo tấm lòng  của Người CMC đến thăm hỏi, động viên tinh thần cho những người chiến sĩ  ngày đêm bám đảo, giữ gìn hòa bình cho Tổ quốc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 483, tokens 197, triggered by: token limit\n",
      "\u001b[34mTháng 5 năm 2012, trên  chuyến tàu HQ571 của Bộ Tư lệnh Quân chủng Hải Quân, anh Nguyễn Trung  Chính cùng chị Triệu Thị Nga - khi ấy là Chánh Văn phòng CMC Soft, người đã  xuất sắc vượt qua hàng chục ứng viên nặng ký của cuộc thi viết “Người CMC  hướng tới Trường Sa” để trở thành tình nguyện viên CMC tham gia chuyến đi  ý nghĩa “Hành trình tuổi trẻ vì biển đảo quê hương” do Trung ương Đoàn TNCS  Hồ Chí Minh tổ chức.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 484, tokens 194, triggered by: 0.19\n",
      "\u001b[35mHành trang mang theo trên chuyến tàu ấy là 100 triệu đồng do Người CMC  quyên góp gửi tặng đồng bào  và chiến sĩ, 1 bộ máy tính CMS  trị giá hơn 6 triệu đồng và  những chiếc điện thoại  Bluefone của CMC. Đặc biệt  nhất là lá cờ ghi những lời  nhắn gửi thân thương từ người  CMC tới Trường Sa thân yêu. KHÁT .120  Tinh thần quật cường nơi đầu sóng ngọn gió - Trường Sa Anh Chính đã đến hầu hết các đảo:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 485, tokens 66, triggered by: 0.25\n",
      "\u001b[31mTrường Sa Lớn,  Trường Sa Nhỏ, Đá Tây, Đá Đông, Tốc Tan, Phan Vinh,  An Bang, Thuyền Chài, Núi Le, Tiên Nữ… và các đảo  nhỏ khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 486, tokens 57, triggered by: 0.25\n",
      "\u001b[32mVới những đảo có địa hình nguy hiểm, xuồng  máy khó vào được khiến đoàn phải hạn chế số lượng  thành viên lên đảo mỗi lượt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 487, tokens 90, triggered by: 0.25\n",
      "\u001b[34mCác trung đội phải xếp  hàng lần lượt, đợi thật lâu sau lái, nghe đọc đến tên  mình mới được xuống xuồng. Có hôm tàu gặp bão,  việc lên đảo phải hoãn lại để đảm bảo an toàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 488, tokens 141, triggered by: 0.22\n",
      "\u001b[35mAnh tâm sự: trước lúc đi, qua thông tin báo đài, anh đã được  nghe và đọc về sự khắc nghiệt và khó khăn nơi đây nhưng  anh không ngờ rằng, khi đến tận nơi, chứng kiến tận mắt  cuộc sống của người dân và chiến sĩ nơi đây, anh mới thấy  những khó khăn, vất vả sát thực đến thế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 489, tokens 53, triggered by: 0.11\n",
      "\u001b[31mXa đất liền đến 1.200 hải lý, Trường Sa có nửa số ngày trong  năm là những ngày nắng chang chang, nắng đến nhức mắt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 490, tokens 51, triggered by: 0.27\n",
      "\u001b[32mNgoài cây bàng vuông trên đảo, chỉ có 2 loài cây dại sống  được trên đá san hô, đó là cây phong ba và bão táp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 491, tokens 174, triggered by: 0.31\n",
      "\u001b[34mNghe cái  tên thôi cũng đủ thấy dữ dội và vất vả đến thế nào. Có những  đảo còn không có cây, bóng râm duy nhất tỏa xuống mặt  cát bỏng là bóng dáng người lính. Nơi đây còn có cả những  đảo chìm bé tí nổi giữa biển khơi, khi thủy triều lên, nước gần  như ngập hết đảo, chỉ còn lô cốt canh giữ đất trời của người  lính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 492, tokens 100, triggered by: 0.30\n",
      "\u001b[35mCuộc sống quanh năm của người dân cùng chiến sĩ thật  oi bức, tù túng và thiếu thốn. Thiếu thốn từ cơ sở vật chất.KHÁT  121 đến những thứ thiết yếu như rau xanh, điện, đặc biệt là nguồn nước ngọt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 493, tokens 104, triggered by: 0.30\n",
      "\u001b[31mNước ngọt chủ yếu trông vào nguồn nước mưa ít ỏi chứa trong những hầm,  những thùng dự trữ và phải dùng rất tiết kiệm, xoay vòng: tắm xong giữ lại để  tưới rau, tưới cây hoặc tái sử dụng trong việc khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 494, tokens 66, triggered by: 0.28\n",
      "\u001b[32mBên cạnh những ngày nắng cháy da, nửa số ngày trong năm Trường Sa vật  lộn với bão giông. Mỗi năm, không đếm nổi bao nhiêu cơn bão đi qua.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 495, tokens 114, triggered by: 0.28\n",
      "\u001b[34mCó  những cơn bão lớn đi vào lịch sử như bão Chanchu kinh hoàng năm 2006,  cũng có những cơn bão thường nhật quen thuộc như cơm bữa, bão đến rồi đi. Những cơn bão ấy đã khiến hàng ngàn người chết trên biển và nhiều chiến sĩ  hy sinh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 496, tokens 143, triggered by: 0.25\n",
      "\u001b[35mGiữa khó khăn của thiên nhiên, đôi lúc người chiến sĩ nơi đây còn phải  đối mặt với kẻ thù lăm le chiếm đảo. Nhưng dù khó khăn cỡ nào, họ vẫn kiên  cường bám biển và sẵn sàng hy sinh cuộc sống, tính mạng của mình vì sứ  mệnh thiêng liêng nơi đầu sóng ngọn gió.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 497, tokens 182, triggered by: token limit\n",
      "\u001b[31mQuan sát và trải nghiệm sự khắc nghiệt nơi đây, anh Chính nhận ra rằng: “Đối  mặt với khó khăn đến như vậy mà các chiến sĩ còn vượt qua được thì những  khó khăn của mình chưa là gì cả”. Điều đó đã tác động mạnh mẽ và trào dâng  trong anh sự quyết tâm: “Người ta có ý chí vượt qua được thì mình cũng có ý  chí để vượt qua khó khăn hiện tại của công ty”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 498, tokens 161, triggered by: token limit\n",
      "\u001b[32mNhững hình ảnh đáng nhớ về chuyến đi Trường Sa của anh Chính.Trong suốt chuyến đi, có lẽ điều xúc động  nhất là thời điểm con tàu đến đảo chìm Cô Lin  - điểm đến tưởng nhớ về sự kiện bi hùng không  thể nào quên: Hải chiến Trường Sa. Đây là vùng  biển nơi 64 anh hùng liệt sĩ đã hy sinh tạo nên  vòng tròn bất tử huyền thoại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 499, tokens 134, triggered by: 0.28\n",
      "\u001b[34mKhông khí linh  thiêng và tĩnh lặng bao trùm, các thành viên  làm lễ tưởng niệm những anh hùng liệt sĩ  giữa mênh mông sóng nước với tấm  lòng tự hào, biết ơn sâu sắc. Sứ mệnh cao cả .Rồi tàu đi qua đảo Gạc Ma và các vùng bị Trung Quốc chiếm đóng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 500, tokens 149, triggered by: 0.23\n",
      "\u001b[35mKhi đi qua  đây, mọi người phải giữ yên lặng tuyệt đối vì lý do an toàn. Nhìn từ xa, hướng  về những vùng đất của Việt Nam đã bị chiếm đóng với lô cốt hoành tráng, anh  Chính nhận ra: bằng khả năng quân sự và tiềm lực kinh tế vượt trội, Trung  Quốc đã phát triển các đảo trên Trường Sa rất mạnh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 501, tokens 57, triggered by: token limit\n",
      "\u001b[31mAnh ý thức sâu sắc:  “Ngoài ý chí thì mình phải giàu và mạnh. Mình phải thật mạnh thì mình mới  giữ được Nước”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 502, tokens 458, triggered by: token limit\n",
      "\u001b[32mCó lẽ chính điều này đã truyền cho người thuyền trưởng CMC thêm động lực  và quyết tâm phát triển CMC, góp phần xây dựng đất nước hùng cường như  chính sứ mệnh mà Tập đoàn CMC đã công bố và không ngừng nỗ lực từng  bước để thực hiện: “Dẫn đầu các làn sóng công nghệ mới, nỗ lực phát triển  những sản phẩm - dịch vụ - giải pháp công nghệ đẳng cấp thế giới, mang lại  những giá trị vượt trội cho khách hàng, góp phần nâng cao vị thế Việt Nam  trong kỷ nguyên số, xây dựng đất nước hùng cường.” KHÁT  123  Những hình ảnh đáng nhớ về chuyến đi Trường Sa.Giữa đại dương bao la, nơi mà sự sống và cái chết không còn là điều đáng sợ;  nơi mà ý chí, sự kiên cường giúp con người đối diện và vượt qua mọi khó khăn;  nơi đầu sóng ngọn gió linh thiêng của Tổ quốc, người thuyền trưởng của CMC  như được tiếp một nguồn năng lượng mới, được tái tạo và ý thức rõ hơn trách  nhiệm và sứ mệnh to lớn của mình với công ty, với xã hội và đất nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 503, tokens 160, triggered by: token limit\n",
      "\u001b[34mTrong  buổi sáng chào cờ cuối cùng để trở về đất liền, tiếng quốc ca trầm hùng hòa  vào biển trời, lá cờ đỏ sao vàng tung bay trong gió, tiếng cười khúc khích xa xa  của các em nhỏ sinh ra và lớn lên trên đảo đã giúp anh có thêm niềm tin mới,  một niềm tin tươi sáng về con người nơi đây cũng như niềm tin về một tương  lai mới cho CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 504, tokens 104, triggered by: 0.25\n",
      "\u001b[35mNăng lượng mới ấy, niềm tin mãnh liệt ấy cùng với tinh thần và trách nhiệm  của người đứng đầu đã thôi thúc anh dẫn dắt CMC nhanh chóng vượt qua khó  khăn và vững bước đi lên. Nguồn  năng lượng mới.Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 505, tokens 111, triggered by: token limit\n",
      "\u001b[31mNhững kỷ niệm trong chuyến đi Trường Sa  được anh Nguyễn Trung Chính nâng niu Trường Sa  -   Đi thật xa để trở về Chuyến đi Trường Sa năm ấy được ví như “chuyến đi thật xa để trở về”. Mỗi  lần nhắc tới Trường Sa, anh Chính không khỏi xúc động.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 506, tokens 150, triggered by: token limit\n",
      "\u001b[32mAnh đã mang về và  luôn giữ bên mình cát cháy cùng mảnh đá san hô nhỏ, một vài vỏ ốc xinh xắn  - một biểu tượng của Trường Sa gian khó nhưng đẹp vô cùng - cái đẹp từ  lòng can đảm và phẩm chất kiên cường của người Việt Nam. Những kỷ vật ấy vẫn luôn được đặt ở vị trí quan trọng trong Phòng truyền  thống của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 507, tokens 56, triggered by: 0.35\n",
      "\u001b[34mKhông những thế, anh còn rất nâng niu và mang về cây  bàng vuông ở Trường Sa trồng tại tòa nhà CMC Tower 11 Duy Tân.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 508, tokens 97, triggered by: 0.25\n",
      "\u001b[35mCây bàng  ấy vẫn xanh tươi như nhắc nhở anh, nhắc nhở Người CMC luôn giữ vững niềm  tin, đối diện với thử thách và quyết tâm tìm giải pháp vượt khó khăn để chinh  phục mục tiêu đặt ra.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 509, tokens 91, triggered by: 0.34\n",
      "\u001b[31mKHÁT .Sau chuyến đi Trường Sa, anh Chính quay về Tập đoàn, cùng anh Minh và  các cộng sự xây dựng lại tổ chức với quyết tâm “Khi kiên định đi theo con  đường đã chọn thì nhất định sẽ thành công”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 510, tokens 76, triggered by: 0.18\n",
      "\u001b[32mVực dậy.Với những thành công trong hơn 15 năm, CMC vẫn luôn tự tin với những mô  hình quản trị dựa trên năng lực cá nhân và kinh nghiệm tích lũy lâu năm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 511, tokens 150, triggered by: 0.34\n",
      "\u001b[34mTuy  vậy, đó chỉ là mô hình quản trị thuận tiện, mô hình đó không phù hợp với các  tập đoàn lớn và công ty đại chúng với đội ngũ nhân sự lên tới con số hàng  ngàn và nhiều lĩnh vực, mô hình kinh doanh. Với tầm nhìn vươn ra khu vực và  toàn cầu, CMC cần có sự thay đổi mạnh mẽ về cách thức quản trị.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 512, tokens 87, triggered by: 0.45\n",
      "\u001b[35mTrước đây, các anh đánh giá khả năng xử lý tình huống của mỗi người là yếu  tố quan trọng, nhưng với quy mô tập đoàn, tính quản trị khoa học lại là yếu tố  quan trọng bậc nhất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 513, tokens 59, triggered by: 0.25\n",
      "\u001b[31mNăng lực cá nhân muốn phát huy tốt phải dựa trên một  hệ thống quản trị khoa học, hệ thống chính sách đầy đủ, rõ ràng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 514, tokens 117, triggered by: token limit\n",
      "\u001b[32mCông tác  đào tạo, xây dựng đội ngũ được chú tâm nhiều hơn; các hoạt động hướng  dẫn, chuyển giao tri thức được triển khai một cách bài bản. Đội ngũ quản lý được đầu tư đi học về quản trị doanh nghiệp với những  chương trình uy tín.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 515, tokens 135, triggered by: token limit\n",
      "\u001b[34mBên cạnh đó, anh Hà Thế Minh đọc rất nhiều sách về  hoạch định chiến lược, tự nghiên cứu và tổ chức các workshop chia sẻ, thảo  luận nội bộ với mục tiêu giúp đội ngũ quản lý, lãnh đạo toàn Tập đoàn hiểu và  vận dụng những phương pháp quản trị khoa học trong công việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 516, tokens 156, triggered by: token limit\n",
      "\u001b[35mTập đoàn tập trung viết lại bộ tài liệu quản trị, điều chỉnh những điểm chưa  hợp lý và thúc đẩy sự phát triển của nội bộ công ty, thay vì chỉ tập trung vào  việc kinh doanh, phát triển mối quan hệ bên ngoài. Toàn bộ hệ thống về quản  trị được xây dựng lại, chuyển từ quan điểm quản trị dựa trên nhiều cá nhân  sang quản trị khoa học.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 517, tokens 136, triggered by: token limit\n",
      "\u001b[31mCông tác hoạch định chiến lược, kế hoạch kinh doanh và đầu tư hàng năm đối  với các đơn vị thành viên được triển khai. Tình hình thực hiện kế hoạch sản  xuất kinh doanh các đơn vị được giám sát định kỳ hàng tháng, quý nhằm  kiểm soát rủi ro và kịp thời đưa ra các biện pháp thực thi kế hoạch kinh doanh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 518, tokens 165, triggered by: 0.26\n",
      "\u001b[32mCác chính sách quản trị về tài chính, nhân sự, đầu tư được bổ sung và hoàn  thiện nhằm nâng cao hiệu quả hoạt động, kiểm soát rủi ro ở mức độ toàn Tập đoàn. KHÁT .Cú lội ngược dòng “tốc độ” Sau khi xây dựng lại hệ thống, kiểm soát rủi ro và đưa ra các chương trình  hành động quyết liệt, CMC đã bắt đầu có những dấu hiệu tích cực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 519, tokens 134, triggered by: token limit\n",
      "\u001b[34mCác lĩnh vực truyền thống trong Tập đoàn chủ động mở rộng thị trường,  không chỉ khai thác thị trường lớn của nhà nước mà mở rộng đấu thầu tại các  doanh nghiệp - nơi không quá khắt khe về yêu cầu, số năm tích lũy kinh  nghiệm mà chú trọng vào năng lực triển khai gói thầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 520, tokens 172, triggered by: token limit\n",
      "\u001b[35mNhững bước thay đổi  được thực hiện một cách chắc chắn với sự kiểm soát chặt chẽ về chi phí, đảm  bảo chuyên môn kỹ thuật, tối ưu hóa quy trình, rút ngắn thời gian triển khai…  Trước những khó khăn nội tại và đòi hỏi ngày càng khắt khe của thị trường,  Tập đoàn CMC đã thực hiện dự án tái cơ cấu lĩnh vực Tích hợp hệ thống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 521, tokens 157, triggered by: token limit\n",
      "\u001b[31mDự  án được bắt đầu từ năm 2010, là hành động chiến lược, được thực hiện trên  quy mô toàn quốc, bao hàm và tác động đến toàn bộ hoạt động của CMC SI. Ngày 29/08/2011, Chi nhánh CMC SI tại Tp.HCM đã chính thức chuyển đổi  thành mô hình Công ty TNHH MTV thuộc sở hữu của CMC SI nhằm tăng tính  chủ động tại thị trường phía Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 522, tokens 122, triggered by: 0.32\n",
      "\u001b[32mDự án tái cơ cấu đã mang lại cho lĩnh vực  Tích hợp Hệ thống CMC một diện mạo mới mẻ. Việc trở thành một tổ chức  linh hoạt hơn giúp CMC SI tập trung nguồn lực cho mảng dịch vụ ICT chuyên  nghiệp, chủ động trong tìm kiếm và khai thác thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 523, tokens 105, triggered by: 0.31\n",
      "\u001b[34mCác lĩnh vực mới như Viễn thông, Bảo mật nhanh chóng hoàn thành chu kỳ  đầu tư tích lũy, sẵn sàng bước vào chu kỳ phát triển, tạo ra những giá trị đóng  góp, tạo động lực cho sự phát triển của Tập đoàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 524, tokens 84, triggered by: token limit\n",
      "\u001b[35mNhững sự thay đổi này ngay lập tức mang lại hiệu quả khi kết quả kinh doanh  năm 2012 - 2013 đã có lợi nhuận dương trở lại lần lượt là 9 tỷ, 23 tỷ và những  thay đổi tích cực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 525, tokens 196, triggered by: token limit\n",
      "\u001b[31mTại lĩnh vực Tích hợp hệ thống và lĩnh vực Phát triển Phần  mềm, năng lực quản trị hợp đồng và dự án ngày càng hoàn thiện, đóng góp  tích cực vào nâng cao hiệu quả dự án, tối ưu chi phí triển khai, chi phí tài  chính và có góp phần nâng cao tỷ lệ lợi nhuận. Đến 2013, doanh thu của Tích  hợp hệ thống tăng 11%, lợi nhuận tăng 57%, một số mảng tăng gấp đôi so với  năm trước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 526, tokens 161, triggered by: 0.39\n",
      "\u001b[32mLĩnh vực Phát triển Phần mềm cũng tăng doanh thu 46%, lợi  nhuận tăng 8 lần so với năm trước tuy nhiên không đạt kế hoạch do liên  doanh CMC – Ciber (tiền thân là Segmenta - CMC) có mức hoàn thành thấp. Trong lĩnh vực Phân phối, mặc dù doanh thu và vị thế suy giảm do yếu tố thị  trường nhưng công ty vẫn nỗ lực thay đổi và thích ứng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 527, tokens 93, triggered by: 0.39\n",
      "\u001b[34mMô hình tổ chức đã có  thay đổi theo hướng thu hẹp phù hợp với chiến lược kinh doanh. Các quy trình  quản lý như hệ thống ERP, quy trình kinh doanh cũng được sửa đổi phù hợp .với quy mô của công ty.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 528, tokens 86, triggered by: 0.31\n",
      "\u001b[35mHệ thống đại lý được đánh giá xếp hạng và triển khai  các chính sách kinh doanh phù hợp với quy mô. Tất cả nhằm mục tiêu kiểm  soát và khắc phục công nợ tồn đọng trước đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 529, tokens 113, triggered by: 0.08\n",
      "\u001b[31mĐối với lĩnh vực Bảo mật, CMC Infosec tiến quân vào thị trường an toàn thông  tin cho hệ thống lõi của ngân hàng và được đánh giá cao bởi sự đầu tư bài  bản, kiến thức chuyên môn vững chắc, mở ra hướng đi mới sau khi thị trường  bán lẻ suy giảm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 530, tokens 89, triggered by: 0.27\n",
      "\u001b[32mNăm 2013, Tập đoàn đã hoàn toàn vượt qua được khó khăn, mà theo như  anh Chính dí dỏm so sánh, cảm giác như “chúng ta vừa thoát khỏi đợt ốm  nặng, thập tử nhất sinh”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 531, tokens 134, triggered by: 0.33\n",
      "\u001b[34mMặc dù chưa thể bứt phá và bùng nổ mạnh mẽ  nhưng với những kết quả tích cực, người CMC đã tạo cho mình niềm tin về sự  đồng lòng vượt qua khó khăn, đã tạo ra được con đường mới, một năng  lượng mới và những bài học quý giá để bắt đầu chuẩn bị cho chặng đường  mới đầy khát vọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 532, tokens 60, triggered by: 0.26\n",
      "\u001b[35mKHÁT .Tự tin chinh phục CMC đã bước sang tuổi 20 – tuổi của sức trẻ, tuổi của những ước mơ, những  hoài bão và lý tưởng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 533, tokens 50, triggered by: 0.41\n",
      "\u001b[31mKhát vọng tuổi 20 được lựa chọn là chủ đề xuyên suốt  Lễ kỷ niệm 20 năm thành lập với thông điệp:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 534, tokens 101, triggered by: 0.07\n",
      "\u001b[32mCMC là nơi để Người CMC gửi  gắm và cùng Công ty hiện thực hóa ước mơ. Mỗi người CMC là một sứ giả của lòng khát khao  Trải qua 20 năm, CMC đã khẳng định vị thế vững chắc của mình trên nhiều  lĩnh vực:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 535, tokens 177, triggered by: token limit\n",
      "\u001b[34mTích hợp hệ thống, Phát triển Phần mềm, Lắp ráp máy tính, Thương  mại dịch vụ và Viễn thông/Internet. Cái tên CMC được phủ sóng rộng rãi và  được nhiều người biết đến. Các sản phẩm của CMC được khách hàng, đối tác  công nhận. Bên cạnh đó, CMC còn vinh dự nhận được Huân chương Lao động  Hạng Nhì, Bằng khen của Bộ trưởng Bộ Thông tin & Truyền thông cùng nhiều  giải thưởng khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 536, tokens 211, triggered by: token limit\n",
      "\u001b[35mCMC đã trở thành ngôi nhà thứ hai, trở thành niềm tự hào của tất cả Người  CMC. Trong trái tim mỗi Người CMC có những hình bóng khác nhau, có người  tự hào vì những sản phẩm công nghệ xuất sắc, có người lại vì “trót” đem lòng  mến yêu con người, văn hóa CMC mà lựa chọn gắn bó,… Còn đối với Cố Chủ  tịch Hà Thế Minh: “Vào thời điểm này, nhiều người thường đặt câu hỏi cho tôi: .“Sau 20 năm điều tôi tự hào nhất là gì?”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 537, tokens 296, triggered by: token limit\n",
      "\u001b[31mNếu lựa chọn chỉ một, thì với tôi đó  chính là tập thể CMCers đã/ đang làm việc tại CMC. Trong hai mươi năm qua,  chúng ta đã cùng làm việc, cùng cống hiến, đã và đang cùng đóng góp  những giá trị vật chất, trí tuệ cho cho xã hội, cho đất nước và góp sức đưa  Công nghệ thông tin và Viễn thông trở thành một ngành dịch vụ quan trọng  của Việt Nam.” (Chia sẻ trên Báo Người CMC số tháng 03/2013) Người CMC đã kế thừa phẩm chất đáng quý của những người kỹ sư công nghệ  thời kỳ đầu, cùng nhau tạo nên bản sắc riêng của CMC: không khoa trương  nhưng nhiệt thành và thấu đáo trong từng việc mình làm, từng lời mình nói.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 538, tokens 82, triggered by: 0.44\n",
      "\u001b[32mTập đoàn Công nghệ CMC là tập hợp những con người giỏi về chuyên môn,  tâm huyết xây dựng công ty, quyết liệt và cam kết trong công việc, trong  từng hành động. Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 539, tokens 84, triggered by: 0.44\n",
      "\u001b[34mNgười CMC hướng tới khát vọng tuổi 20 KHÁT . 132  Quy luật của tạo hóa trong vòng đời vạn vật sẽ có lúc thăng trầm và sự phát  triển của mỗi công ty không nằm ngoài quy luật ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 540, tokens 145, triggered by: token limit\n",
      "\u001b[35mCMC đã có 10 năm khởi  đầu rực rỡ, bước vào giai đoạn 10 năm tiếp theo với những thay đổi quan  trọng trong chiến lược phát triển và mở rộng lĩnh vực kinh doanh. Sang đến  năm 2011 – 2012, Tập đoàn CMC cũng như nhiều công ty khác trong ngành  ICT, phải đối mặt với các thách thức không nhỏ trên thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 541, tokens 106, triggered by: token limit\n",
      "\u001b[31mTuy nhiên,  những khó khăn này đã giúp CMC vững vàng hơn, trưởng thành hơn, sẵn  sàng tinh thần và quyết tâm để vượt qua những thử thách ở phía trước, nắm  bắt cơ hội hiện tại và đón đầu những cơ hội mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 542, tokens 148, triggered by: token limit\n",
      "\u001b[32mCMC bước vào tuổi 20 với những hoài bão và ước mơ lớn cùng mục tiêu chiến  lược đạt doanh thu hợp nhất 5.000 tỷ và lợi nhuận hợp nhất 300 tỷ vào năm  2015, đồng thời tiếp tục duy trì vị thế công ty IT số 2 tại Việt Nam. .KHÁT  133  Chiến lược 2013 - 2015 của Tập đoàn CMC nhấn mạnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 543, tokens 120, triggered by: token limit\n",
      "\u001b[34mDịch vụ chuyên  nghiệp là năng lực cốt lõi và yếu tố quan trọng thúc đẩy sự thành công của  CMC trong giai đoạn tới. Lễ kỷ niệm 20 năm thành lập Tập đoàn được diễn ra tại Hạ Long, Sài Gòn và  Đà Nẵng trong không khí ấm cúng và đoàn kết.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 544, tokens 184, triggered by: token limit\n",
      "\u001b[35mNgười CMC đã cùng nhau gửi  đi những khát vọng tuổi 20, khát vọng về một tương lai vững mạnh, khát  vọng về một Tập đoàn CMC thịnh vượng với tâm thế mới, năng lượng mới để  cùng bắt đầu một chặng đường mới - chặng đường “Chinh phục thế giới số”. .## ĐẦU ẤN CHƯƠNG II khat (2003 - 2013)  ## ĐẦU MỐC LỊCH SỬ 2006 CMC thực hiện tái cấu trúc công ty, trong đó:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 545, tokens 130, triggered by: 0.36\n",
      "\u001b[31mCMC giữ vốn chủ sở hữu, đầu tư và định hướng chiến lược các hoạt động của công ty thành viên. Tại thời điểm này, CMC bao gồm 03 công ty thành viên hoạt động trong lĩnh vực CNTT: Công ty Máy tính CMS; Công ty Tích hợp hệ thống CMC (CMC SI); Công ty Giải pháp Phần mềm (CMC Soft).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 546, tokens 712, triggered by: token limit\n",
      "\u001b[32m02/07/2007 Thực hiện cổ phần hóa công ty. Công ty TNHH Máy tính Truyền thông CMC chính thức chuyển đổi thành Công ty Cổ phần Tập đoàn Công nghệ CMC - CMC Corporation  03/10/2007 Thành lập Công ty TNHH Phân phối CMC - CMC Distribution  12/10/2007 Thành lập Công ty Cổ phần Dịch vụ Viễn thông CMC - CMC Telecom  30/11/2007 Thành lập Liên doanh Segmenta - CMC  30/05/2008 Thành lập Công ty Cổ phần An ninh An toàn Thông tin CMC - CMC Infosec  05/09/2008 Thành lập Công ty Cổ phần Hạ tầng Viễn thông CMC - CMC TI.DẤU MỐC LỊCH SỬ 09/2009 Thành lập Công ty TNHH CMC Blue France tại Pháp 22/01/2010 Chính thức niêm yết hơn 63,5 triệu cổ phiếu với mã CMG tại Sở Giao dịch chứng khoán Hồ Chí Minh 31/03/2010 Trở thành cố đông chiến lược của Netnam 29/08/2011 CMC SI ra mắt đơn vị thành viên - Công ty TNHH Tích hợp Hệ thống CMC Sài Gòn - CMC SISG 02/03/2012 CMC Distribution đổi tên thành CMC P&T, nằm trong chiến lược tái tổ chức lĩnh vực sản xuất và thương mại Tạp đoàn 07/01/2013 Hợp nhất CMC Telecom & CMC TI KIẾN TẠO DI SẢN SỐ 137.GIẢI THƯỞNG GIAI ĐOẠN 2003 - 2013 2003 Huấn chương Lao động Hạng Ba của Chủ tịch nước cho anh Nguyễn Trung Chính 2005 Huấn chương Lao động hạng Ba của Chủ tịch nước Việt Nam trao cho CMC 2002 - 2009 Top 5 Công ty ICT Việt Nam do HCA xếp hạng tại ComputerWorldExpo liên tục trong 8 năm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 547, tokens 94, triggered by: token limit\n",
      "\u001b[34m2002 - 2009 Huy chương vàng ICT Việt Nam dành cho đơn vị phần cứng, phần mềm, tích hợp hệ thống có doanh số cao do HCA trao tặng tại Computerworld Expo. 2002 - 2009 Cúp vàng sản phẩm Công nghệ thông tin tại Việt Nam IT Week.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 548, tokens 245, triggered by: token limit\n",
      "\u001b[35m2003, 2005, 2007, 2008, 2009, 2010 CMC nhận Giải thưởng Sao Vàng Đất Việt do Hội các nhà doanh nghiệp trẻ Việt Nam trao tặng 2008 Bằng khen của Thủ tướng Chính phủ cho cá nhân anh Nguyễn Trung Chính vì đã có thành tích trong công tác từ năm 2003 đến 2007, góp phần vào sự nghiệp xây dựng Chủ nghĩa xã hội và bảo vệ Tổ quốc 2010 CMC nhận Huân chương Lao động hạng Nhì của Chủ tịch nước Việt Nam Máy tính CMS là thương hiệu máy tính duy nhất được Chính phủ trao tặng Biểu trưng “Thương hiệu Quốc gia”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 549, tokens 91, triggered by: 0.30\n",
      "\u001b[31m138  KIẾN TẠO DỊCH SẢN SỐ. CHẠY  Chương 3 - CHẠY là giai đoạn PHÁT TRIỂN mạnh mẽ, là giai đoạn bùng nổ và chảy hết mình của CMC trong 10 năm 2013 - 2023.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 550, tokens 172, triggered by: token limit\n",
      "\u001b[32mCùng khát khao Chính phục thế giới số và mục tiêu trở thành Tập đoàn số tỷ đô, CMC đã liên tiếp gặt hái được những thành công với 4 khối kinh doanh chiến lược: Công nghệ & Giải pháp, Hạ tầng số, Kinh doanh quốc tế, Nghiên  Trong giai đoạn này, Tập đoàn CMC đã có những bước phát triển được đánh giá mang tính “lột xác”, mạnh mẽ, hướng đến trở thành Tập đoàn số toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 551, tokens 141, triggered by: 0.06\n",
      "\u001b[34mCMC xác định rõ ràng tầm nhìn, quyết tâm chuyển đổi số cho khách hàng và tổ chức. Trong nội bộ CMC, tất cả các khối kinh doanh, back-office đều tham nhuan tu tuồng thay doi thay doi, thay đổi tư vệc hoc hoc, tri thuc, thay đổi cách nghĩ, cách làm; thay đổi quy trình làm việc; nâng cao năng lực quản trị.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 552, tokens 68, triggered by: 0.25\n",
      "\u001b[35m. . CMC đã đầu tư các nền tảng công nghệ số vào việc vận hành quy trình, quản trị nhân lực, như: Success Factors, các hệ thống tài chính, phân tích báo cáo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 553, tokens 141, triggered by: token limit\n",
      "\u001b[31mTất cả đều sẵn sàng cùng CMC chinh phục Digital Hub của thế giới. Khối Công nghệ & Giải pháp thực hiện hợp lực ONE CTS, trở thành đơn vị hàng đầu trong tư vấn, triển khai các giải pháp chuyển đổi số và bảo mật cho các tổ chức và doanh nghiệp, đặt mục tiêu doanh thu 10.000 tỷ và 3.000 nhân sự vào năm 2028.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 554, tokens 179, triggered by: token limit\n",
      "\u001b[32mKhối Hạ tầng số có bước phát triển mạnh mẽ, mang tầm vĩ đại và tiên phong, ngoài trợ thành nhà cung cấp dịch vụ hỗ trợ cơ sở hạ tầng số có độ, tích hợp viên thông và công nghệ thông tin cho khách hàng; đầu tư xây dựng hệ sinh thái 3 Data Center (DC) tại Hà Nội và TP.HCM với tổng quy mô lên đến 3.000 racks, đặc biệt là CMC DC Tân Thuận - DC hiện đại và an toàn nhất tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 555, tokens 171, triggered by: token limit\n",
      "\u001b[34mMục tiêu của Khối là dẫn đầu về Cloud và Data Center với 2.000 nhân sự vào 2028. Với chiến lược “Go Global” của Tập đoàn, khối Kinh doanh Quốc tế tiên quân ra thị trường nước ngoài, phát triển bùng nổ về quy mô và tốc độ tăng trưởng. CMC Global đặt mục tiêu trở thành đối tác uy tín toàn cầu trong triển khai lĩnh vực ITO và chuyển đổi số với quy mô 7.000 nhân sự vào 2028.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 556, tokens 148, triggered by: token limit\n",
      "\u001b[35mĐây cũng là giai đoạn đánh dấu bước ngoặt lớn của CMC khi đầu tư nghiêm túc vào nghiên cứu ứng dụng công nghệ với Viện CMC ATI và đặc biệt là bước tiến mới khi thành lập Đại học CMC - Đại học số đầu tiên của Việt Nam với sứ mệnh phùng sự cho đất nước, cung cấp nguồn nhân lực chất lượng cao cho thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 557, tokens 201, triggered by: token limit\n",
      "\u001b[31mChương 3 - CHẠY là tập hợp những câu chuyện truyền cảm hứng về quyết tâm và sứ phát triển của CMC, từng bước “Kiến tạo Di sản số” cho xã hội, gắn sự mệnh phát triển của công ty với sứ mệnh phát triển của quốc gia - dân tộc, xây dựng một Việt Nam hùng cường, hạnh phúc. 141.Mục tiêu tí độ KHÁT KHAO & CHINH PHỤC THẾ GIỚI SỐ  \"Tốt là kẻ thù của vĩ đại!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 558, tokens 55, triggered by: token limit\n",
      "\u001b[32mĐó là một trong những lý do chính giải thích vì sao có rất ít điều vĩ đại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 559, tokens 314, triggered by: token limit\n",
      "\u001b[34mQuá trình chuyển đổi từ \"tốt\" đến \"vĩ đại\" là một con đường dài và cam go.\"  (Trích \"Từ Tốt đến Vĩ đại\" - Jim Collins)  Khát vọng tạo đột phá  Qua 2 thập kỷ xây dựng và hình thành, tuy có những khó khăn, vấp ngã nhưng với niềm tin và sự nỗ lực không ngừng, CMC đã trở thành một Tập đoàn lớn mạnh, là một trong những công ty công nghệ đứng đầu tại Việt Nam, có đóng góp quan trọng trong sự phát triển của đất nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 560, tokens 53, triggered by: token limit\n",
      "\u001b[35mNgay sau thời gian vuột qua khủng hoảng, CMC đã nhanh chóng tăng tốc trở lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 561, tokens 206, triggered by: token limit\n",
      "\u001b[31mTrong năm 2014 - năm đầu tiên của giai đoạn phát triển mới, tổng doanh thu toàn Tập đoàn đạt hơn 3.260 tỷ đồng (tăng 14%), lợi nhuận trước thuế đạt 129,6 tỷ (tăng 6,4 lần) so với 2013. Đây là một cơ sở đáng mơ ước trong giai đoạn khủng hoảng chung của nền kinh tế lúc bây giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 562, tokens 189, triggered by: token limit\n",
      "\u001b[32m142 SỰ KỶ CMC 30.Cùng trong bối cảnh đó, khoa học công nghệ có những bước phát triển như vũ bão, internet trở thành phương tiện không thể thiếu của mọi người khi giao tiếp với thế giới văn vật (IOT), các công ty công nghệ ngày càng nhiều hơn, đem lại những giá trị to lớn cho con người. Bên cạnh đó, cũng có không ít những công ty tên tuổi đã đi vi không còn phù hợp và thích ứng với thời đại (như Nokia, Compaq,…).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 563, tokens 158, triggered by: token limit\n",
      "\u001b[34mKhông tự thoả mãn với những thành tựu đã đạt được, Ban lãnh đạo CMC nhận thấy cần phải có những thay đổi đột phá để trở thành công ty lớn mạnh hơn, không chỉ tốt mà phải “vĩ đại”…  “Hành trình của CMC như mới chỉ bắt đầu. Doạn đường chúng ta vừa đi qua đường như con qua nhỏ bé, quá ngắn ngủi so với dài đường đầy ắp cơ hội và thử thách.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 564, tokens 154, triggered by: token limit\n",
      "\u001b[35mNếu chúng ta không thay đổi, không tự làm mới mình, không tự trẻ lại và tự thích ứng, chúng ta sẽ già và sẽ không còn tồn tại như nhiều công ty công nghệ thông tin khác.”  (Anh Nguyễn Trung Chính - Tổng Giám đốc tập đoàn xác định)  Với định hướng ấy, CMC quyết định “lột xác” để thay đổi, đón đầu kỷ nguyên mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 565, tokens 107, triggered by: 0.29\n",
      "\u001b[31mBước đi đầu tiên trên hành trình lột xác đó là tập trung vào các hoạt động chiến lược; chủ trọng vào 3 trụ cột cốt lõi của CMC bao gồm: Tích hợp hệ thống, Viễn thông và Phần mềm; tạo nên thể kiềng ba chân vững chắc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 566, tokens 99, triggered by: 0.24\n",
      "\u001b[32mNgay lập tức, Ban chiến lược đầu tư tại Tập đoàn được thành lập: nhận nhiệm vụ yêu cầu, hướng dẫn các công ty thành viên, bộ phận chuyên môn thực hiện bài bản công tác hoạch định chiến lược và xây dựng kế hoạch.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 567, tokens 159, triggered by: 0.24\n",
      "\u001b[34mKhông khí thu thập tài liệu, phân tích, đánh giá, cùng nhau đưa những ý tưởng, giải pháp mới trở nên rộn ràng, hối hả. Khắp các văn phòng là tiếng trò chuyện hào hứng: “Tình hình tài liệu có gì hay không nào?”, “Báo cáo chiến lược thực tiễn, sâu sát, đi thẳng vào vấn đề và định hướng phát triển chủ không hình thức, chung chung.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 568, tokens 88, triggered by: 0.08\n",
      "\u001b[35mBằng tinh thần quyết liệt, tốc độ và đổi mới mạnh mẽ, cuối năm 2018, doanh thu hợp nhất toàn Tập đoàn đạt gần 6.000 tỷ đồng, lợi nhuận trước thuế đạt 300 tỷ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 569, tokens 127, triggered by: token limit\n",
      "\u001b[31mCon số này tăng gấp đôi so với năm 2014 (năm thứ 21 của CMC). .Tham vọng \"tỷ đô\"  - mục tiêu đầy thách thức  Trên đà tăng trưởng và những nền tảng công nghệ đã được xây dựng vững chắc, Ban lãnh đạo CMC đưa ra định hướng chiến lược 5 năm 2019-2023:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 570, tokens 187, triggered by: 0.04\n",
      "\u001b[32mTập đoàn công nghệ CMC sẽ trở thành Tập đoàn sở toàn cầu mang đẳng cấp quốc tế, mục tiêu đặt quy mô 1 tỷ đô và 10.000 nhân sự vào năm 2023 (doanh thu gấp 4 lần so với thời điểm 2019). Nhìn vào lịch sử tăng trưởng của CMC cũng như khả năng tăng trưởng của các công ty công nghệ thông tin Việt Nam tại thời điểm ấy, mục tiêu đạt doanh thu 1 tỷ USD vào năm 2023 là rất khó khả thi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 571, tokens 95, triggered by: 0.17\n",
      "\u001b[34mTuy nhiên, anh Chính chia sẻ: \"Kể từ khi còn là sinh viên cho đến khi đi làm, mình đều đặt cho bản thân những thách thức hay đối lúc là mục tiêu vượt giới hạn để thử thách chính mình xem có vượt được hay không.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 572, tokens 76, triggered by: 0.25\n",
      "\u001b[35mMình cũng hay chia sẻ với các bạn trẻ trong gia đình là: Nếu bạn không có mục tiêu cao để chinh phục nó thì cuộc đời cũng không như vậy thì mới phát triển và tiến bộ được.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 573, tokens 96, triggered by: 0.22\n",
      "\u001b[31mTổ chức cũng thế thôi. Trải nghiệm cá nhân ở một lĩnh vực khác là chạy bộ. Ở tuổi của mình thì không ai nghĩ có thể chạy được 21km thì trong vòng 1 năm mình đã tập và hoàn thành được mục tiêu của mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 574, tokens 180, triggered by: 0.08\n",
      "\u001b[32mMình đã và chạy với mục tiêu của mình mà theo \"pace\" (tốc độ) của người khác thì chết tôi.\"  Quyết liệt cùng cánh bạc lớn  Để hiện thực hóa chiến lược trở thành Tập đoàn sở toàn cầu và mục tiêu trở thành công ty tỷ đô trong 5 năm, Ban Lãnh đạo Tập đoàn đã quyết định tái cấu trúc CMC với 3 khối kinh doanh mới, chính thức đưa vào vận hành từ năm tài chính 2019, bao gồm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 575, tokens 122, triggered by: 0.32\n",
      "\u001b[34mKhối Công nghệ & Giải pháp, Khối Kinh doanh Quốc tế, và Khối Dịch vụ Viễn thông. Cũng trong năm nay, Tập đoàn kiến toàn lại bộ máy tổ chức, bố nhiệm dàn lãnh đạo với nhiều anh tài cùng CMC góp sức chinh phục những mục tiêu đầy tham vọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 576, tokens 168, triggered by: token limit\n",
      "\u001b[35m.Tuy nhiên, từ 2019 đến 2022, nền kinh tế trên toàn thế giới chao đảo bởi dịch Covid-19, ảnh hưởng nghiêm trọng đến mọi mặt của đời sống, xã hội. Điều này tác động không nhỏ đến con đường chinh phục mục tiêu chinh phục CMC. Trước tình hình đó, CMC liên tục thích nghi, thay đổi để điều chỉnh kịp thời các phương án, mục tiêu kinh doanh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 577, tokens 148, triggered by: 0.23\n",
      "\u001b[31mNăm 2022, CMC mở rộng lĩnh vực và tái cấu trúc thành 4 khối chiến lược, bao gồm: Khối Công nghệ & Giải pháp, Khối Hạ tầng số, Khối Kinh doanh Quốc tế, Khối Nghiên cứu và Giáo dục để cùng hợp lực, thúc hiện 20 big moves (thay đổi) quan trọng nhằm tạo đà tiến đến mục tiêu tự do vào năm 2028.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 578, tokens 117, triggered by: 0.34\n",
      "\u001b[32mTrong đó, Khối Hạ tầng số đã tiên  trên thành nhà cung cấp dịch vụ Data Center hàng đầu tạo mục tiêu SME và Bảo mật An toàn kinh thông tin với trung tâm dữ liệu hiện đại, an toàn nhất Việt Nam. Khối Công nghệ & Giải pháp tập trung chuyển đổi số toàn diện cho doanh nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 579, tokens 113, triggered by: 0.28\n",
      "\u001b[34mKhối Kinh doanh Quốc tế cung cấp các dịch vụ phát triển phần mềm, các dịch vụ quản trị ở quy mô lớn trên toàn cầu. Khối Nghiên cứu và Giáo dục phát triển nghề  liên kết CMC và nuôi dưỡng nguồn nhân lực chất lượng cao cho thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 580, tokens 135, triggered by: token limit\n",
      "\u001b[35mThành viên thuộc Tập đoàn và sức mạnh \"One CMC\" hứa hẹn sẽ mang lại bước tiến mới cho CMC. Tỷ đó chắc chắn không phải là mục tiêu dễ dàng nhưng với sức trẻ, bản lĩnh và sự quyết tâm của mình, CMC rất tự tin về sự chuyển mình đột phá để đi từ “tốt” lên “vĩ đại”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 581, tokens 166, triggered by: token limit\n",
      "\u001b[31m.Lột xác để  cất cánh Tối ngày 4/1/2017 tại khách sạn Marriott Hà Nội, Tập đoàn Công nghệ CMC đã  chính thức ra mắt nhận diện thương hiệu và công bố chiến lược phát triển  giai đoạn mới. Với chủ đề Transformation Today – sự kiện này đánh dấu sự lột  xác sau 23 năm hình thành và lớn mạnh của CMC nhằm khẳng định vị trí là  Tập đoàn Công nghệ hàng đầu Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 582, tokens 138, triggered by: token limit\n",
      "\u001b[32mChương trình gây ấn tượng cho khách mời và người tham dự với hình ảnh  truyền tải thông điệp của Tập đoàn CMC: chú bướm cất cánh bay cao. Để tự  tin cất cao đôi cánh trên bầu trời, loài bướm thường phải trải qua nhiều giai  đoạn chuyển đổi. Quá trình phát triển của CMC cũng như vậy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 583, tokens 177, triggered by: token limit\n",
      "\u001b[34mCMC đã trải  qua quá trình tích lũy những giá trị - chiêm nghiệm để xác định rõ hướng đi  BƯỚC CHUYỂN MÌNH ÐỂ CẤT CÁNH Bay Cao  Sự kiện Transformation Today đánh dấu buổi bình minh của một kỷ  nguyên mới đối với CMC. Sự chuyển dịch của CMC là một quá trình  toàn diện: từ tầm nhìn chiến lược, tầm nhìn thương hiệu đến phương thức  và cách làm việc của người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 584, tokens 116, triggered by: 0.30\n",
      "\u001b[35mSự chuyển dịch này giống như quá  trình một con tằm trải qua bao đau đớn và biến đổi, tự vươn lên mạnh  mẽ không ngừng hoàn thiện, khát khao và lột xác trở thành con bướm  rực rỡ bay lên bầu trời đầy mơ ước và hoài bão. .Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 585, tokens 88, triggered by: 0.29\n",
      "\u001b[31mChủ tịch Nguyễn Trung Chính phát biểu tại buổi ra mắt của chính mình và giờ đây, sẵn sàng bước vào hành trình mới với tâm thế tự  tin sau một quá trình tự thay đổi, tự “lột xác”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 586, tokens 66, triggered by: 0.37\n",
      "\u001b[32mCMC đang ở trong dòng chảy  của sự sáng tạo, đổi mới, sẵn sàng vượt qua các giới hạn và hướng đến tương  lai trường tồn, vĩnh cửu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 587, tokens 180, triggered by: token limit\n",
      "\u001b[34mNếu như khởi nguồn logo CMC những ngày đầu là các chữ cái đầu tên của hai  thành viên sáng lập: anh Nguyễn Trung Chính, anh Hà Thế Minh và Cộng sự;  hình ảnh quả địa cầu thể hiện khát vọng: hướng tới tương lai, mang những  tiến bộ của thế giới đến với người dân Việt Nam. Thì tại chương trình, CMC đã  công bố logo mới thể hiện tinh thần đổi mới và sáng tạo hướng tới những  mục tiêu mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 588, tokens 147, triggered by: token limit\n",
      "\u001b[35m.Vẫn là sự kết hợp hài hòa của các chữ cái C – M - C với những đường nét mềm  mại nhưng đủ vững chắc, logo mới của CMC thể hiện sự tăng trưởng bền  vững, màu xanh với ý nghĩa mang đến sự tin cậy, hoàn thiện và chuyên  nghiệp đồng thời cũng tượng trưng cho sự tươi trẻ, năng động.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 589, tokens 131, triggered by: 0.42\n",
      "\u001b[31mMàu xanh còn  là màu của sự trường tồn - vĩnh cửu, chứa đựng khát khao và quyết tâm phát  triển vươn xa hơn nữa của 1 Tập đoàn Công nghệ thông tin hàng đầu. Tại buổi lễ, Chủ tịch Nguyễn Trung Chính nhấn mạnh và khẳng định giá trị mà  CMC hướng tới:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 590, tokens 165, triggered by: token limit\n",
      "\u001b[32mCông nghệ vị cuộc sống – Công nghệ vị nhân sinh. Để thực  hiện mục tiêu đó, Tập đoàn CMC đã tái cấu trúc thành 3 khối kinh doanh  chính: Khối Công nghệ & Giải pháp (Technology & Solution), Khối Kinh doanh  Quốc tế (Global Business) và Khối Dịch vụ Viễn thông (Telecom), hợp lực để  đưa con thuyền CMC tiến nhanh và bước những bước phát triển dài trên hành  trình mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 591, tokens 185, triggered by: token limit\n",
      "\u001b[34m149  Vận mệnh tương lai của chàng khổng lồ  được đặt lên đôi vai của những người hùng tí hon Hành trình thực hiện mục tiêu trở thành Tập đoàn số tỷ đô không chỉ dừng lại  ở việc quyết liệt thực hiện các hoạt động tái cấu trúc kinh doanh và nâng cao  năng lực công nghệ, CMC còn nỗ lực trang bị những hành trang quan trọng  nhất, tạo động lực mạnh mẽ cho người CMC tự tin bước vào giai đoạn mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 592, tokens 159, triggered by: token limit\n",
      "\u001b[35mĐó là phát triển Văn hóa CMC - yếu tố quyết định sự phát triển và trường tồn  của doanh nghiệp  Năm 2018, với chủ đề Breaking Mind, Hội nghị chiến lược CMC tập hợp 65  lãnh đạo các cấp và key persons của Tập đoàn cùng các công ty thành viên  .với nhiệm vụ đặc biệt: chuẩn bị hành trang cho hành trình đầy hy vọng kế tiếp  của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 593, tokens 60, triggered by: token limit\n",
      "\u001b[31mVăn hóa CMC, giá trị cốt lõi người CMC một lần nữa được đưa ra đánh giá dựa  trên 3 giá trị cốt lõi hiện có:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 594, tokens 210, triggered by: token limit\n",
      "\u001b[32mTrách nhiệm – Cam kết, Sáng tạo – Đổi mới, và  Đồng đội. Đồng thời những người tham gia còn thảo luận sôi nổi về những giá  trị bổ sung, phù hợp với mục tiêu mới, bối cảnh hiện tại. 100% lãnh đạo đồng  tình với việc CMC cần chú trọng phát triển văn hóa doanh nghiệp, 97,5% lãnh  đạo sẵn sàng tham gia vào đội ngũ “Người truyền lửa” hoặc “Đại sứ văn hóa”  để góp phần xây dựng văn hóa CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 595, tokens 143, triggered by: 0.35\n",
      "\u001b[34mĐể thực hiện mục tiêu trở thành Tập đoàn tỷ đô, Tập đoàn số toàn cầu, Người  CMC cần nhanh chóng thay đổi để đáp ứng với những yêu cầu trong giai đoạn  mới. Song hành cùng điều đó là những giá trị văn hóa cốt lõi cần được phát  huy, những giá trị mới phù hợp với thời đại cần được đưa vào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 596, tokens 162, triggered by: token limit\n",
      "\u001b[35mVề những giá trị  bổ sung, có tới hơn 40% đề xuất bổ sung thêm giá trị Hướng khách hàng, giá  trị về Cam kết và Kỷ luật cũng được nhắc đến bên cạnh các đề xuất: Tử tế,  Linh hoạt, Thấu hiểu, Trách nhiệm, … Ngay sau kỳ họp chiến lược, công tác  xây dựng Bộ Giá trị cốt lõi Người CMC “phiên bản cập nhật” được tiến hành.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 597, tokens 93, triggered by: 0.28\n",
      "\u001b[31mBộ Giá trị cốt lõi 4C hoàn thiện thể hiện khát khao chinh phục thế giới số, là  kim chỉ nam cho mọi hoạt động, là bảo bối giúp Người CMC chinh phục ước  mơ chung của Tập đoàn bao gồm: Creativity:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 598, tokens 131, triggered by: token limit\n",
      "\u001b[32mSáng tạo là đam mê của Người CMC C-Speed: Tốc độ là lợi thế của Người CMC Commitment: Cam kết là sức mạnh của Người CMC Customer Centricity: Hướng khách hàng là triết lý hành động của Người CMC Bước sang năm 2019, Tập đoàn CMC cũng thay đổi slogan thành: “Aspire to  Inspire the Digital World” (Khát khao chinh phục thế giới số).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 599, tokens 192, triggered by: token limit\n",
      "\u001b[34mVới triết lý tập trung vào khát vọng (aspire), truyền cảm hứng (inspire), CMC  mong muốn tạo dựng niềm tin đối với khách hàng và tạo động lực cho những  người yêu công nghệ. Tập đoàn Công nghệ CMC đang khát khao vươn mình  thành Tập đoàn toàn cầu, khát khao tạo nên những bước đột phá trong làn  sóng công nghệ mới, khát khao trở thành Tập đoàn số, đi đầu trong chuyển  đổi số, cung cấp dịch vụ số cho khu vực và thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 600, tokens 79, triggered by: token limit\n",
      "\u001b[35mChỉ khi có khát khao và  đam mê, người CMC mới có thể cùng nhau tạo ra những giá trị vượt trội cho  khách hàng, thúc đẩy sự tiến bộ của xã hội, chinh phục được Thế giới số!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 601, tokens 190, triggered by: token limit\n",
      "\u001b[31m.Ngày 26/07/2019, báo giới rầm rộ đưa tin về buổi ký kết hợp đồng đầu tư với sự  hợp tác chiến lược toàn diện về công nghệ của đối tác nước ngoài vào một  doanh nghiệp công nghệ Việt Nam, dự án được coi là lớn nhất từ trước đến  thời điểm ấy. Samsung SDS chi 850 tỷ đồng mua 25 triệu cổ phiếu CMC. Sau  giao dịch, Samsung SDS trở thành cổ đông lớn nhất, sở hữu 25% vốn điều lệ  CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 602, tokens 144, triggered by: 0.14\n",
      "\u001b[32mThỏa thuận hợp tác giữa CMC và Samsung SDS là kết quả của những nỗ  lực to lớn trong quá trình khẳng định vị thế, uy tín cũng như năng lực của Tập  đoàn CMC trên thị trường Việt Nam và quốc tế. Phía sau thành công ấy là dáng hình nỗ lực của Người CMC, là những đêm  sáng đèn quyết tâm chinh phục thử thách khó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 603, tokens 195, triggered by: 0.11\n",
      "\u001b[34mTrong quá trình chuẩn bị hồ sơ  hợp đồng, theo thông lệ báo cáo thẩm định chi tiết (Due Diligence) đối với tập  đoàn gồm nhiều đơn vị thành viên sẽ mất ít nhất 2 tháng. Vì thế khi Chủ tịch  kiêm Tổng giám đốc của Samsung SDS - Dr.Hong hỏi: “Bao lâu có thể ký được  hợp đồng?”, pháp chế CMC đưa ra con số 3 tháng, trong đó: 2 tháng thực hiện  thẩm định chi tiết và 1 tháng đàm phán hợp đồng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 604, tokens 161, triggered by: token limit\n",
      "\u001b[35mKhi Dr. Hong hỏi 1 cán bộ  của Samsung SDS về thời gian thực hiện, vị cán bộ này trả lời là 1 tuần. Chủ  tịch nói ngay: “Sao phải 1 tuần, chỉ 3 ngày thôi”. Chính vì câu nói “chỉ 3 ngày thôi” mà cả 2 bên đều “vắt chân lên cổ” chạy hết  công suất. Chỉ sau mấy ngày, Samsung SDS đã ra được danh sách tài liệu cần  CMC cung cấp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 605, tokens 183, triggered by: token limit\n",
      "\u001b[31mTiếp đó, 1 tuần là khoảng thời gian Tập đoàn CMC và các.đơn vị/ công ty thành viên miệt mài không kể ngày hay đêm sáng đèn để tập  hợp tài liệu theo yêu cầu từ phía đối tác. Một tuần tiếp theo là thời gian để  đoàn Samsung SDS bay sang CMC làm việc trực tiếp, rà soát và thẩm định lại  các dữ liệu. Một tuần sau nữa, hai bên thống nhất mọi dữ liệu để ra báo cáo  phục vụ quá trình ký kết thỏa thuận.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 606, tokens 100, triggered by: 0.33\n",
      "\u001b[32mTất cả hoạt động chuẩn bị hợp đồng được diễn ra trong vòng chưa đến 1 tháng. Về hoạt động đàm phán, thông thường các đàm phán mua bán doanh nghiệp  phải diễn ra gần chục vòng trong một thời gian khá dài.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 607, tokens 130, triggered by: 0.13\n",
      "\u001b[34mNhưng với thương vụ  Samsung SDS, Chủ tịch Tập đoàn Nguyễn Trung Chính chỉ bay sang gặp Chủ  tịch Samsung SDS một lần duy nhất vào đầu tháng 7. Trong vòng hơn nửa  tháng sau đó, các thành viên trong đoàn đàm phán hai bên đã cùng nhau làm  việc chi tiết, chủ yếu qua các cuộc họp và hội nghị.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 608, tokens 136, triggered by: 0.10\n",
      "\u001b[35mNgười CMC đã dũng cảm và quyết tâm bứt phá và theo đó, trái ngọt thành  công đã đến với CMC. Đối với CMC, để đi đến dấu mốc thành công của dự án là  những ngày chạy đua với thời gian, phá vỡ giới hạn của bản thân, củng cố  thêm giá trị cốt lõi C-Speed vốn được thấm nhuần.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 609, tokens 67, triggered by: 0.33\n",
      "\u001b[31m.153 CUSTOMER CENTRICITY | Hướng khách hàng:  “Phải hiểu dịch vụ mình đang bán có ý nghĩa  như thế nào với người cần nó thì bạn mới bán  được hàng”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 610, tokens 139, triggered by: 0.19\n",
      "\u001b[32mAnh Đặng Tùng Sơn (Phó Tổng giám đốc CMC Telecom chia sẻ) Chia sẻ về giá trị Hướng khách hàng tại CMC, Anh Đặng Tùng Sơn – Phó Tổng  Giám đốc CMC Telecom nhớ lại một ngày mưa tầm tã năm 2016, khi vừa đặt  chân tới công ty, anh nhận được cuộc gọi điện thoại từ Đại sứ quán Hàn Quốc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 611, tokens 63, triggered by: 0.25\n",
      "\u001b[34mVừa nhấc máy, đầu dây bên kia vang lên những lời trách móc của ông Tham  tán vì đường dây Internet đứt lần thứ hai trong tháng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 612, tokens 109, triggered by: 0.29\n",
      "\u001b[35mTheo điều khoản hợp  đồng, công ty luôn xử lý sự cố trong vòng hai tiếng, chưa một lần vi phạm. Anh  Sơn tự nhủ: “Khó tính quá!”. Xin lỗi khách hàng xong, anh tính gọi đội Kỹ thuật  đến xử lý theo đúng hợp đồng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 613, tokens 58, triggered by: 0.26\n",
      "\u001b[31mNhưng phân vân một lúc, anh nghĩ phải giải  quyết triệt để nên phóng xe ra tận hiện trường giữa lúc mưa như trút.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 614, tokens 72, triggered by: 0.34\n",
      "\u001b[32m“Nếu tính về giá trị hợp đồng chỉ 6-7 triệu/tháng sao phải mất công? Hơn thế  nghĩ đơn giản, mưa gió thế này cáp đứt là điều dễ hiểu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 615, tokens 89, triggered by: 0.24\n",
      "\u001b[34mSong, tôi thấy áy náy  khi sự cố xảy ra liên tục tại Đại sứ quán Hàn Quốc. Hình ảnh doanh nghiệp Việt  Nam trong mắt quan chức nước ngoài sẽ không đẹp” – anh Sơn nói.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 616, tokens 54, triggered by: 0.33\n",
      "\u001b[35mRa đến  nơi, anh càng thấm thía vì sao ông Tham tán nổi nóng. Đường Internet của  CMC dùng để duyệt hồ sơ visa.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 617, tokens 183, triggered by: 0.19\n",
      "\u001b[31mCáp đứt, hàng trăm người xếp hàng chờ lấy  giấy tờ trong mưa lạnh. Anh Sơn nghĩ nếu là người nhà mình đứng xếp hàng cả  tiếng dưới mưa thì sao? Sau chuyến “trực tiếp đến hiện trường” đáng nhớ, Phó  Tổng giám đốc CMC Telecom chỉ đạo đội Kỹ thuật kéo thêm một đường dây  cáp cho Đại sứ quán Hàn Quốc để nếu dây này đứt có ngay dây thay thế trong  lúc chờ xử lý sự cố.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 618, tokens 101, triggered by: 0.10\n",
      "\u001b[32mCustomer Centricity với Người CMC bắt nguồn từ những  việc nhỏ như vậy. Nếu chúng tôi không thấu hiểu ý nghĩa dịch vụ mình cung cấp đến  những khách hàng cuối của doanh nghiệp, thì chúng tôi không thể  thành công.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 619, tokens 154, triggered by: token limit\n",
      "\u001b[34m.154  CREATIVE | SÁNG TẠO: C.OPE2N – khát vọng  chinh phục những đỉnh cao. Trong bối cảnh chuyển đổi số quy mô toàn cầu, với mục tiêu trở thành Tập  đoàn số góp phần xây dựng Việt Nam hùng cường; năm 2019, CMC ra mắt hệ  sinh thái hạ tầng mở cho doanh nghiệp và tổ chức có tên C.OPE2N (CMC Open  Ecosystem for Enterprise).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 620, tokens 152, triggered by: token limit\n",
      "\u001b[35mLà một hệ thống kiến trúc mở, tích hợp tất cả thế  mạnh công nghệ của CMC như Nền tảng Multi-Cloud, Nền tảng dữ liệu (Data  Lake), Trí tuệ nhân tạo (AI) và Nền tảng ứng dụng, Hệ sinh thái C.OPE2N cho  phép các cơ quan, doanh nghiệp và khách hàng của CMC có thể liên kết và  chia sẻ tài nguyên dữ liệu trên môi trường số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 621, tokens 199, triggered by: token limit\n",
      "\u001b[31mVới thông điệp “Kết nối chia sẻ  tinh hoa, cùng thành công” (Connect knowledge & success together),  COPE2N giúp CMC hiện thực hoá mục tiêu kết nối các đối tác để giúp doanh  nghiệp chuyển đổi số thành công, vươn xa dựa vào công nghệ số, dựa trên  triết lý Hướng khách hàng – Mở – Công bằng – Tin Cậy – Chia sẻ tinh hoa. Với hệ sinh thái C.OPE2N, CMC là đơn vị tiên phong dẫn đầu xu hướng chuyển  đổi số quy mô toàn cầu ngay tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 622, tokens 142, triggered by: 0.33\n",
      "\u001b[32mGiải thích về lí do xây dựng hệ sinh  thái hạ tầng mở trong thời điểm này, anh Nguyễn Trung Chính chia sẻ: “CMC  hay bất kì công ty công nghệ nào nếu không thích ứng với thời đại mới thì đều  đối mặt với hiểm nguy, như nhiều bài học từ những tên tuổi hàng đầu thế giới: Compaq, Nokia, Yahoo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 623, tokens 181, triggered by: 0.23\n",
      "\u001b[34mChúng tôi có nhận thức thay đổi và bắt buộc phải  chuyển đổi số từ lâu, biến năng lực từ product (sản phẩm) sang service (dịch  vụ), từ service sang Cloud, rồi xây dựng hệ sinh thái. Không làm hệ sinh thái  thì làm sao tích hợp với các đối tác cung cấp dịch vụ Cloud như Amazon,  Google, Microsoft? Không làm hệ sinh thái thì làm sao “gõ cửa” các thị trường  trăm tỷ USD như Nhật Bản, Hàn Quốc, Châu  u?\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 624, tokens 139, triggered by: 0.21\n",
      "\u001b[35mNếu không phải bây giờ thì  không bao giờ làm được”. Hệ sinh thái C.OPE2N là thành quả đổi mới trong công nghệ của CMC, là minh  chứng rõ nét và đầy cảm hứng về đam mê sáng tạo và khát vọng đem những  thành quả của mình góp phần vào sự phát triển của ngành công nghệ, vào sự  hùng cường của đất nước thân yêu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 625, tokens 140, triggered by: token limit\n",
      "\u001b[31m.155 Chủ tịch Nguyễn Trung Chính chia sẻ (năm 2019) COMMITMENT | CAM KẾT: Câu chuyện đêm  Giáng Sinh Trung tâm kinh doanh FSI của CMC SI với đặc thù triển khai dự án chuyển đổi  cơ sở dữ liệu, hoạt động chuyển đổi thường được thực hiện ban đêm để tránh  gián đoạn đến các hoạt động của khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 626, tokens 199, triggered by: token limit\n",
      "\u001b[32mCó lần, trung tâm nhận nhiệm  vụ chuyển đổi toàn bộ ứng dụng và cơ sở dữ liệu của Tập đoàn Bảo Việt. Đêm  Noel, dự án đã gần hoàn thành, dữ liệu của các đơn vị bên dưới như bảo hiểm,  ngân hàng, quỹ đầu tư… đã hoàn toàn ổn định, anh chị em hồ hởi bởi chuẩn bị  được về đón Giáng Sinh cùng những người thân. Nhưng đến bước cuối cùng  của công ty Chứng khoán Bảo Việt thì gặp trục trặc về dữ liệu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 627, tokens 162, triggered by: 0.25\n",
      "\u001b[34mHoạt động để  khắc phục đã diễn ra suốt đêm Giáng sinh và anh em dự án đã quyết tâm khắc  phục đến rạng sáng hôm sau để hoàn thành dự án đúng thời hạn. Và còn rất nhiều những câu chuyện, những con người CMC đang miệt mài  từng ngày từng giờ phát huy giá trị cốt lõi 4C để góp trí chung sức cùng phát  triển Tập đoàn CMC!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 628, tokens 122, triggered by: token limit\n",
      "\u001b[35mĐiều tôi tự hào trong suốt quá trình xây  dựng và phát triển CMC là việc có  được hơn 3.000 người cộng sự. Tôi  không coi các bạn là nhân viên mà coi  đó là những cộng sự đã chung tay góp  trí cùng tôi đưa CMC phát triển. Đó là  phần hồn của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 629, tokens 281, triggered by: token limit\n",
      "\u001b[31m.CHUYỂN ĐỔI SỐ ĐỂ TĂNG TRƯỞNG Thần tốc  CMC kiên định với tương lai trở thành nhà tư vấn, cung cấp dịch vụ chuyển đổi số, giúp doanh nghiệp và tổ chức trong nước số hóa thành công, góp phần định hình thị trường dịch vụ điện toán đám mây và phần mềm dịch vụ mới và dẫn dắt thị trường an ninh mạng. Để thực hiện mục tiêu ấy, CMC quyết tâm chuyển đổi hoạt động nội bộ sang phương thức mới. .Quyết tâm của Người đứng đầu  9 giờ sáng một ngày cuối tháng 8/2020, tại đại bản doanh CMC Tower Duy Tân, hơn 100 người hội hả bước vào căn phòng họp hơn 50 m2.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 630, tokens 168, triggered by: 0.35\n",
      "\u001b[32mHọ là những thành viên chủ chốt thuộc Dự án Chuyển đổi số của Tập đoàn công nghệ CMC, tham dự buổi khởi động dự án quy mô lớn do Tập đoàn Chuyển đổi số HDQT Nguyễn Trung Chính điều hành. Sau hơn một tiếng đồng hồ trao đổi tích nhiệt huyết, vị thuyền trưởng của CMC bước ra khỏi phòng họp với tâm trạng của một người truyền cảm hứng thành công.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 631, tokens 178, triggered by: 0.31\n",
      "\u001b[34mAnh ngồi vào bàn làm việc của mình, phồng tầm mắt ra bầu trời xanh ngắt và tâm sự cùng báo Đầu tư online: “Chúng tôi vẫn miệt mài lao động tiếp tục chiến đấu với những dự án, vừa chủ động, đề vừa chống dịch an toàn, nhưng chúng tôi vẫn đang sống từng ngày, từng giờ cho khát khao đó và sẽ luôn hành động để hiện thực hóa giấc mơ đó”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 632, tokens 80, triggered by: 0.25\n",
      "\u001b[35m157 .\"Đặt cược\" vào chuyển đổi số  \"\"  Muốn vậy, chỉ có một con đường là liên tục đổi mới. Luôn hướng tới vận động phát triển và đi lên thì sẽ không bao giờ thấy bế tắc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 633, tokens 83, triggered by: token limit\n",
      "\u001b[31m\"\"  Anh Nguyễn Trung Chính chia sẻ. Năm 2020, CMC đặt mục tiêu tăng trưởng doanh thu gấp 4 lần trong vòng 5 năm, doanh thu từ chuyển đổi số đóng góp ít nhất 50%.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 634, tokens 270, triggered by: token limit\n",
      "\u001b[32mCMC kiến định với nghiệp vụ chuyển nhòa tư vấn, cung cấp dịch vụ chuyển đổi số, giúp doanh tương lai trở thành nhà tư vấn, cùng góp phần định hình thị trường dịch vụ điện toán đám mây và phần mềm dịch vụ mới và dẫn đầu thị trường an ninh mạng. Để thực hiện mục tiêu ấy, CMC quyết tâm chuyển đổi hoạt động trong nội tại sang phù hợp  với  “ngôi  dưới  đây”,  tội  thành công rồi thì mới có thể cung cấp dịch vụ mạnh là năng lực của mình phải sẵn sàng theo – vì thuyền trưởng Nguyễn Trung Chính nhấn mạnh về quyết định của mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 635, tokens 112, triggered by: 0.26\n",
      "\u001b[34mBan lãnh đạo CMC xác định sự chuyển đổi ấy cần tiên hành nhanh nhưng của hội tụ sẵn sàng và sự chuẩn bị kỹ lượng, hướng tới sự phát triển bền vững của tập đoàn. Dòng long cứng  Ban chia sẻ giấc mơ CMC sẽ trường tồn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 636, tokens 116, triggered by: token limit\n",
      "\u001b[35m158  SỰ  KỶ  CMC 30.Hình ảnh: Chủ tịch Nguyễn Trung Chính nhấn mạnh trong workshop thảo luận Dự án Tu văn và Chiến lược chuyển đổi số cho Tập đoàn CMC - chuẩn bị sẵn sàng cho \"11 tuần máu lửa\" cũng dự án chuyển đổi số tại CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 637, tokens 119, triggered by: token limit\n",
      "\u001b[31mCMC đã lựa chọn đối tác McKinsey - công ty tư vấn quản trị toàn cầu, danh giá và lớn nhất trong nhóm \"Big-three\" trên toàn thế giới, thực hiện dự án tư vấn chiến lược phát triển, chuyển đổi số, tiến hành tái cấu trúc để phát triển mạnh mẽ và hợp nhất năng lực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 638, tokens 157, triggered by: token limit\n",
      "\u001b[32m“Hãy coi McKinsey là người bác sĩ đang giúp chúng ta, nếu như chúng ta không khai báo lịch sử bệnh, không mạnh dạn nói chúng ta đau ở đâu thì họ không thể giúp chúng ta được. Vì vậy, yêu cầu tất cả các thành viên trong team dự án của từng đơn vị cung cấp thông tin một cách đầy đủ, chính xác, khách quan để đảm bảo hiệu quả đầu ra”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 639, tokens 195, triggered by: 0.03\n",
      "\u001b[34mAnh Nguyễn Trung Chính chia sẻ về những thành tựu của năm 2018   159.Nguyên tắc “vừa chạy vừa xếp hàng”  Trong giai đoạn chuẩn bị cho sự chuyển đổi, CMC đã cẩn thận tiến hành từng bước kỷ càng. Từ việc nghiên cứu thị trường, triển khai chuyển đổi số tài chính CMC tới quá trình làm việc với McKinsey & Company để tìm hướng đi, một “cú hích” đẩy CMC lấn vào quỹ đạo của sự thay đổi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 640, tokens 142, triggered by: 0.29\n",
      "\u001b[35mHình ảnh: Người CMC nghiêm túc, quyết tâm thực hiện dự án Chuyển đổi số nội bộ  Anh Chính chia sẻ: “Trong quá trình chuyển đổi, tôi có một nguyên tắc là vừa chạy vừa xếp hàng, bởi chuyển đổi nhanh như vậy thì không thể không chạy nhưng chạy mà không có hàng lối thì sẽ rối loạn”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 641, tokens 57, triggered by: 0.19\n",
      "\u001b[31mCMC xác định năng lực quản trị của tổ chức không thể xây dựng ngày một ngày hai, cần có quá trình hoạch định và đào tạo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 642, tokens 89, triggered by: 0.21\n",
      "\u001b[32mNăng lực quản trị cần tương ứng với công cụ và hệ thống. Tinh thần nghiêm túc yêu cầu tốc độ được nhân mạnh đối với mỗi thành viên dự án chuyển đổi số nội bộ và lan tỏa tới mọi thành viên CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 643, tokens 176, triggered by: token limit\n",
      "\u001b[34mTrải qua 4 tuần làm việc nghiêm túc cùng McKinsey, chiến lược tích hợp 3-5 năm và lộ trình triển khai đã được McKinsey chỉ ra. Kết quả của dự án đã giúp CMC định hình các bước chuyển lớn trong tương lai, đồng thời hỗ trợ chiến lược và kế hoạch hoạt động của các Khối kinh doanh và các công ty thành viên. CMC đã sẵn sàng chuyển sang giai đoạn mới trong hành trình chuyển đổi số nội bộ - giai đoạn triển khai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 644, tokens 121, triggered by: token limit\n",
      "\u001b[35mTrong nội bộ CMC, tất cả các khối kinh doanh, kỹ thuật, backoffice đều thấm nhuần tư tưởng thay đổi, thay đổi tư duy, thay đổi quy trình, nâng cao quản trị… CMC đã đầu tư các nền tảng công nghệ số vào việc văn hành quy trình, quản trị nhân lực như:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 645, tokens 199, triggered by: token limit\n",
      "\u001b[31mSuccess Factors, các hệ thống tài chính, phân tích báo cáo… hướng tới tăng cường hiệu suất làm việc, nâng cao khả năng cung cấp dịch vụ, tối ưu hóa quản lý thông tin và tạo ra môi trường làm việc hiện đại, đổi mới sáng tạo. .SF4C - Ký niệm trên hành trình chuyển đổi số 8 tháng - 1500 giờ làm việc - 200 cán bộ quản lý - 1700 cán bộ nhân viên là những con số ấn tượng trong quá trình triển khai dự án SF4C của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 646, tokens 142, triggered by: token limit\n",
      "\u001b[32mNhững cố gắng nhận sự kết hợp cùng các thành viên của team dự án CMC Ciber (nay là CMC Consulting) đã trải qua nhiều buổi workshop, đào tạo triển khai ứng dụng hệ thống Quản trị và Phân tích Nguồn nhân lực (SAP Successfactor) với mục tiêu giúp toàn thể người CMC có thể sử dụng nhu một công cụ hỗ trợ công việc hiệu quả ngay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 647, tokens 190, triggered by: token limit\n",
      "\u001b[34mDự án nằm trong lộ trình chuyển đổi số và phát triển, đồng bộ hóa toàn bộ quy trình, nền tảng, công cụ của Tập đoàn CMC, hướng tới tối ưu hóa quy trình vận hành, nhằm mang trải nghiệm dịch vụ chuẩn thế giới tới khách hàng. Những ngày đầu triển khai dự án, nhóm kỹ thuật triển khai dự có hơn 10 năm kinh nghiệm triển khai các sản phẩm ERP của SAP nhưng với họ, đây là dự án Successfactor đầu tiên nhóm thực hiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 648, tokens 103, triggered by: 0.11\n",
      "\u001b[35mNhững ngày đầu, tin nắm lòng kiến thức kỹ thuật của SAP, nhóm kỹ thuật hùng hục khi thì mỗi các khách hàng nội bộ lên tăng 19 nhà CMC tham gia workshop, demo, giải thích các khái niệm hệ thống. Tuy nhiên người nghe chẳng hiểu gì.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 649, tokens 124, triggered by: 0.09\n",
      "\u001b[31mNhận về sổ từ trắng và những câu hỏi thể như về trời dẫn dắt xuống thành viên đối diện. Buổi workshop đầu tiên thất bại nhưng sự quyết tâm lại giúp các thành viên vực dậy, nghiên cứu giải pháp kỹ lưỡng hơn để từ đó CMC lên hệ thống rồi tổ chức workshop tiếp theo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 650, tokens 87, triggered by: 0.30\n",
      "\u001b[32mCứ như vậy, ròng rã 8 tháng, ngày 10/12/2019. .du an SAP Successfactor for CMC (SF4C) chính thức go-live, tạo bước chuyển biến đáng nhớ trong công tác quản trị nhân sự tại Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 651, tokens 108, triggered by: 0.17\n",
      "\u001b[34mCử bền bỉ và kiên trì, miệt mài với những mục tiêu chiến lược đã được hoạch định, Người CMC dẫn dắt đưa minh vào quy đạo của sự chuyển nghiệp, của những tiêu chuẩn quốc tế trong công tác quản trị, vận hành và thực thi công việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 652, tokens 124, triggered by: 0.31\n",
      "\u001b[35mKhi đại dịch Covid 19 ập đến bất ngờ và được đánh giá là một sự khủng hoảng đột ngột làm gián đoạn đời sống thường nhật của con người và công việc kinh doanh; các doanh nghiệp mới bắt đầu áp dụng hình thức làm việc tại nhà, họp hành và giao việc đều chuyển đổi sang online.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 653, tokens 64, triggered by: 0.28\n",
      "\u001b[31mNhưng những thay đổi rất nhanh đến mức nhiều người chưa kịp gởi tên đầy lại chính là câu chuyện vốn đã quen thuộc với Người CMC:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 654, tokens 118, triggered by: token limit\n",
      "\u001b[32mChuyển đổi số. Cũng bởi có phong trong hoạt động chuyển đổi số từ rất sớm, CMC đã nhanh chóng có cho mình những kịch bản ứng phó linh hoạt, người CMC tự tin duy trì các công việc thường nhật bởi được trang bị những \"vũ khí chuyển đổi số\" tiên phong.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 655, tokens 93, triggered by: 0.16\n",
      "\u001b[34m.Hòa mình vào trung tâm chuyển đổi số ONE CTS  Hành trình thực hiện sứ mệnh chuyển đổi số quốc gia, đồng hành cùng doanh nghiệp chuyển đổi số toàn diện đã – đang và sẽ luôn được CMC thực hiện với trách nhiệm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 656, tokens 162, triggered by: 0.40\n",
      "\u001b[35mKiến tạo Di sản số vì một Việt Nam hùng cường! Khát vọng dẫn đầu thị trường dịch vụ chuyển đổi số  Trong dòng chảy của quá trình chuyển đổi số, Tập đoàn CMC đã liên tục đón đầu và đưa các xu hướng công nghệ mới nhằm thúc hiện mục tiêu trở thành đơn vị hàng đầu trong tư vấn, triển khai các giải pháp chuyển đổi số và bảo mật cho các tổ chức doanh nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 657, tokens 121, triggered by: token limit\n",
      "\u001b[31mKhối Công nghệ Giải pháp CMC với nền tảng vững chắc là lĩnh vực Tích hợp hệ thống và Phát triển Phần mềm đã liên tục duy trì uy tín, thương hiệu, thể mạnh của mình trong các thị trường khách hàng truyền thống và không ngừng nâng cao năng lực, mở rộng thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 658, tokens 143, triggered by: 0.08\n",
      "\u001b[32m164 SỰ KỲ CMC 30.Những năm 2014 - 2018, lĩnh vực Tích hợp Hệ thống và Phát triển Phần mềm tại CMC luôn duy trì vị thế là đối tác hàng đầu của các hãng công nghệ lớn, khẳng định thế mạnh về năng lực trong các thị trường trọng điểm: Hạ tầng mạng, sao lưu, ảo hóa, lưu trữ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 659, tokens 81, triggered by: token limit\n",
      "\u001b[34m. . Đặc biệt, lĩnh vực Tích hợp hệ thống ở khu vực phía Nam đã đạt một tầm vóc mới với việc cán mốc doanh thu 1.000 tỷ đồng cho năm tài chính 2015.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 660, tokens 227, triggered by: token limit\n",
      "\u001b[35mNăm 2016, nhận thấy thực trạng nhiều doanh nghiệp trong quá trình chuyển đổi số thường loay hoay trong lĩnh vực bảo mật với tình trạng \"hồng đâu, và đấy\" - khi bị tấn công ở đâu thì bổ sung, gia cố, phòng ngự ở đó, bị động và luôn đi sau đối tượng tấn công; CMC với mục tiêu vun vã và cung cấp dịch vụ chuyên sâu dịch chuyển đổi số, nhanh chóng sắp nhập lĩnh vực Bảo mật vào Tích hợp Hệ thống để đồng hành toàn diện cùng các doanh nghiệp trong quá trình chuyển đổi số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 661, tokens 112, triggered by: 0.23\n",
      "\u001b[31mTình đến hết tháng 11/2018, doanh thu lũy kế của Tập đoàn CMC đã đạt 4.210 tỷ đồng, lợi nhuận trước thuế đạt 260 tỷ đồng. Có thể nói, thành quả này gần liên với phần khối \"Cloud\" khi ở cả 3 trụ cột kinh doanh chính:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 662, tokens 190, triggered by: token limit\n",
      "\u001b[32mTích hợp hệ thống, Phần mềm và Viễn thông đều có dấu ấn của điện toán đám mây (mô hình điện toán sử dụng công nghệ dựa vào mạng internet). Cụ thể, năm 2018, Công ty TNHH Tích hợp Hệ thống CMC (CMC SI) đã chuyển đổi hướng dịch vụ sang hạ tầng - ứng dụng - data - bảo mật, tập trung về bảo mật Cloud, Hybrid Cloud, tích hợp đã nền tảng & API, phát triển giải pháp trải nghiệm  Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 663, tokens 66, triggered by: token limit\n",
      "\u001b[34mSAMSUNG SDS vừa ký kết hợp đồng hợp tác chiến lược với Tập đoàn Công nghệ CMC.## Hợp lực sức mạnh để vươn xa khách hàng 360 (CSS).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 664, tokens 180, triggered by: 0.40\n",
      "\u001b[35mCùng trong giai đoạn này, Tập đoàn CMC đang tập trung đầu tư vào lĩnh vực An ninh An toàn thông tin và bước đầu gặt hái những thành quả với Công ty Cổ phần An ninh an toàn thông tin CMC (CMC Infosec) như việc hợp tác chiến lược với 4 trụ cột An ninh An toàn thông tin của Chính phủ, sản phẩm CISE chiếm số 1 thị phần tại các Bộ ban ngành trong yếu, dịch vụ bảo mật được triển khai cho 50% số lượng ngân hàng tại Việt Nam. .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 665, tokens 220, triggered by: token limit\n",
      "\u001b[31m. Trong lĩnh vực Phần mềm, 2018 là một năm thành công của Công ty TNHH Giải pháp phần mềm CMC Soft (CMC Soft) khi liên tục gặt hái những thành công lớn như hợp đồng hợp tác chiến lược với SAMSUNG SDS từ tháng 6/2018 để triển khai giải pháp quản lý  Năm 2018 CMC đã có nhiều thành công, có những mảng đâu tư chiến lược đã bắt đầu gặt hái được thành công như lĩnh vực An ninh An toàn thông tin, có những kí kết, hợp tác chiến lược với khách hàng, đối tác lớn trong nước và quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 666, tokens 70, triggered by: 0.37\n",
      "\u001b[32mNhưng nói như vậy không có nghĩa là chúng ta ngủ quên trên chiến thắng. Kỹ nguyên của những đột phá công nghệ đã mơ ra, khi những lot, Big Data, AI. .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 667, tokens 59, triggered by: 0.07\n",
      "\u001b[34m. không còn xa lạ. Ngay cả những công ty công nghệ lớn như Microsoft, SAP, Oracle. . . cũng bị dè dọa và phải thay đổi cơ cấu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 668, tokens 67, triggered by: 0.10\n",
      "\u001b[35mVi thế, CMC vẫn tập trung đặt chất lượng sản phẩm dịch vụ lên hàng đầu, vạch ra chiến lược tương lai mà toàn tập đoàn phải chung sức để đạt được.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 669, tokens 113, triggered by: 0.32\n",
      "\u001b[31mAnh Nguyễn Trung Chính chia sẻ về những thành tựu của năm 2018. .Với phương châm 'Hợp lực giúp sức mạnh CMC ngày càng vươn xa' , ngày 11/04/2019, CMC công bố thành lập Tổng Công ty Công nghệ và Giải pháp CMC (CMC Technology & Solution - CMC TS).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 670, tokens 118, triggered by: token limit\n",
      "\u001b[32mCMC TS là hợp lực của 4 công ty thành viên Tập đoàn CMC, bao gồm: Công ty TNHH Tích hợp Hệ thống CMC (CMC SI), Công ty TNHH CMC Sài Gòn (CMC SISG), Công ty TNHH Giải pháp Phần mềm CMC (CMC Soft) và Công ty Cổ phần An ninh An toàn Thông tin CMC (CMC Infosec).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 671, tokens 139, triggered by: token limit\n",
      "\u001b[34mVới việc kế thừa 26 năm phát triển và xây dựng các giải pháp tích hợp từ CMC SI, năng lực phát triển và triển khai phần mềm từ CMC Soft, nhà cung cấp dịch vụ CNTT và tích hợp số 1 ở thị trường phía Nam CMC SISG cùng nhà cung cấp các giải pháp ATTT hàng đầu Việt Nam về kinh doanh và công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 672, tokens 125, triggered by: token limit\n",
      "\u001b[35mVới đội ngũ gần 1000 cán bộ, chuyên gia trong lĩnh vực CNTT tại Việt Nam, CMC TS được Ban Lãnh đạo Tập đoàn CMC đặt kỳ vọng sẽ trở thành một trong những doanh nghiệp có vị thế hàng đầu về lĩnh vực CNTT tại Việt Nam, mang tầm nhìn vươn ra thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 673, tokens 103, triggered by: token limit\n",
      "\u001b[31m.Đồng hành chuyển đổi số cho khách hàng   Với việc hợp lực 4 công ty thành viên, CMC TS có doanh thu hợp nhất của 4 công ty đạt trên 3000 tỷ đồng trong năm tài chính 2019 đã là doanh nghiệp top đầu trong lĩnh vực CNTT tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 674, tokens 112, triggered by: token limit\n",
      "\u001b[32mCMC TS đặt mục tiêu chiếm lĩnh vị trí dẫn đầu về tư vấn giải pháp chuyển đổi số cho chính phủ, tổ chức và doanh nghiệp; cung cấp giải pháp điện toán đám mây (Cloud computing); dịch vụ dữ liệu và các dịch vụ an ninh an toàn thông tin.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 675, tokens 130, triggered by: token limit\n",
      "\u001b[34mVề các giải pháp phần mềm, CMC TS sẽ tập trung nguồn lực cung cấp giải pháp phần mềm cho ngành tài chính công, bộ ngành, ngân hàng và doanh nghiệp; các giải pháp thanh toán phức tạp, cung cấp các sản phẩm phần mềm theo mô hình kinh doanh SaaS (cung cấp phần mềm mang dịch vụ).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 676, tokens 155, triggered by: 0.24\n",
      "\u001b[35mNgoài ra, CMC TS sẽ tập trung nghiên cứu và phát triển các  công nghệ mới như Cloud, Big Data, SaaS model, IoT, FinTech, Insurance Tech… CMC TS đã tăng trưởng mạnh mẽ và đạt được những thành tựu kinh doanh ấn tượng. Khẳng định là doanh nghiệp số 1 chuyển tư vấn, triển khai các giải pháp chuyển đổi số và bảo mật cho tổ chức, doanh nghiệp Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 677, tokens 97, triggered by: token limit\n",
      "\u001b[31mTổng cộng  tỷ sở hữu mạng lưới 10.000 khách hàng trong và ngoài nước, trên 150 đội tác công nghệ, trên 1.000 chứng chỉ kỹ thuật và kinh doanh, phạm vi cung cấp dịch vụ phủ khắp 63 tỉnh thành.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 678, tokens 121, triggered by: token limit\n",
      "\u001b[32mTrải nghiệm khách hàng và tư duy dịch vụ là định hướng chiến lược phát triển quan trọng nhất của CMC TS với mong muốn mang những công nghệ mới nhất, giải pháp tốt nhất và dịch vụ CNTT chất lượng nhất đến khách hàng, đồng hành cùng tổ chức và doanh nghiệp chuyển đổi số thành công.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 679, tokens 195, triggered by: token limit\n",
      "\u001b[34m.Nhiều dự án quan trọng được CMC TS đã và đang triển khai thành công: dự án hỗ trợ ABBank trong việc xây dựng một nền tảng hội nhập số toàn vẹn thân thiện cho người dùng, vận hành giải pháp SAP Business One cho Tập đoàn DOJI, tham gia xây dựng hệ thống thông tin địa lý GIS cho chính quyền tỉnh Kiên Giang, góp phần tối ưu chi phí, thời gian quản lý thông tin và hướng đến xây dựng thành phố thông minh…  Nhờ hợp nhất các mạng kinh doanh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 680, tokens 157, triggered by: 0.30\n",
      "\u001b[35mTích hợp hệ thống, Giải pháp phần mềm CMC TS đã chuyển dịch sang chiến lược “Đồng hành chuyển đổi số cùng khách hàng”, tư vấn và triển khai giải pháp chuyển đổi số tổng thể nhằm mang tới bộ giải pháp toàn diện nhất cho khách hàng. Năm 2024, CMC đã tiên phong đón đầu làn sóng Al với mục tiêu đóng hành cung sứ mệnh chuyển đổi số quốc gia.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 681, tokens 191, triggered by: token limit\n",
      "\u001b[31mCMC nhận định, trí tuệ nhân tạo sẽ tạo ra một kỷ nguyên Al tác động rộng khắp đến xã hội loài người trên mọi mặt của đời sống, kinh tế, xã hội. Tại CMC, Al trở thành một phần không thể thiếu trong kế hoạch kinh doanh và chiến lược tập đoàn. CMC hướng tới mục tiêu ứng dụng các công nghệ Al giúp các đơn vị, tổ chức phát triển hiệu quả và sáng tạo Al kiểm soát và chi phí trong dài hạn thông qua sản phẩm của mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 682, tokens 189, triggered by: token limit\n",
      "\u001b[32mCác giải pháp Made by CMC như: Hợp đồng điện tử C-Contract, phần mềm ký số C-Sign đã được triển khai cho hơn 5000 khách hàng, đáp ứng nhu cầu ký số đa dạng, từ giao dịch giữa các cá nhân với nhau đến chính quyền sở, ngân hàng số, CMC đã có những bước chuyển đổi số dẫn đầu, đồng hành cùng các cơ quan chức năng trong quá trình hiện thực hóa nhiệm vụ quốc gia về Chính phủ số, Kinh tế số, Xã hội số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 683, tokens 81, triggered by: token limit\n",
      "\u001b[34mHành trình thực hiện sứ mệnh chuyển đổi số doanh nghiệp chuyên đổi số toàn diện đã - đang và sẽ luôn được CMC thực hiện với trách nhiệm: Kiến tạo Di sản số vì một Việt Nam hùng cường!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 684, tokens 213, triggered by: token limit\n",
      "\u001b[35m.## HẠ TẦNG SỐ Bước chạy đà cho tham vọng TỰ DO  \"Tự công ty cổ phần hạ tầng viễn thông đầu tiên tại Việt Nam, trở thành nhà cung cấp dịch vụ mạng có ảnh hưởng nhất tới sự phát triển của Internet Việt Nam trong dịch chuyển kỹ, tiếp tục gặt hái nhiều thành công vang dội khi tiến phong một thập kỷ mở hình sang nhà cung cấp dịch vụ hội tụ; CMC đã trải qua hành trình 15 năm đầy tự hào trong lĩnh vực Viễn thông - Hạ tầng số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 685, tokens 68, triggered by: 0.36\n",
      "\u001b[31mTừ hai thành một  Năm 2011, Luật Viễn thông có hiệu lực và cho phép mọi thành phần tham gia thị trường viễn thông. Cố chủ tịch Hà Thế Minh nhận định:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 686, tokens 85, triggered by: token limit\n",
      "\u001b[32m\"Đây là bước ngoạt, tạo cơ hội để Tập đoàn Công nghệ CMC thực hiện sáp nhập hai công ty của CMC đang hoạt động trong lĩnh vực này cùng các định hướng đầu tư mạnh mẽ nhất\".\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 687, tokens 129, triggered by: token limit\n",
      "\u001b[34mCác kế hoạch, hoạt động chuẩn bị sáp nhập được thực hiện từ năm 2012. Đến ngày 07/01/2013, Tập đoàn Công nghệ CMC chính thức công bố sáp nhập CMC Telecom vào CMC TI, trở thành công ty hoạt động trong lĩnh vực viễn thông, Internet - Công ty cổ phần Hạ tầng Viễn thông CMC (CMC Telecom).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 688, tokens 153, triggered by: token limit\n",
      "\u001b[35mSự kiện hợp nhất nhằm mục đích quy hoạch lĩnh vực hoạt động, tối ưu hóa chiều sâu, đẩy mạnh các dịch vụ và sản phẩm tiềm năng, đặc biệt thôi điểm sáp nhập, mạng kinh doanh viễn thông của Tập đoàn CMC đã đạt điểm hòa vốn (trước kế hoạch 2 năm) và bắt đầu có lợi nhuận từ năm 2012.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 689, tokens 155, triggered by: 0.01\n",
      "\u001b[31mVới đầu mục sáp nhập hai công ty về chung \"một nhà\", vốn chủ sở hữu CMC Telecom được tinh toán chạm mức tiêu doanh thu vào 2015. CMC đạt mục tiêu tăng lên 500 tỷ đồng vào 2015 đạt 1.000 tỷ đồng và phủ sóng mạng lưới dịch vụ tại 20 tỉnh thành lớn, sẵn sàng cho những mục tiêu và định mới trong lĩnh vực Viễn thông.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 690, tokens 148, triggered by: token limit\n",
      "\u001b[32m. KHÁT  LỄ CÔNG BỐ HỢP NHẤT CMC  CMC Telecom  /01/2013/  TIME dotCOM  và câu chuyện chấp nhận thương đau để bước tiếp, đứng vững và thật vững chãi   Trên trang mạng xã hội cá nhân của anh Hà Thế Minh, năm 2014 có đăng tải bức ảnh bầu trời trong xanh - kỷ niệm cuộc gặp gỡ trao đổi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 691, tokens 96, triggered by: token limit\n",
      "\u001b[34mSuốt sẽ cùng đối tác trong dự án tại thời điểm này. Đây là một dự án đặc biệt, không chỉ có ý nghĩa về mặt quản trị - kinh doanh mà còn mở ra hướng đi mới cho lĩnh vực Viễn thông của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 692, tokens 141, triggered by: token limit\n",
      "\u001b[35mSau khi sáp nhập, CMC đặt mục tiêu trong lĩnh vực Viễn thông: nâng cao chất lượng dịch vụ và nâng cấp, bổ sung dự phòng ổn định chất lượng đường truyền, hướng tới trở thành nhà mạng hội tụ mạnh mẽ về nguồn vốn, hoạt động xây dựng quản trị cần nhanh chóng thích ứng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 693, tokens 182, triggered by: 0.35\n",
      "\u001b[31m171.   Để thực hiện giấc mơ này, Ban lãnh đạo Tập đoàn quyết định tìm nhà đầu tư để đẩy \"đưa con tinh thần\" lớn nhanh. Đó là những ngày phòng làm việc của anh Minh không bao giờ tắt đèn. Rất nhiều cuộc họp nội bộ liên tiếp để tìm kiếm các quy đầu tư đúng giấc, các cuộc họp bàn tay, gật đầu rồi lại lác đầu khiến những người truyền trường Tập đoàn càng thăng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 694, tokens 80, triggered by: token limit\n",
      "\u001b[32mCũng trong thời gian này, theo chủ trương vươn ra khu vực Đông Nam Á của Chính phủ Malaysia, nhiều doanh nghiệp ở xứ sở đâu có tìm đến Việt Nam để nắm bắt cơ hội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 695, tokens 133, triggered by: token limit\n",
      "\u001b[34mQua giới thiệu, anh Minh, anh gặp TIME dotCom - công ty viễn thông hàng đầu tại Malaysia, được TIME dotCom có những kinh nghiệm và định hướng phát triển trong lĩnh vực viễn thông tương đồng với CMC. Đã có nhiều chuyến bay giữa Việt Nam và Malaysia để trao đổi hợp tác, cánh cửa hy vọng ngày một rộng mở hơn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 696, tokens 106, triggered by: token limit\n",
      "\u001b[35mSáng ngày 8/5/2015, CMC Telecom chính thức ký kết thỏa thuận đầu tư chiến lược với TIME dotCom, trở thành công ty có phần hạ tầng viễn thông đầu tiên của Việt Nam có cổ đông chiến lược quốc tế. TIME dotCom nắm giữ 25% cổ phần của CMC Telecom.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 697, tokens 122, triggered by: token limit\n",
      "\u001b[31mThông qua Hợp đồng Đầu tư chiến lược này, cả CMC Telecom và TIME sẽ chia sẻ và hỗ trợ nhau phát triển về công nghệ, dịch vụ, sản phẩm, đặc biệt là kết nối mạng lưới hạ tầng viễn thông quốc tế, cùng nhau khai thác tập khách hàng trong nước cũng như quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 698, tokens 191, triggered by: 0.27\n",
      "\u001b[32mLỄ KÝ KẾT HỢP ĐỒNG ĐẦU TƯ CHIẾN LƯỢC Strategic Investment Agreement Signing Ceremony CMC Telecom - TIME dotCom Berhad Hà Nội, 08* May 2015  .Sau khi ký kết hợp tác, nhiều đoàn chuyên gia của TIME đã sang Việt Nam làm việc với CMC Telecom. Nhận thấy thị trường Việt Nam có nhiều điểm tương đồng với những kinh nghiệm “xuống mẫu” của mình, TIME dotCOM tự vấn CMC Telecom nên tập trung khai thác đối tượng khách hàng doanh nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 699, tokens 125, triggered by: 0.19\n",
      "\u001b[34mVới những gì đã triển khai trong hơn 5 năm trước đó, nếu nghe theo tư vấn của đối tác, nhiều năm trời cố sức xây dựng mạng lưới Internet trên truyền hình cáp, mở rộng chi nhánh tại các tỉnh để tập trung vào phân khúc khách hàng hộ gia đình sẽ \"đổ sông đổ bể\".\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 700, tokens 68, triggered by: 0.29\n",
      "\u001b[35m\"Nếu bố, khác gì cát đi một phần có thể đâu\" - Anh Đỗ Đức Kiên, lãnh đạo Tập đoàn nói với chủ đề Mass or Not Mass được đưa ra lúc bấy giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 701, tokens 130, triggered by: 0.40\n",
      "\u001b[31mNhiều cuộc họp dành để trưởng đang phát triển nóng, viên thông một tương lai tươi sáng đồng thời công nghệ cấp) đã và đang nhanh chóng lỗi thời. CMC sẽ tập trung khai thác đối tượng khách hàng doanh nghiệp, chấp nhận thương đau để bước tiếp, đừng đường và thất vọng chán.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 702, tokens 161, triggered by: 0.30\n",
      "\u001b[32mtham vọng đưa Việt Nam  trở thành điểm kết nối hàng đầu khu vực.Sử kỷ CMC 30 Kiến tạo di sản số  Sau khi sắp nhập và được tiếp thêm \"sức mạnh\" nguồn vốn và kinh nghiệm, lĩnh vực Viễn thông của CMC đạt những cột mốc đầy tự hào.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 703, tokens 56, triggered by: 0.29\n",
      "\u001b[34mNăm 2012 - 2013, tốc độ xây dựng hạ tầng số của CMC bằng 5 năm công lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 704, tokens 131, triggered by: 0.09\n",
      "\u001b[35mTừ một nhà mạng non trẻ, CMC đã xây dựng được cạnh ngang qua cửa khảu Làng Sơn, Tây Ninh sang Trung Quốc, Campuchia, đứng ngang vai với các nhà mạng đối thủ để xây dựng cạnh quang biển.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 705, tokens 230, triggered by: token limit\n",
      "\u001b[31mHình ảnh: Người CMC cùng quyết tâm kéo cạp CMC di muôn nơi  Nhớ về kỷ niệm hoàn thành tuyến đường trục quốc tế, anh Đặng Tùng Sơn - Phó Tổng Giám đốc CMC Telecom kể lại  \"Chuyện công tác sang Hongkong để đật thiết bị tại tòa nhà Mega Millions danh tiếng rất đáng nhớ. Ở nhà là Phó Tổng giám đốc, Trưởng ban, Giám đốc Trung tâm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 706, tokens 87, triggered by: 0.34\n",
      "\u001b[32m. . nhưng qua đó, chúng tôi như tha bốc vác. Chi phí thuê di chuyển thiết bị đắt đỏ nên anh em tự bốc vác, di bộ cho tiết kiệm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 707, tokens 156, triggered by: 0.18\n",
      "\u001b[34mNgày chuyển thiết bị trời mưa tầm tẵm, máy anh em cổi áo khoác để bốc máy. Vaó đến Data center uốt nhụt, máy anh em cồi đầu ra lạnh thầu xong, nhưng chỉ cần nhìn thấy đường dây hộ thống bao mẹt mỏi tan biến.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 708, tokens 60, triggered by: 0.19\n",
      "\u001b[35mNhiều năm sau, anh vẫn thấy mình may mắn vì được chứng kiến khoảnh khắc tự hào:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 709, tokens 91, triggered by: 0.20\n",
      "\u001b[31mCMC Telecom bước ra thế giới.\" 174 Sử kỷ CMC 30.Tháng 12 năm 2017, CMC tiếp tục đặt dấu mốc mới khi hoàn thành tuyến cáp đường trục CVCS (Cross Vietnam Cable System) chỉ sau 8 tháng triển khai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 710, tokens 50, triggered by: 0.19\n",
      "\u001b[32mCVCS có tổng đầu tư hàng trăm tỷ đồng, dài hơn 2.500 km độc chiếu dài đất nước, đi qua 19 tỉnh thành.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 711, tokens 125, triggered by: token limit\n",
      "\u001b[34mCMC là đơn vị duy nhất sở hữu tuyến cáp quang ở Việt Nam kết nối trực tiếp vào mạng lưới cáp đặt liên thông cùng A - A-Grid. Cũng trong năm 2017, mạng xuống cả đến hơn 20 tỉnh thành cũng được CMC hoàn thiện với tốc độ xây dựng hạ tầng nhanh chóng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 712, tokens 79, triggered by: token limit\n",
      "\u001b[35mVới những dấu mốc đáng tự hào ấy, CMC đã trở thành một trong những nhà cung cấp Internet lớn nhất Việt Nam đồng thời góp phần giúp CMC nuôi ước mơ lớn:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 713, tokens 174, triggered by: token limit\n",
      "\u001b[31mDưa Việt Nam trở thành điểm kết nối hàng đầu khu vực châu Á - Thái Bình Dương  Từ ISP đến CSP Hành Trình Tự hào Sau 9 năm chinh phục thị trường, năm 2017, lĩnh vực Hạ tầng - Viễn thông của CMC được Hiệp hội Internet Việt Nam vinh danh là một trong 5 ISP (Internet Services Provider - Nhà cung cấp dịch vụ mạng) có ảnh hưởng nhất tới sự phát triển của Internet Việt Nam trong một thập kỷ (2007 - 2017).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 714, tokens 175, triggered by: token limit\n",
      "\u001b[32m.  2008 Thành lập Internet Services Provider (ISP) 2017 Converged Service Provider (CSP) 2023 Cùng trong năm 2017, khi CSP (Converged Service Provider) – nhà cung cấp dịch vụ hội tụ là khái niệm còn mới ngày cả trên thế giới, CMC đã tiên phong khi tuyên bố dịch chuyển chiến lược trong lĩnh vực từ một nhà cung cấp ISP sang CSP nhằm đem lại giải pháp tổng thể cho doanh nghiệp từ hạ tầng đến giải pháp chuyển đổi số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 715, tokens 199, triggered by: token limit\n",
      "\u001b[34mMột hệ sinh thái dịch vụ viễn thông – công nghệ và phát triển. Mô hình CSP – đầu tư ứng dụng nhu cầu thị trường trong thời kỳ chuyển đổi số toàn diện, đã đưa lĩnh vực hạ tầng – Viễn thông đến những thành tựu mới, đưa CMC thành công trong việc nhanh chóng đón đầu làn sóng Cách mạng Công nghệ 4.0. Bước chân đầu tiên của sự dịch chuyển này chính là nền tảng điện toán đám mây Make-in- Vietnam mà CMC đi tiên phong trong xây dựng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 716, tokens 195, triggered by: 0.23\n",
      "\u001b[35mCMC Cloud thể hiện quyết tâm xây dựng sản phẩm Việt để phục vụ nhu cầu của doanh nghiệp Việt lúc bấy giờ. Từ thành công của Cloud tự phát triển, liên tiếp những năm sau đó, CMC được chọn mặt gửi vàng bởi hàng loạt ông lớn về đám mây trên thế giới như AWS, Google Cloud, Microsoft khi họ đến Việt Nam. CMC đã trở thành nhà cung cấp dịch vụ Cloud nội địa hàng đầu Việt Nam, nắm giữ hơn 25% thị phần tính đến giữa năm 2023.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 717, tokens 103, triggered by: token limit\n",
      "\u001b[31mNhững trung tâm dữ liệu (Data center) đẳng cấp thế giới cũng dần được hình thành. .Trong hệ sinh thái hạ tầng số chuẩn mực, nếu coi mạng lưới hạ tầng viễn thông là mạch máu thì Data Center (DC) chính là trái tim của hệ thống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 718, tokens 142, triggered by: token limit\n",
      "\u001b[32mVới mục tiêu trở thành nhà cung cấp dịch vụ trung tâm dữ liệu trung lập số một Việt Nam, CMC đã mạnh dạn và quyết tâm xây dựng DC theo tiêu chuẩn quốc tế nhằm đáp ứng các yêu cầu cao nhất của các doanh nghiệp, đặc biệt là khối tài chính, ngân hàng, bảo hiểm và các tập đoàn đa quốc gia.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 719, tokens 174, triggered by: token limit\n",
      "\u001b[34mBộ trưởng Lê Doãn Hợp trao giấy phép ISP (Nhà cung cấp internet) cho CMC năm 2008  Nhớ lại dự án đầu tiên triển khai DC với khách hàng lớn ở mảng tài chính - ngân hàng với yêu cầu kỹ thuật phức tạp, phải di chuyển cả hệ thống phần cứng, phần mềm, hệ thống core banking của cả một ngân hàng; những người nắm vai CMC Telecom vẫn nhớ những ngày  hối hả chuyển đổi hệ thống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 720, tokens 144, triggered by: 0.12\n",
      "\u001b[35mSau nửa  kỳ sửa hạng trong 4 ngày nghỉ lễ, với hàng trăm công nhân,  kỹ sư công nghệ,  kỹ sư điện cùng làm việc với “tôn chỉ”:  bảo vệ kỹ thuật không trang nào được sai  dù chỉ một dấu phẩy, một đường kẻ. Con đường vận chuyển thiết bị về Data center của CMC dài 30km mà như cả  trăm cây số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 721, tokens 168, triggered by: 0.38\n",
      "\u001b[31mBữa trưa ăn với chiếc bánh mì, bữa tối ăn nhanh suất cơm hộp,  không ai ngần ngại đưa  vui  kỷ  nghi,  với công việc, quyết không  lui bước  trước khó khăn. Ngày  đóng  dữ  liệu,  các  anh  em  đứng giữa “thành đường” của  chính mình - Data center CMC và tự nhủ  cùng nhau:  “Chúng ta đã bước sang trang mới với những server, kết nối này”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 722, tokens 89, triggered by: 0.40\n",
      "\u001b[32m.Thành công của dự án đầu tiên ấy đã giúp CMC khẳng định vị thế của mình trong lĩnh vực, tự tin chinh phục khách hàng khói Ngân hàng – Tài chính, chứng minh vị thế Top 1 IDC Việt Nam trong phân khúc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 723, tokens 64, triggered by: 0.38\n",
      "\u001b[34mKể từ đó cho đến nay, CMC đã nhanh chóng vươn lên trở thành nhà cung cấp dẫn đầu về công nghệ trên đường đua xây dựng DC Việt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 724, tokens 73, triggered by: 0.42\n",
      "\u001b[35mTháng 5/2022, CMC Telecom đưa vào vận hành DC Tân Thuận (TP Hồ Chí Minh) với diện tích 10.000m2 cung cấp 1.200 rack, công suất điện lớn lên tới 20kw/rack.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 725, tokens 167, triggered by: token limit\n",
      "\u001b[31mCMC DC Tân Thuận được đánh giá là trung tâm dữ liệu hiện đại, an toàn nhất Việt Nam và khu vực APAC… CMC DC Tân Thuận được B-Barce-lona Singapore thiết kế tuân thủ theo các tiêu chuẩn khắt khe nhất cho một Trung tâm dữ liệu hiện đại như PCI DSS, ISO 27001:2013/ ISO 9001:2015. Đây là DC tiên phong ở Việt Nam có đánh giá phòng chống rủi ro TVRA và có chứng chỉ Uptime Tier III về xây dựng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 726, tokens 180, triggered by: token limit\n",
      "\u001b[32mHệ sinh thái DC của CMC đã góp phần hoàn thiện hạ tầng số quốc gia, tiến gần hơn tới mục tiêu đưa Việt Nam trở thành trung tâm lưu trữ và xử lý dữ liệu của khu vực và quốc tế. .SỰ KỲ CMC 30   CMC CORPORATION Aspire to Inspire the Digital World  LỄ KHAI TRƯỜNG TRUNG TÂM DỮ LIỆU CMC DATA CENTER TÂN THUẬN  CMC DATA CENTER TAN THUAN OPENING CEREMONY  TP.HỒ CHÍ MINH, 15.8.2022  Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 727, tokens 116, triggered by: token limit\n",
      "\u001b[34mLễ khai trương & Trung tâm dữ liệu CMC Data Center Tân Thuận  Với mục tiêu trở thành tập đoàn tỷ đô, năm 2022 Tập đoàn Công nghệ CMC có những động thái mạnh mẽ tái cấu trúc cho chiến lược trở thành Tập đoàn Công nghệ số 1 Việt Nam và khu vực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 728, tokens 177, triggered by: token limit\n",
      "\u001b[35mTheo đó, Khởi Hạng số của Tập đoàn CMC ra đời từ sự dịch chuyển khỏi Hạ tầng Viễn thông bao gồm CMC Telecom và Netnam sang Khởi Hạng số, tập trung vào kết nối băng rộng, trung tâm dữ liệu, điện toán đám mây và an toàn, an ninh thông tin. Sự bổ sung CMC Cyber Security sẽ giúp Khởi hạ tầng số chuyển đổi so với hạ tầng số hiện đại và an toàn theo tiêu chuẩn quốc tế cao nhất cho khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 729, tokens 136, triggered by: token limit\n",
      "\u001b[31mTrải qua hơn 15 năm hình thành và phát triển, CMC đã khẳng định vị thế của mình trong lĩnh vực Hạ tầng số – Viễn thông, từng bước cụ thể hóa mục tiêu đưa Việt trở thành Trung tâm Dữ liệu khu vực Digital HUB của Châu Á – Thái Bình Dương, góp phần xây dựng một Việt Nam hùng cường, lớn mạnh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 730, tokens 281, triggered by: token limit\n",
      "\u001b[32m180 SỰ KỲ CMC 30.Hình ảnh Còn mãi CƠ CHỦ TỊCH HẢ THỂ MINH   13 giờ 38 phút, ngày 19/06/2016, ngành công nghệ thông tin Việt Nam và Tập đoàn CMC bàng hoàng nhận tin Chủ tịch Hà Thế Minh qua đời khi ước mơ đưa CMC lên top đầu thị trường vẫn còn dang dở… Giữa tiết trời tháng 6 của Thủ đô Hà Nội, Người CMC cùng gia đình, bạn bè đón anh về sau một thời gian chữa bệnh từ nước Nhật xa xôi và vẫn chưa tin vào sự thật người lãnh đạo tài ba của mình đã mãi ra đi…  Cố Chủ tịch Hà Thế Minh sinh năm 1959, tốt nghiệp loại ưu Trường Đại học Bách khoa Budapest, Hungary năm 1983.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 731, tokens 196, triggered by: token limit\n",
      "\u001b[34mTừ năm 1983 đến 1986, anh Minh làm việc tại Liên hiệp MMG, Hungary. Đến năm 1986 - 1990, anh giữ vị trí Trưởng phòng Tin học, Viện Công nghiệp viễn tử, Viện nghiên cứu Công nghệ Quốc gia. Năm 1990 đến 1993, anh Minh và anh Chính xin thành lập Trung tâm ADCOM. Đến 26/05/1993, hai anh cùng nhau xây dựng nên Công ty HT&NT, đánh dấu bước ngoặt quan trọng, khai sinh ra Tập đoàn CMC ngày nay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 732, tokens 101, triggered by: token limit\n",
      "\u001b[35mVới 23 hình thành và phát triển CMC, anh đã để lại tiếng vang lớn trong ngành công nghệ, đưa CMC tiếp chinh phục nhiều thị trường, mang lại niềm tự hào, mối trường làm việc công bằng, hạnh phúc cho mọi thế hệ Người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 733, tokens 194, triggered by: 0.13\n",
      "\u001b[31mMọi người CMC, những đối tác, khách hàng sẽ không bao giờ quên hình ảnh người lãnh đạo lỗi lạc, có tầm nhìn xa trông rộng, luôn tìm hiểu học hỏi không ngừng nhưng cũng rất đời thường, gần gũi và quan tâm đến mọi người xung quanh. .## Một nhà lãnh đạo _Tài - Tâm_  Trong căn phòng truyền thông, nơi anh Hà Thế Minh đã từng làm việc khi còn sống là rất nhiều cuốn sách đã hoen màu thời gian.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 734, tokens 79, triggered by: 0.34\n",
      "\u001b[32mTrong đó có cuốn Hoạch định chiến lược và Quản trị nguồn nhân lực từ năm 1996. Ngay từ thời kì đầu, anh Minh luôn là người dẫn dắt và định hướng chiến lược cho CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 735, tokens 127, triggered by: 0.40\n",
      "\u001b[34mCòn anh Chính là người phát triển các mối quan hệ và kinh doanh giỏi, chính chiến với các dự án bên ngoài. Với tầm nhìn và chiến lược đúng đắn, hai anh đã đưa CMC gặt hái hết thành công này đến thành công lĩnh vực khác, từ hết lĩnh vực này sang lĩnh vực khác của ngành công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 736, tokens 99, triggered by: 0.26\n",
      "\u001b[35mVới công tác quản trị, anh luôn coi “Con người là tài sản lớn nhất của CMC”. Trong quá trình xây dựng Công ty và Tập đoàn, anh thường trăn trở về việc coi trọng năng lực và đảm bảo công bằng cho cán bộ nhân viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 737, tokens 138, triggered by: 0.31\n",
      "\u001b[31mAnh suy nghĩ, có những lúc thi công  tâm phải  trăn trở rất nhiều,  nhưng  lòng  lý  sao  để  thiếu  nhân  đơn  vì  kinh  doanh,  làm  sao  để  lại  hỗ nhân được lợi ích do chính mình  công  hiến  và  nỗ  lực,  làm  sao  để  ghi  nhận  ho  một cách xứng đáng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 738, tokens 195, triggered by: 0.33\n",
      "\u001b[32mChính từ cái ý nghĩ, cái tâm niệm ấy mà anh đã tìm hiểu về đánh giá nhân sự, về KPIs để đưa KPI về CMC, xây dựng chính sách lương thưởng công bằng cho mỗi cán bộ nhân viên của CMC. Đối với anh, tài chính, vật chất không phải là số một mà sự  nghiệp,  mong  muốn  được  công  hiến  hết  mình,  mang  lại  giá  trị  cho  con  người,  cho  xã  hội  mới  là  điều  quan  trọng  nhất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 739, tokens 102, triggered by: 0.27\n",
      "\u001b[34m.Một người thầy lớn, người anh lớn của CMC  Anh Minh là người rất chịu khó nghiện cừu tìm tới, ham đọc sách và chia sẻ lại cho mọi người.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 740, tokens 68, triggered by: 0.35\n",
      "\u001b[35mAnh đọc nhiều thể loại khác nhau, về chiến lược, kinh doanh, công nghệ và quản trị nhân sự.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 741, tokens 162, triggered by: token limit\n",
      "\u001b[31mAnh là người luôn tìm hiểu, nắm bắt được những xu hướng mới, phương pháp làm việc khoa học, hiệu quả. Không chỉ đọc, anh còn dùng kết quả tìm hiểu để áp dụng vào mô hình quản lý, kinh doanh hoặc cơ cấu tổ chức công ty.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 742, tokens 138, triggered by: 0.28\n",
      "\u001b[32mAnh cũng rất thích chia sẻ những kiến thức mà anh đã đọc, đã tìm hiểu được cho mọi người. Khi anh Minh bắt đầu chơi golf, anh đã dành vài ngày đọc một quyển sách hướng dẫn về golf.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 743, tokens 167, triggered by: -0.08\n",
      "\u001b[34mSau đó khi anh Chính sang gặp, anh Minh chỉ cần tốm tắt lại nội dung cho anh Chính trong 1 tiếng đồng hồ là anh Chính đã đủ năng lượng. Sáng sáng, mỗi khi gặp anh Minh, anh Chính nói  dung gì  mới không?\" anh Minh lại  truyền  dạt tiếp những nội dung anh  vừa miệt  mài  đọc  đêm  trước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 744, tokens 115, triggered by: 0.28\n",
      "\u001b[35m. . Vậy là anh  sách mà vẫn nắm bắt được các kĩ thuật  hay  đùa  nhau: \"Anh Minh là máy đọc sách  hưởng  thành  quả  mà anh Minh  truyền  dạt  lại.\"  Bên cạnh đó, anh Minh là người rất  hiểu cách  động viên, khuyến khích nhân viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 745, tokens 225, triggered by: token limit\n",
      "\u001b[31mChẳng hạn, khi muốn  tài  cơ  mô  hình  tổ  chức, quản tri của CMC, anh  sẽ  yêu cầu những thành viên trong  team tìm hiểu các  mô  hình quản tri trên  thế  giới  đó  và  xu hướng phát triển  của  thời  luân  để  có  được  nhiều  góc  nhìn  đa  chiều cũng như  y kiến phản biện. Đối  với  anh Minh, càng có nhiều ý kiến  càng  tốt, bởi  như  vậy  mỗi nhân viên sẽ có  hội  tu  trao  đổi, phát  triển  tu  duy của  Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 746, tokens 197, triggered by: token limit\n",
      "\u001b[32mCố Chủ tịch Hà Thế Minh. KHÁT  bản thân. Làm việc với anh Hà Thế Minh, anh em CMC thấy mình tiến bộ lên từng ngày, không chỉ trong công việc chuyên môn mà còn ở cách sắp xếp công việc, ứng xử với nhân viên, đồng nghiệp. Đối với nhân viên, anh Minh là một người rất bao dung, cởi mở. Phong cách của anh, như nhiều người CMC nhận xét, là vô cùng hòa đồng, anh chưa bao giờ nổi nóng hay quát tháo bất kỳ ai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 747, tokens 183, triggered by: token limit\n",
      "\u001b[34mAnh Minh sẵn sàng lắng nghe nhân viên chia sẻ tâm tư, nguyện vọng của mình. Khi nhân viên mắc lỗi hoặc có vướng mắc, anh sẽ cùng người đó ngồi lại tìm ra phương án giải quyết. Thậm chí có những trường hợp, anh Minh và anh Minh  luôn trực tiếp,  tư vấn để  lên gỡ của phòng nhân viên  cơ mà  thật  viện  lành  đào  năng  cho  nhân  viên  giải  tỏa  hết  bức  xúc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 748, tokens 168, triggered by: 0.29\n",
      "\u001b[35mCó những bản  làm  sai,  sau  khi  trao  đổi, anh  luôn  nói “Em về  suy  nghĩ  làm  lại  đi”,  chứ  không bao giờ trách mắng. Trong các buổi họp có anh Minh, mọi người có thể đặt bất kì câu hỏi nào và anh Minh sẽ giải thích  cụ  thể,  cặn  kẽ,  sử  dụng  các công thức, ví dụ rất rõ ràng để nhân viên có thể áp dụng được.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 749, tokens 170, triggered by: token limit\n",
      "\u001b[31m**Một người trầm lặng, đau đầu với công việc đến những phút cuối cùng**  Trong suốt quá trình xây dựng CMC, có không ít những khó khăn và thách thức, đặc biệt là những giai đoạn chuyển mình, hay giai đoạn CMC chịu thiệt hại nặng nề do kinh tế khó khăn và một trong khoảnh khắc  thì  chủ  tịch  tường  vỹ  -  phụ  nhân  của  anh  kể  lại:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 750, tokens 148, triggered by: token limit\n",
      "\u001b[32mTrong những lúc như thế, anh Minh  lo lắm, nhưng anh không bao giờ thể hiện ra, anh không muốn chia sẻ những khó khăn để làm người khác lo lắng mà sẽ tự mình giải quyết. Có lẽ, cũng chính vì vậy mà việc anh bị ốm nặng, anh phải nằm viện, phải phẫu thuật mà  rất ít người biết.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 751, tokens 107, triggered by: token limit\n",
      "\u001b[34mTheo ký ức của chi Vy, đó là vào  ngày  thứ  bảy, sau một số lần  anh  bị đau bụng và thấy hơi mệt nên quyết định đi khám ngay thứ năm sau đó, bệnh viện phát hiện một số biểu hiện bất thường nên yêu cầu anh đi khám lại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 752, tokens 199, triggered by: token limit\n",
      "\u001b[35mThứ bảy liên đó  anh  tự  đến  1  giờ  chiều,  anh  lại  vào  viện  thứ  rồi  tự lái  xe  về  nhà. Để yên tâm hơn,  để  khám  lại  xem  những  kết  luận  kia  có  chính  xác  không. Tuy  nhiên  kết  quả vẫn vậy. KIẾN TẠO DỊ SẢN SỐ 185.Rất nhanh sau đó, anh buộc vào ca mổ đầu tiên tại bệnh viện Việt Đức, chống chọi lại với căn bệnh hiểm nghèo.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 753, tokens 166, triggered by: token limit\n",
      "\u001b[31mViệc phẫu thuật ngày đó của anh không nói cho ai cả, mọi người trong công ty cứ nghĩ rằng anh đi công tác. Anh cũng xác định đi một vài tuần rồi về. Tuy nhiên, bệnh của anh ngày một trở nặng. Thời gian đầu, anh thi thoảng vẫn đến Công ty giám sát những công việc quan trọng; rồi sau các cuộc phẫu thuật, anh chỉ có thể ở trong bệnh viện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 754, tokens 195, triggered by: token limit\n",
      "\u001b[32mTuy ở viện, sức khỏe yếu nhưng ngày nào anh cũng cố đến chỗ anh để trao đổi, thảo luận công việc. Có những lúc, nằm trên giường bệnh, anh vẫn không ngồi công việc, vẫn đau đáu với tình hình hoạt động của Công ty. Tháng 3/2016, anh Minh sang Nhật do bệnh trở nặng và kể từ ngày đó cho đến nay anh Minh mất, anh em CMC hai kẻ của chị Trần My Lê, trước ngày về công ty để hỏi về công việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 755, tokens 225, triggered by: token limit\n",
      "\u001b[34mChắc hẳn, cho đến những mất, anh Minh vẫn nghĩ về CMC, nghĩ về của mình. Sự ra đi của cố Chủ tịch Hà Thế Minh là sự mất mát to lớn đối với ngành công nghệ thông tin - viễn thông Việt Nam nói chung và với mỗi người CMC nói riêng nhưng tinh thần, hình ảnh, con người anh vẫn luôn truyền cảm hứng và làm niềm tự hào để mỗi người CMC học tập và phấn đấu mỗi ngày để viết tiếp những ước mơ dang dở của anh, đưa CMC trở thành tập đoàn công nghệ hàng đầu thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 756, tokens 149, triggered by: 0.31\n",
      "\u001b[35mHình ảnh: Cố Chủ tịch Hà Thế Minh và người thân.Câu chuyện bên lề: \"Tôi đã gặp anh Minh như thế nào?\"   Vào một ngày cuối thu năm 1987, sau khi tốt nghiệp đại học Bách Khoa với tấm bằng loại giỏi, với tâm trạng phơi phới kiểu càng câu tốt nghiệp \"đem đủ, còn được xanh với cái nhãn xét:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 757, tokens 113, triggered by: 0.32\n",
      "\u001b[31m\"Mặc dù sinh viên tân mấy Chinh đã thể hiện khả năng làm việc và thực thụ…\". Tôi được một người quen là anh Trung Do Thái (togi) giới thiệu đến Viện Nghiên cứu Công nghệ Quốc gia Nacentech, với lời nhận xét \"luông cao, không cần thực tập, có biên chế!\".\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 758, tokens 67, triggered by: 0.03\n",
      "\u001b[32mước tổ chức viên giới thiệu và hẹn đến Viện (vì mỗi mặt chiếc xe đạp Cuốc - Liên Xô thân yêu, niềm kiêu hãnh của sinh viên thời đó.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 759, tokens 71, triggered by: 0.12\n",
      "\u001b[34m. .) Khi đó, Viện Nghiên cứu Công nghệ Quốc gia đang xây văn phòng và rải rác nhiều nơi, Viện được đặt tạm ở tòa nhà C15, Thành Xuân.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 760, tokens 67, triggered by: 0.21\n",
      "\u001b[35mCảm giác ban đầu khá thất vọng. Phòng họp dự các buổi  tại phòng  Viện  Viện  tư (sép xếp  lăm loạn máy  tinh  ngon  chất   kín.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 761, tokens 149, triggered by: 0.09\n",
      "\u001b[31mTuy nhiên, khi anh \"hàn  viên\" Hà Thế Minh đưa đi giới thiệu một  lượt   với   mọi  người   thì tôi   nhìn   thấy   có   dàn máy tinh  AT-286 trị giá khoảng 10.000 USD là khá ấn tượng. Anh Minh phòng vấn tôi tại phòng khách (là phòng bếp  cận  hộ),  có  ké   chiếc bàn  cũ  và  ấm  chén   trà.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 762, tokens 63, triggered by: 0.29\n",
      "\u001b[32mNhóm   bằng   điểm   trời   đuổi   biến   từ   các  món  đại  cuồng   đến   phổ  học   về   công   nghệ  thông   tin   mới   biết).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 763, tokens 170, triggered by: 0.14\n",
      "\u001b[34mTôi   như   thầm   chắc   thằng   cha   này  tổ   mổ   không   biết   trong   nước   học   hành   thế   nào   và   mình   có   học   thật   hay   bằng   đều   nên   hỏi   vu   vơ. Không  chỉ   vậy,   tôi  còn  thấy   văn  tố   tốan  Truong   phỏng  vấn  trọng  lành  đào  thấy   cũ  \"nhân viên tre mát non choẹt\"   ra   quá!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 764, tokens 132, triggered by: 0.26\n",
      "\u001b[35m! ! Khi đó  anh Minh  mới 28 tuổi và tôi  khong  biet  anh  Minh  là trưởng phòng. Điểm  chốt   là   anh   Minh   đem   một   sơ   đồ   mạch   nguyên   lý   và   phân   tích   mạch  để   xem   có   hiểu   và   có  đọc  được  bản  vẽ   sơ   đồ   vị   mạch   không.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 765, tokens 58, triggered by: token limit\n",
      "\u001b[31mTôi  cười  khây  và   thực   hiện  trời   chạy. Nhìn  vào   mặt   anh   Minh,  tôi  biết  anh  hài  lòng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 766, tokens 208, triggered by: token limit\n",
      "\u001b[32mSau   2   ngày   trả  lời  lên  gấp   tố   chức  để  biết  kết  quả,  làm   tôi   rất  bực  tức   nghĩ   thầm   \"thằng  cha\"  này   hành  minh, chắc  cha   có  quyền   hành   gì…  KIẾN TẠO SẢN SỐ 187.Khi đó, anh Minh còn chỉ vào một chiếc giường bật để ở góc phòng và tuyên bố “đây là giường của cậu kỳ tốt nghiệp loại giỏi từ Bulgari về làm được 6 tháng không đặt nền phải ra đi!”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 767, tokens 77, triggered by: 0.35\n",
      "\u001b[34mTôi nghe xong cũng thấy gai gai. Biết tôi có option làm chuyên tiếp nghiên cứu sinh, anh Minh nói: “Ở đây cần kỹ sư giỏi chứ không cần tiến sỹ giấy”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 768, tokens 164, triggered by: 0.29\n",
      "\u001b[35mCó vẻ như vừa câu, vừa de dọa. Tôi nghe xong thấy khoái! (điều này rất hợp với tôi vì lúc đó tôi đã chán học đến tận cổ và chỉ muốn đi làm kiếm tiền). Lúc phỏng vấn thì thoáng thấy người thở ra thút vào to mồ, sau này mới biết là hội nhân viên to mồ và cũng có phần lo lắng cho tôi. Họ thấy tôi bị quay ghế quá.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 769, tokens 59, triggered by: 0.27\n",
      "\u001b[31mChẳng là tôi là con cả đầu tiên dưới thời  Trưởng phòng - tuyên bố cần người giỏi có năng lực bắt cần mối thân quen.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 770, tokens 62, triggered by: 0.07\n",
      "\u001b[32mTôi muốn cảm ơn những người bạn khi đó (Tuấn Anh, Hải u, Quốc, Lân - Mitec), Hùng Soft, Hải, Ngà, Tấn và Khánh Godick.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 771, tokens 72, triggered by: 0.33\n",
      "\u001b[34m. .) đã chia sẻ và giúp đỡ tôi những ngày làm việc đầu tiên. Sau này khi đã là đồng nghiệp của anh Minh tôi vẫn nhớ mãi ký niệm khó quên này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 772, tokens 114, triggered by: 0.10\n",
      "\u001b[35mGhi lại điều này để các bạn trẻ chẳng may bị phòng vấn như tôi thì đừng oán trách sếp vì sau này khi làm sếp mình cũng thế. Đồng thời, chia sẻ kinh nghiệm để có thể lọt qua các vòng phỏng vấn là phải luôn luôn tự tin vào chính mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 773, tokens 174, triggered by: 0.17\n",
      "\u001b[31m.SỰ KỶ CMC 30 KIẾN TẠO DỊCH SẢN SỐ GLOBAL hành trình  VUỢN RA BIỂN LỚN Quyết tâm để con người Việt Nam, trí tuệ Việt Nam, công nghệ Việt Nam chính phục thế giới là mục tiêu kiên định trong suốt hành trình phát triển của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 774, tokens 81, triggered by: 0.35\n",
      "\u001b[32mQuyết tâm ấy đã, đang và sẽ được CMC hiện thực hóa cùng chiến lược Go Global với những thành tự rục rỡ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 775, tokens 157, triggered by: token limit\n",
      "\u001b[34mHoa tiêu của hài trình vuợn ra biển lớn 190 SỰ KỶ CMC 30.Có thể nói, hành trình vươn ra biển lớn của CMC đã nhen nhóm từ những năm đầu tiên của thế kỷ 21 với việc hợp tác cùng thành lập Hiệp hội Phần mềm và Dịch vụ CNTT Việt Nam nhằm xuất khẩu phần mềm Việt Nam ra thị trường quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 776, tokens 188, triggered by: token limit\n",
      "\u001b[35mNhưng hành trình vươn ra biển lớn của CMC chỉ thực sự thành công và gây tiếng vang lớn với sự quay lại thị trường xuất khẩu phần mềm cùng chiến lược Go Global trong thập kỷ thứ 2 của thế kỷ 21. Năm 2016 đánh dấu việc CMC tiếp tục hành trình ghi tên Việt Nam lên bản đồ công nghệ thế giới cùng nền móng đầu tiên là bộ phận cung cấp xuất khẩu phần mềm - CMC Offshore Development Center (CMC ODC) thuộc CMC Soft gồm 50 nhân viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 777, tokens 190, triggered by: 0.19\n",
      "\u001b[31mTrong kỳ hội nghị chiến lược năm 2015 tại Đà Nẵng, CMC ODC đặt mục tiêu thành viên lên tới 100, thành viên và nhanh chóng chạm mốc 200 người để tăng quy mô công ty, chính phục những khách hàng lớn. Hội nghị chiến lược kết thúc, tôi thứ 6 bên bờ biển Đà Nẵng, những nhân sự chủ chốt của Tập đoàn CMC cũng liên hoan trong sự hào hứng về một năm CMC ODC mới với nhiều dự định.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 778, tokens 75, triggered by: 0.11\n",
      "\u001b[32mAnh Bình đồng ý dẫn người đứng đầu tài chính - anh Nam có gang vị sáng sớm hôm sau anh Nam bay về Hà Nội để tiếp đó sang Úc gặp khách hàng làm về outsourcing.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 779, tokens 71, triggered by: 0.23\n",
      "\u001b[34mNhưng có những chuyến đi sẽ mãi mãi chẳng thể thành hiện thực. Người đứng đầu CMC ODC đã đột ngột qua đời ngay trong đêm tại Đà Nẵng vì sức khoẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 780, tokens 185, triggered by: 0.24\n",
      "\u001b[35mSau biến cố đó, anh Chính tham gia trực tiếp vào các hoạt động kinh doanh trong thị trường quốc tế. Sau khi được Ban lãnh đạo CMC định hướng phát triển tại lĩnh vực xuất khẩu phần mềm, CMC càng đẩy mạnh đầu tư nghiêm túc về quy mô, chất lượng dịch vụ, nguồn lực có chất lượng cao, tránh tâm lý “mua đâu chờ - bán cuối chợ”, không chờ đợi khách hàng đến mà cần xông xáo khai thác thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 781, tokens 158, triggered by: token limit\n",
      "\u001b[31mVới định hướng ấy, cuối năm tài chính 2016, CMC đã tách mảng xuất khẩu phần mềm, dịch vụ và sản phẩm công nghệ thông tin vốn trước đó là 1 bộ phận thuộc CMC Soft. CMC xác định “Go Global” chính là chiến lược trọng tâm trong giai đoạn phát triển mới với mục tiêu. Và từ đây, con thuyền CMC chính thức gióng buồm, tự tin vươn ra biển lớn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 782, tokens 144, triggered by: token limit\n",
      "\u001b[32mTrên cơ sở nghiên cứu thị trường và tầm nhìn của Ban lãnh đạo, CMC đã quyết định đầu tư thành lập CMC Global thuộc khối Kinh doanh Quốc tế với mục tiêu chiến lược đến năm 2020 đạt 310 tỷ đồng về doanh thu và hơn 1.000 nhân sự; 5.000 nhân tại châu Á và hơn, sang các nước khác ở Mỹ, châu Âu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 783, tokens 162, triggered by: token limit\n",
      "\u001b[34mVới việc thành lập Khối Kinh doanh Quốc tế, CMC hướng đến mục tiêu doanh thu 1 USD vào năm 2028 với trọng tâm dành cho thị trường nước ngoài, tiếp tục đưa Việt Nam trở thành trung tâm công nghệ mới của thế giới. .Chiến lược đầu tư cho lĩnh vực Kinh doanh Quốc tế được CMC đưa ra khá khác biệt so với các công ty outsourcing khác ở thời điểm ấy tại thị trường Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 784, tokens 206, triggered by: token limit\n",
      "\u001b[35mCMC sẽ chú trọng vào việc phát triển nguồn lực, chuẩn hóa quy trình cung cấp dịch vụ và phát triển phần mềm, đào tạo nhân sự chất lượng cao và thu hút số lượng lớn các nhân tài CNTT. Đồng thời, CMC Global không chỉ đơn vị xuất khẩu phần mềm, cung cấp các dịch vụ CNTT đa dạng tới khách hàng quốc tế, mà còn là đại diện và cầu nối của các công ty thành viên của CMC trong việc cung cấp các giải pháp và dịch vụ tích hợp trọn gói ra thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 785, tokens 129, triggered by: 0.30\n",
      "\u001b[31mMục tiêu doanh thu từ thị trường quốc tế được kỳ vọng sẽ lớn hơn doanh thu từ thị trường nội địa của Tập đoàn CMC. Để thực hiện chiến lược này, CMC đã chủ động đào tạo nguồn nhân lực chất lượng cao thông qua việc thành lập Trung tâm Đào tạo và Phát triển Nguồn nhân lực (RDC).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 786, tokens 105, triggered by: 0.02\n",
      "\u001b[32mTrung tâm có nhiệm vụ xây dựng và triển khai chương trình đào tạo nghiệp vụ bài bản, chuyển giao nghiệp, gắn liền với thực tiễn cũng đối với hơn 3.600 lượt học viên và tổng số giờ đào tạo là 63.000 giờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 787, tokens 123, triggered by: token limit\n",
      "\u001b[34mRiêng về tin. Ngay trong năm đầu tiên thành lập - 2018, RDC đã tổ chức 17 khóa học lĩnh vực công nghệ thông tin, trung tâm đào tạo hơn 256 học viên với 32.000 giờ trong lĩnh vực CNTT phục vụ nhu cầu của Tập đoàn Công nghệ CMC nói riêng và thị trường nói chung.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 788, tokens 210, triggered by: token limit\n",
      "\u001b[35m.Với việc đầu tư bài bản trong phát triển nguồn nhân lực cùng những nỗ lực trong tuyển dụng và xây dựng thương hiệu, chỉ sau 1 năm thành lập, số lượng nhân sự Khối Kinh doanh Quốc tế của CMC đã tăng trưởng gấp đôi, có những bước tiến khá, cán mốc 250 nhân sự. Đây là nền móng vững chắc để CMC phát triển rực rỡ, đạt mục 1.000 nhân sự, 2.000 - 3.000 nhân sự với những dấu ấn vàng đối trong lĩnh vực xuất khẩu phần mềm sau này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 789, tokens 165, triggered by: 0.06\n",
      "\u001b[31mĐóng chữ trên nắp capo phủ tuyết trắng và chiến thắng trong trái tim Người CMC  Dự án đầu tiên của Khối kinh doanh Quốc tế yêu cầu 30 nhân sự trong thời gian ngắn, công tác tuyển dụng ngay lập tức được triển khai. Có những ngày, hơn chục cuộc phỏng vấn nhân sự được diễn ra tại CMC Global, ánh đèn tại CMC Global chưa bao giờ tắt trước 9 giờ tối.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 790, tokens 78, triggered by: 0.37\n",
      "\u001b[32mCuối cùng, cuộc chạy đua nước rút cũng đi đến hoàn thành kế hoạch để ra quân. Dự án cần Tết 2017, các nhân viên on-site vừa sang nước bạn nên không thể về đón Tết.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 791, tokens 131, triggered by: token limit\n",
      "\u001b[34mMột buổi đêm muộn nọ, bức ảnh tuyết phủ đầy cốp trên nắp capo xe được gửi về, điều đặc biệt trên nền trắng xóa ấy khiến những người ở CMC anh được gửi về Việt Nam với tin nhắn “Em nhớ nhà” khiến đồng nghiệp quản lý tại CMC Global chợt cay cay nơi mắt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 792, tokens 160, triggered by: token limit\n",
      "\u001b[35mCó lẽ, CMC là bao yêu thương và CMC Global đã ngủ ngon kỹ như được đến tên một công ty non trẻ thuộc về, hai nữa nhưng người con xa xứ, đặc biệt của CMC đã trao trọn như thế lĩnh vực Xuất khẩu phần mềm, không chỉ trong thường trường, trong dự án lần này mà ở cả lẽ chiến thắng lớn nhất mà CMC Global làm được là có được sự tin yêu của những cán bộ nhân viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 793, tokens 124, triggered by: token limit\n",
      "\u001b[31m.CMC Japan Điểm dừng chân đầu tiên  Khởi Kinh doanh Quốc tế CMC đặt mục tiêu đẩy mạnh phát triển kinh doanh tại các thị trường Nhật Bản, Hàn Quốc và Singapore. Để chinh phục những thị trường khó tính này, việc phù sóng thương hiệu và tiếp cận các khách hàng được chú trọng thực hiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 794, tokens 128, triggered by: 0.15\n",
      "\u001b[32mNăm 2016, đích thân Chủ tịch Tập đoàn Nguyễn Trung Chính cùng anh thanh niên “mới nhận offer CMC” Nguyễn Xuân Cảnh, đã có những ngày rong ruổi khắp đất nước mặt trời mọc. Với đặc thù địa lý và giao thông Nhật Bản, mỗi ngày chỉ có thể gặp 2-3 đối tác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 795, tokens 95, triggered by: 0.34\n",
      "\u001b[34mTuy nhiên, anh  muốn gặp được 5 đối tác. Để làm được như vậy, anh  phương tiện di chuyển được đổi thành tàu điện ngầm, những giờ phút nghỉ ngơi được đổi thành các bữa ăn với váng trên tàu điện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 796, tokens 105, triggered by: 0.32\n",
      "\u001b[35mNhớ lại những chuyến công tác liên tục, có khi là dài ngày tại đất nước mặt trời mọc, anh Cảnh chia sẻ: “Di công tác với anh Chính nhiều, anh nhận ra cái được gọi là khoảng cách giữa lãnh đạo và anh Cảnh như không có.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 797, tokens 53, triggered by: token limit\n",
      "\u001b[31mChuyến đi vật và nhất kéo dài hơn 10 ngày, hết đất nước Nhật Bản và phải đi chuyển liên tục bằng tàu điện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 798, tokens 183, triggered by: token limit\n",
      "\u001b[32mNhiều lúc mệt quá, hai đứa em phải tranh thủ hùn nhùn  con động viên ngẫu ngợn trên tàu, ăn cơm  nằm hay  ăn  cái gì anh cũng  cắn được  cái đấy”.  “Lúc đấy mới nghĩ, à thì lãnh đạo  cũng giống chúng ta, cũng  gần gũi như thế”-  anh Cảnh nhớ lại về quyết tâm chinh phục thị trường khó tính của vị thuyền trưởng Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 799, tokens 124, triggered by: 0.28\n",
      "\u001b[34m.Sử Kỷ CMC 30 Kiến Tạo Di Sản Số  Sau 2 tháng nỗ lực tìm kiếm khách hàng, CMC đã có dự án IT Outsourcing đầu tiên với khách hàng Nhật Bản. Tin vui nối tiếp, các dự án liên tục đổ về và số lượng cán bộ nhân viên CMC sang on-site Nhật Bản ngày một đông.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 800, tokens 56, triggered by: 0.22\n",
      "\u001b[35mBan lãnh đạo Tập đoàn nhận thấy đã đến lúc cần có pháp nhân ở nước sở tại để các hoạt động diễn ra thuận tiện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 801, tokens 199, triggered by: 0.32\n",
      "\u001b[31mMùa thu năm 2017, công tác tìm kiếm địa điểm được gấp rút triển khai. Sau một thời gian tìm kiếm, CMC chọn đặt trụ sở tại thành phố Yokohama, tỉnh Kanagawa - một địa phương có nhiều chính sách hỗ trợ tốt đối với doanh nghiệp mới thành lập. Đây được coi là bước khởi đầu quan trọng, tạo tiền đề phát triển vững chắc cho CMC tại đất nước mặt trời mọc. Sáng ngày 07/11/2017, CMC Japan chính thức khai trương.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 802, tokens 95, triggered by: token limit\n",
      "\u001b[32mLễ khai trương có sự tham dự của Thứ trưởng Bộ TT&TT Việt Nam Nguyễn Minh Hồng, Đại sứ Đặc mệnh Toàn quyền Việt Nam tại Nhật Bản Nguyễn Quốc Cường và Thống đốc Kuroiwa Yuji của tỉnh Kanagawa.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 803, tokens 163, triggered by: token limit\n",
      "\u001b[34mGiây phút khách mời cùng Ban lãnh đạo Tập đoàn thực hiện nghi thức Kagami Biraki, gõ một củ búa nhẹ vang vọng âm thanh khắp không gian, nập thùng mạn giải phóng hương thơm nồng nàn và quyến rũ của rượu Sake như lần toa ước mở về một hành trình vun ra biện luận thành công của CMC và niềm tự hào đối với thành công của điểm dừng chân đầu tiên - Nhật Bản!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 804, tokens 140, triggered by: token limit\n",
      "\u001b[35m196 Sử Kỷ CMC 30.Ghi dấu Việt Nam lên bản đồ công nghệ thế giới  Trong hành trình đi về phía trước, CMC hướng đến mục tiêu doanh thu tỷ đô với trọng tâm đẩy mạnh các mảng dịch vụ CNTT cho thị trường nước ngoài. Trong đó, chuyển đổi số và AI được xác định là những hướng đi trọng tâm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 805, tokens 164, triggered by: token limit\n",
      "\u001b[31mAnh Nguyễn Trung Chính nhấn định: “Trong chiến lược cạnh tranh về thị trường quốc tế, CMC xây dựng năng lực bằng cách tạo ra giá trị dịch vụ tiềm công nghệ mà mình cung cấp được cho khách hàng. CMC không muốn sử dụng từ “bán” mà là nhà “cung cấp”, dịch vụ và sản phẩm công nghệ chất lượng cao mà CMC sở hữu cho khách hàng trong các chi nhánh nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 806, tokens 124, triggered by: token limit\n",
      "\u001b[32mNhằm thúc hiện mục tiêu này, bên cạnh việc phát triển các văn phòng thành phố Hồ Chí Minh, mở rộng quy mô CMC Japan. CMC APAC thuộc khối Kinh doanh Quốc tế với trụ sở đặt tại Singapore được thành lập năm 2021. CMC Korea ra mắt tại Seoul Hàn Quốc đã gây tiếng vang lớn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 807, tokens 173, triggered by: 0.12\n",
      "\u001b[34mBên cạnh những thành công rực rỡ tại thị trường Châu Á, CMC tiếp tục mở rộng phạm vi hoạt động tại châu Âu và Hoa Kỳ để từng bước thực hiện mục tiêu trở thành “công ty doanh thu tỷ đô với quy mô trên 10.000 nhân sự toàn cầu”. Khởi Kinh doanh Quốc tế của CMC đã tạo ra nhiều dự án ấn tượng, là niềm tự hào của CMC trên bản đồ công nghệ quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 808, tokens 91, triggered by: token limit\n",
      "\u001b[35m.Phát triển CÔNG NGHỆ LỢI Tư nghiên cứu ứng dụng  Làm công nghệ chỉ có thể thăng bằng công nghệ và muốn thăng bằng công nghệ thì phải thuộc nhóm dẫn đầu mới có thể cạnh tranh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 809, tokens 130, triggered by: token limit\n",
      "\u001b[31mLật lại những trang đầu trong chuyến hành trình lịch sử 30 năm của Tập đoàn CMC, hình ảnh những người kỹ sư công nghệ mạnh dạn \"tháo bỏ chiếc áo\" nghiên cứu chuyển sang làm kinh doanh đã gây ấn tượng về sự quyết đoán, dấn thân của những người thuyền trưởng ngày ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 810, tokens 196, triggered by: token limit\n",
      "\u001b[32mSau hơn 20 năm, hình ảnh về những phòng lab sáng đèn ngày đêm, về những công trình nghiên cứu, về cảm xúc và khi chế tạo ra một sản phẩm văn hóa xuyên hiện về trong tâm trí những người lãnh đạo CMC. Ở từng đơn vị thành viên trong Tập đoàn, hoạt động nghiên cứu và phát triển được thực hiện nhưng mang tính chất phân tán, dẫn đến khó khăn trong việc phát triển các sản phẩm dài hạn vì bị áp lực từ các hiệu quả ngắn hạn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 811, tokens 207, triggered by: token limit\n",
      "\u001b[34mVới nỗi niềm đau đáu cống hiến cho sự phát triển khoa học công nghệ của Việt Nam, Ban lãnh đạo Tập đoàn quyết định \"thành lập viên nghiên cứu mạng CMC xác định trong cuộc chơi, với slogan \"Khát khao chinh phục thế giới\",  thực  hiệu  định  hướng  căn  chỗ  ngành  công  nghệ  và  phát  triển  như vũ bảo, làm công nghệ chỉ có thể thăng bằng công nghệ và muốn thăng bằng công nghệ thì phải thuộc nhóm dẫn đầu mới có thể cạnh tranh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 812, tokens 63, triggered by: token limit\n",
      "\u001b[35mTrong bối muốn tạo một môi trường nghiên cứu  và  phát  triển  cho  những  nhà khoa học, góp phần vào sự phát triển của đất nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 813, tokens 138, triggered by: token limit\n",
      "\u001b[31mNgày 26/06/2014, Tập đoàn Công nghệ CMC đã tổ chức họp báo công bố chính thức về việc thành lập Viện Nghiên cứu Ứng dụng Công nghệ CMC (CMC Institute of Science and Technology - CIST), Tiến sỹ Nguyễn Kim Cường, Phó.Tổng Giám đốc Công ty Giải pháp phần mềm CMC, được bổ nhiệm làm Viện trưởng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 814, tokens 89, triggered by: token limit\n",
      "\u001b[32mVới phương châm: nghiên cứu thật, tạo ra những sản phẩm có giá trị thật, Viện CIST là môi trường nghiên cứu học thuật, là nền tảng xây dựng nền tảng giá trị cốt lõi cho Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 815, tokens 144, triggered by: token limit\n",
      "\u001b[34mCMC xác định mục tiêu nghiên cứu và phát triển các sản phẩm và dịch vụ có hàm lượng công nghệ và sáng tạo cao, có khả năng thương mại hóa để tạo động lực cạnh tranh cho các đơn vị thành viên của Tập đoàn CMC và Viện Nghiên cứu Ứng dụng Công nghệ CMC là nơi giúp Tập đoàn hiện thực hóa mục tiêu cao cả ấy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 816, tokens 193, triggered by: 0.19\n",
      "\u001b[35mBên cạnh đó, Viện CIST phối hợp với các đơn vị thành viên của Tập đoàn CMC tổ chức thực hiện các đề tài theo đơn đặt hàng từ các đơn vị này. Ngoài ra, Ban lãnh đạo Tập đoàn CMC cũng đặt mục tiêu xây dựng uy tín của Viện ở trong nước cũng như quốc tế thông qua các công trình nghiên cứu, các hợp tác đào tạo, tổ chức hội thảo hội nghị chuyên sâu, thường góp phần nâng cao giá trị thương hiệu CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 817, tokens 187, triggered by: token limit\n",
      "\u001b[31mTS. Đặng Minh Tuấn, hay còn quen thuộc với giới công nghệ thông tin dưới cái tên Vietkey – phần mềm gõ tiếng Việt đầu tiên trước khi UNICODE chính thức áp dụng, là người có nhiều kinh nghiệm trong lĩnh vực nghiên cứu blockchain. Anh gia nhập Viện nghiên cứu CMC tháng 10/2018 với vai trò chuyên gia blockchain. Đến tháng 7/2019, anh được bổ nhiệm vị trí Viện trưởng Viện Nghiên cứu Ứng dụng Công nghệ CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 818, tokens 145, triggered by: token limit\n",
      "\u001b[32mNăm 2022, Viện CMC CIST được đổi tên thành Viện CMC ATI, đánh dấu bước chuyển mới trong chiến lược phát triển Tập đoàn CMC. Chiến lược của CMC đến năm 2023 sẽ trở thành Tập đoàn số và cung cấp dịch vụ về chuyển đổi số cho các doanh nghiệp trong và ngoài nước, đặc biệt là trong khu vực công thơi trò thành tập đoàn toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 819, tokens 177, triggered by: token limit\n",
      "\u001b[34mCác sản phẩm, giải pháp của CMC ATI là những sản phẩm, chiến lược quan trọng góp phần đưa tập đoàn CMC đạt được các mục tiêu, chiến lược đã đề ra. .CMC ATI hướng tới những phần mềm sản phẩm, dịch vụ hoàn chỉnh thay vì dừng lại ở công bố có khả năng thương mại. Từ nghiên cứu, làm ra sản phẩm hoàn chỉnh, CMC ATI đặt mục tiêu thương mại hóa để có xắt thị trường, hướng tới thu về tài chính.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 820, tokens 163, triggered by: 0.27\n",
      "\u001b[35mVề sản phẩm, CMC ATI hướng tới nghiên cứu các công nghệ lỗi, công nghệ mới, công nghệ cao phục vụ cách mạng công nghệ 4.0 cũng như quá trình chuyển đổi số. Trong suốt quá trình hình thành và phát triển, lĩnh vực nghiên cứu của CMC đã có bước chuyển mình lớn khi xây dựng được 20 công nghệ lỗi, từ đó phát triển được hệ sinh thái AI phục vụ cho chuyển đổi số.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 821, tokens 56, triggered by: 0.38\n",
      "\u001b[31mCũng với độ xây dựng ra nên tăng xử lý dữ liệu (Big Data), xây dựng được những giải pháp cho lot, nên tăng security và blockchain.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 822, tokens 196, triggered by: token limit\n",
      "\u001b[32m\"Mạnh dặt\" của sự sáng tạo  Nói về định hướng phát triển CMC ATI, Viện trưởng Đặng Minh Tuấn cho rằng con người là yếu tố cốt lõi: \"Tại CMC ATI, nhân viên có thể phát triển hết khả năng, chúng tôi tạo dựng một môi trường kiến thức, kỹ năng chủ không phải thuần tuý về đầu ra. Chúng tôi luôn hướng tới mục tiêu biến CMC ATI trở thành \"mạnh dặt\" của sự sáng tạo.\", Viện trưởng Đặng Minh Tuấn chia sẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 823, tokens 96, triggered by: 0.15\n",
      "\u001b[34mCMC ATI nhận mạnh sự chủ động trong việc học và giải quyết vấn đề của mỗi nhân viên. Giải pháp phân tích và quản lý hình ảnh thông minh (CIVAMS) của CMC ATI là điểm \"lâm công nghệ thi phạm\"  thái băng công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 824, tokens 160, triggered by: 0.07\n",
      "\u001b[35mTại thời điểm đó, có rất nhiều \"làm công nghệ\". Tại thời điểm đó, có rất nhiều làm vấn đề nhưng điểm làm nên sự khác biệt cho sản phẩm của CMC ATI chính là độ chính xác và tốc độ nhận diện cao. Sản phẩm của CMC ATI có thể nhận diện khu - ôn mặt trên dữ liệu 160 triệu khoảnh ảnh, 2 giây -  đây là sự khác biệt lớn nhất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 825, tokens 70, triggered by: 0.10\n",
      "\u001b[31mVới khả năng  phạm kết nối với cơ sở dữ liệu quốc gia về toàn bộ dân số Việt Nam. Điều này rất có ích tại các cửa khẩu, khu vực check in tại sân bay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 826, tokens 126, triggered by: 0.17\n",
      "\u001b[32m. . với yêu cầu nhận diện tốc độ cao trên dữ liệu lớn. Ngoài nhận diện khuôn mặt, sản phẩm của CMC ATI cũng có thể nhận diện những người bị nga, xo át đâu hay phát hiện dấu tấc giới tính cũng như có thể tìm kiếm, cảnh báo những đối tượng nguy hiểm,. . . .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 827, tokens 71, triggered by: 0.25\n",
      "\u001b[34mKHÁT  Bên cạnh đó, sản phẩm giúp chuyển đổi văn bản in, viết tay, bằng excel phục tạp… thành tài liệu số cũng là một điểm tự hào khác của CMC ATL.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 828, tokens 63, triggered by: 0.04\n",
      "\u001b[35mKỳ họp quốc hội năm 2023, phần mềm nhận dạng tiếng nói, chuyển chữ tự viết của CMC được ứng dụng trong hai kỳ họp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 829, tokens 112, triggered by: 0.18\n",
      "\u001b[31mThời gian gặp gáp, dự án quan trọng cần đảm bảo yêu cầu kỹ thuật và bảo mật theo yêu cầu nghiệm ngặt, đội dự án được yêu cầu ở lại Viên, làm việc bám sát theo lịch họp và sẵn sàng cho mọi tình huống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 830, tokens 198, triggered by: token limit\n",
      "\u001b[32mDự án đã đem lại những kinh nghiệm quý giá cho các nhân sự tham gia. Khởi Nghiên cứu và Giáo dục của Tập đoàn CMC với hạt nhân là Viện Nghiên cứu Ứng dụng Công nghệ ATI đã, đang và sẽ là nòng cốt, là hạt nhân cho công nghệ lỗi, công nghệ của tương lai; sáng lập Tập đoàn, đồng thời tạo ra nguồn nhân lực nghiên cứu ứng dụng chất lượng cao cho CMC nói riêng và cho khát vọng hùng cường của Việt Nam nói chung.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 831, tokens 176, triggered by: token limit\n",
      "\u001b[34mKIẾN TẠO DỮ LIỆU SỐ 201.CMC UNIVERSITY ĐẠI HỌC SỐ Đầu tiên của Việt Nam  LỄ RA MẮT TRƯỜNG ĐẠI HỌC CMC MÔ HÌNH ĐẠI HỌC SỐ ĐẦU TIÊN CỦA VIỆT NAM VÀ KHAI GIẢNG KHOÁ 1 Ngày 17.11.2022  Trải qua gần 30 năm hình thành và phát triển, đối với CMC, nhân lực là một trong những nguồn vốn quan trọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 832, tokens 123, triggered by: token limit\n",
      "\u001b[35mVới việc đầu tư cho lĩnh vực giáo dục, Tập đoàn CMC định hướng xây dựng Trường đại học chất lượng cao, đào tạo ra những con người số - digital thinker - để chinh phục thế giới số vì mục tiêu phát triển xã hội ngày một tốt đẹp hơn, vì một Việt Nam hùng cường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 833, tokens 196, triggered by: 0.09\n",
      "\u001b[31m202 SỰ KỶ CMC 30.Tiếng chuông đầu tiên  Một buổi sáng mùa thu năm 2022, khi thành phố mới chỉ thức dậy sau giấc ngủ - 6 giờ sáng, khuôn viên trường Đại học CMC đã tràn ngập những bước chân: bước chân của các thầy cô giáo, bước chân của những người trong Ban điều hành và văn phòng nhà trường, bước chân của 345 sinh viên khóa đầu tiên. Mọi người không ai nói chuyện nhiều, chỉ là những lời chào hỏi khi gặp nhau ở hành lang.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 834, tokens 124, triggered by: 0.20\n",
      "\u001b[32mMột cảm xúc hồi hộp kèm lo lắng khi chờ đợi điều kỳ diệu xảy ra. Dừng 7 giờ sáng, tiếng chuông  giảng  đầu tiên vang lên. Tiếng chuông không chỉ báo hiệu tiết học bắt đầu, tiếng chuông của Đại học CMC nói riêng và Tập đoàn CMC nói chung.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 835, tokens 169, triggered by: token limit\n",
      "\u001b[34mKể từ giây phút này, ước mơ đã được hiện thực hóa: ước mơ vun mầm thế hệ trẻ với tư duy sáng tạo, khích mạnh khám phá; ước mơ gôm  khắc  hỗ trợ vào sự  phát triển  của đất nước Việt Nam thân yêu và ước mơ Kiến tạo Di sản số của Tập đoàn CMC. Khuôn viên trường Đại học CMC  dần chìm vào sự yên tĩnh khi giảng viên và sinh viên vào lớp học.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 836, tokens 168, triggered by: token limit\n",
      "\u001b[35mTiết học đầu tiên dần trôi qua, tiếng chuông thứ hai  vang lên; không khí hội họp  trước đó được  gửi  đi trong  mọi  nhóm  hội,  những  tin  hiệu  trường Hồ Như  Hải  đi một vòng hành lang  hội các  thầy  cô,  trò chuyện  với  sinh viên về tiết  học  đầu tiên. “Đây mới  thực  sự là  không  khí  một trường  học” - thầy Hải chia sẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 837, tokens 75, triggered by: token limit\n",
      "\u001b[31mĐể đi đến ngày đặc biệt này là một hành trình tuy không dài nhưng nhiều khó khăn và đầy nỗ lực của các thành viên trong  Dự án Thành lập trường Đại học CMC. Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 838, tokens 191, triggered by: 0.37\n",
      "\u001b[32mLễ  ra mắt  trường Đại học CMC  - mô hình đại học số  đầu  tiên  của  Việt Nam.## Ước mơ xây dựng Việt Nam hùng cường  Sau gần 30 năm xây dựng và phát triển, CMC muốn đóng góp nhiều hơn nữa cho xã hội, để \"trả ơn\" những gì mà đất nước đã giúp chúng tôi có được thành quả như ngày hôm nay. Linh vực giáo dục chính là nội tốt nhất để CMC thực hiện lý tưởng của mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 839, tokens 143, triggered by: 0.24\n",
      "\u001b[34m**Nguyễn Trung Chính**  Chủ tịch HĐQT, Chủ tịch Điều hành Tập đoàn Công nghệ CMC  Hình ảnh: Anh Nguyễn Trung Chính chia sẻ về mục tiêu xây dựng Đại học CMC  Trải qua gần 30 năm hình thành và phát triển, đối với Tập đoàn CMC, nhân lực là một trong những nguồn vốn quan trọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 840, tokens 103, triggered by: 0.26\n",
      "\u001b[35mTuy nhiên với đặc điểm giáo dục tại Việt Nam hiện nay, khoảng cách giữa trường đại học và doanh nghiệp là rất lớn tuy rằng hai tổ chức này có mối liên hệ mật thiết: đầu ra của trường đại học chính là đầu vào của doanh nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 841, tokens 93, triggered by: 0.03\n",
      "\u001b[31mXu hướng kết hợp với doanh nghiệp để thực  hợp  mới doanh nghiệp,  thúc đẩy doanh nghiệp  về  thình giường,  tham gia thiết kế chương trình đào tạo  và  xây  dựng  chuẩn  đầu  ra .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 842, tokens 68, triggered by: 0.39\n",
      "\u001b[32m. . Với sự quyết đoán và mong muốn xây dựng một Việt Nam hùng cường, Tập đoàn CMC đã lựa chọn hướng đi triệt để để giải quyết vấn đề này:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 843, tokens 165, triggered by: token limit\n",
      "\u001b[34mXây dựng một trường đại học trong lòng doanh nghiệp. Từ hoạt động quản trị, vận hành đến xây dựng đội ngũ giảng viên và tổ chức đào tạo sinh viên được thiết kế gì và sinh viên học được gì khi đồng hành cùng trường Đại học CMC để sẵn sàng đáp ứng yêu cầu của thị trường lao động và là nguồn nhân lực chất lượng cao của CMC cũng như của ngành công nghệ thông tin.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 844, tokens 174, triggered by: token limit\n",
      "\u001b[35m.Quyết định xây dựng và phát triển Đại học CMC đã truyền tải mong muốn được đóng góp và duy trì sự phát triển của đất nước, để lại một di sản cho các thế hệ sau. Đồng thời, khẳng định mạnh mẽ thông điệp nhận thức là nguồn vốn quý giá, với đội ngũ nhân sự có trình độ cao, lợi thế cạnh tranh của CMC trên thị trường trong và ngoài nước sẽ được gia tăng nhanh chóng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 845, tokens 146, triggered by: 0.15\n",
      "\u001b[31mNhững khó khăn và \"chuyên gia gỡ nút thắt\"  Giáo dục là một lĩnh vực đặc biệt, khi \"sản phẩm\" của các trường đại học là những cam kết về tương lai, là niềm tin không chỉ của người học, của gia đình mà còn là niềm tin của Chính phủ và Nhà nước. Việc xin thành lập một trường đại học vốn không phải câu chuyện dễ dàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 846, tokens 88, triggered by: 0.25\n",
      "\u001b[32mDiệu kỳ điều là mỗi lần cảm thấy khó, để ăn dưỡng như đi vào bế tắc, chủ tịch Nguyễn Trung Chính lại \"tạo ra\" \"thảo gỡ nút thắt\" bằng một cách thần kỳ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 847, tokens 150, triggered by: 0.15\n",
      "\u001b[34mSau này, anh Hài nho rằng, \"hóa gỡ nút thắt\" bằng một \"Đôi vai anh Chính\", điều gì có lời cho đất nước, cho dân thì anh có thể minh phát thùy thuyết phục đến cùng. Nhờ sự quyết liệt và niềm tin sắt đá ấy của trong tổ dự án thành lập Đại học CMC được niềm tin, kiến trì biến giấc mơ thành hiện thực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 848, tokens 76, triggered by: 0.26\n",
      "\u001b[35mTháng 02/2022, CMC mua lại Đại học A Châu thông qua công ty CMC Education. Đến ngày 26/07/2022, trên bản đồ các trường đại học tại Việt Nam chính thức xuất hiện cái tên mới:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 849, tokens 130, triggered by: 0.33\n",
      "\u001b[31mTrường Đại học CMC – CMC University. Khi không quyết định, thực ra đó không phải là một điều bất ngờ đối với tổ dự án đã ngày đêm chuẩn bị kỹ càng, \"nhưng có sự khủng hoảng, có sự thoả phán hành phúc, còn thành một khó khăn và thử thách\". - những thành viên của tổ dự án chia sẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 850, tokens 76, triggered by: token limit\n",
      "\u001b[32mNgười thuyền trưởng Nguyễn Trung Chính hồ mệnh lệnh \"Khao quân\" - kỷ niệm dấu mốc đầy tự hào mới của CMC. CHU TỊCH TẬP ĐOÀN CMC:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 851, tokens 200, triggered by: token limit\n",
      "\u001b[34m\"ĐẦU TƯ GIÁO DỤC LÀ CÁCH TỐT NHẤT CHUNG TÔI TRA ƠN BẤT NƯỚC\"  Trên con đường trở thành tập đoàn công nghệ dẫn đầu khu vực với USD 500 triệu vốn đầu tư, đây là  vấn đề quan trọng &  bước đi  thầm  yên  với xây  dựng  & phát triển  Trường  Đại  học  CMC thành  Đại học  Sở  dữ  liệu  tiên  tiến. Năm  với  vốn đầu  tư  hơn  1.000  tỷ  VNĐ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 852, tokens 64, triggered by: 0.29\n",
      "\u001b[35m.Tài sư kiên chào đón tân sinh viên Khoa đầu tiên \"CMC Uni: Into the new world\". Chủ tịch Nguyễn Trung Chính đã chia sẻ truyền lửa tới 345 sinh viên:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 853, tokens 90, triggered by: token limit\n",
      "\u001b[31m\"Thắm sâu trong lòng, tôi kháo khát tạo nên chiếc nôi để thôi bùng lên những đam mê thế giới số, mong các bạn trẻ viết tiếp giấc mơ ghi danh Việt Nam lên bản đồ khoa học công nghệ thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 854, tokens 179, triggered by: token limit\n",
      "\u001b[32mVà hôm nay, nhìn những gương mặt trẻ đầy nhiệt huyết ở đây, tôi tin các bạn sẽ khẳng định vị thế trong tương lai 4.0, tự do tạo ra những đột phá trong khoa học công nghệ để kiến tạo thế giới số và đóng góp tích cực cho phát triển xã hội.\"  Với chủ đề \"Digital World Maker\", lễ khai giảng năm học với hơn 1.000 tân sinh viên khóa 2, đánh dấu cột mốc quan trọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 855, tokens 106, triggered by: token limit\n",
      "\u001b[34mSau một năm hoạt động của Nhà trường với số lượng sinh viên tăng gần 3 lần. Trường Đại học CMC đang dần khẳng định vị thế tại Việt Nam, với sứ mệnh đào tạo nguồn nhân lực chất lượng cao trong lĩnh vực khoa học - công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 856, tokens 124, triggered by: token limit\n",
      "\u001b[35mTrường Đại học CMC đã vươn mình trở thành trường học đa ngành, đa lĩnh vực với mục tiêu đào tạo nguồn nhân lực chất lượng cao, nhưng công  đánh toàn cầu, công  đánh chuyên môn và kỹ năng nghề nghiệp đáp ứng nhu cầu thực tiễn trong nước và quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 857, tokens 134, triggered by: token limit\n",
      "\u001b[31mVới việc đầu tư cho lĩnh vực giáo dục, Tập đoàn CMC định hướng xây dựng nguồn nhân lực chất lượng cao, đào tạo ra những con người số - digital thinker - để chinh phục thế giới số, vì một mục tiêu phát triển xã hội ngày một tốt đẹp hơn, vì một Việt Nam hùng cường, thịnh vượng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 858, tokens 190, triggered by: 0.13\n",
      "\u001b[32m.KIẾN TẠO đi sản số  “Những ngày đầu hạ năm 2023, tại các “đại bản doanh” của CMC tại Hà Nội, Thành phố Hồ Chí Minh, Hải Phòng, Đà Nẵng và các văn phòng tại các nước mà CMC có mặt ngập tràn những biểu ngữ với tựa đề \"Inspire the Digital Heritage - Kiến tạo di sản số\". Đó chính là thông điệp, là mục tiêu mới của CMC. Kể từ đây, sau 30 năm thành lập, CMC chính thức bắt đầu con đường mới, kỷ nguyên mới:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 859, tokens 140, triggered by: token limit\n",
      "\u001b[34mKỷ nguyên Kiến tạo Di sản số. CMC đang hướng đến mục tiêu trở thành tập đoàn số toàn cầu với tầm nhìn không chỉ là 10 năm, 30 năm, hay 50 năm, mà là hàng trăm năm. Sau sự phát triển bền vững, CMC mong muốn trở thành một tập đoàn phát triển trường tồn, giống như nhiều tập đoàn lớn trên thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 860, tokens 66, triggered by: token limit\n",
      "\u001b[35mTrong hành trình đó, CMC mong muốn kiến tạo nên những di sản số, không phải chỉ riêng mình, mà hơn hết, là cho đất nước, cho xã hội, cho nhân loại.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 861, tokens 208, triggered by: token limit\n",
      "\u001b[31mTừ hào hành trình 30 năm  Sau 30 năm dẫn thân và kiên định với ước mơ của mình: xây dựng CMC trở thành công ty công nghệ, đưa Việt Nam trở thành cường quốc về công nghệ thông tin, CMC đã có những cột mốc đáng tự hào. Áp tốc độ đã mang thành một công ty đi đầu về công nghệ số, công nghệ điện toán đám mây với việc cung cấp dịch vụ chuyển đổi số cho hàng ngàn doanh nghiệp không chỉ ở Việt Nam, mà còn nằm trong Top 500 công ty lớn nhất toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 862, tokens 71, triggered by: token limit\n",
      "\u001b[32mBên cạnh đó, hệ thống trung tâm dữ liệu Tập đoàn CMC (TPHCM) đã được công nhận là trung tâm dữ liệu an toàn và hiện đại nhất Việt Nam tính đến thời điểm 2023.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 863, tokens 144, triggered by: token limit\n",
      "\u001b[34mTừ 20 thành viên ban đầu, CMC giờ đã trở thành một tập thể gần 6.000 cán bộ nhân viên, với doanh thu năm tài chính 2022 (kết thúc vào\".ngày 31/3/2023) đạt 8.363 tỷ đồng, lợi nhuận EBITDA gần 900 tỷ đồng, đều tăng trưởng hai con số, tương ứng là 21% và 23% so với cùng kỳ năm trước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 864, tokens 298, triggered by: token limit\n",
      "\u001b[35mCMC cũng có rất nhiều di sản khác. Đó là tăng số vật lý với 2.500km đường trục backbone CVCS (Cross Vietnam Cable System) …; là hạ tầng số phí vật lý với hệ sinh thái số dành cho tổ chức & doanh nghiệp C.Ope2n, với CMC Cloud - nền tảng điện toán đám mây makeInVietnam hàng đầu; là các công nghệ lõi phát triển thành các giải pháp số áp dụng cho việc hoạt động kinh doanh, bảo mật của từ nhân, doanh nghiệp…; là nhân lực số, với tầng tầng lớp lớp thế hệ con người CMC có tinh kế thừa từ các lãnh đạo, kỹ sư, cộng sự, tới sinh viên đại học số… Tất cả đều là những di sản số mà CMC nỗ lực kiến tạo trong suốt 30 năm hình thành - xây dựng và phát triển.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 865, tokens 193, triggered by: 0.27\n",
      "\u001b[31m.“CMC hãy nhận lấy một sứ mệnh quốc gia”  Tham dự lễ kỷ niệm 30 năm thành lập Tập đoàn Công nghệ CMC ngày 16/5/2023, Bộ trưởng Bộ TT&TT Nguyễn Mạnh Hùng đã nhắc tới “di sản số” đang tự hào của Tập đoàn, cũng như sứ mệnh mà quốc gia trao gửi tới CMC  “CMC hãy nhận lấy một sứ mệnh quốc gia. Doanh nghiệp kinh doanh thì phải có lợi nhuận để tồn tại và phát triển.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 866, tokens 75, triggered by: 0.38\n",
      "\u001b[32mNhưng sau lợi nhuận phải là sứ mệnh giải quyết một bài toán, một nỗi đau của đất nước, của nhân loại, để đất nước cường thịnh; để nhân loại hạnh phúc hơn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 867, tokens 98, triggered by: 0.20\n",
      "\u001b[34mCác doanh nghiệp xuất sắc, các doanh nghiệp lớn thường nhận lấy một sứ mệnh quốc gia làm thành sứ mệnh của mình để dẫn dắt doanh nghiệp đi xa hơn nữa, để gắn mình với quốc gia, dân tộc hơn nữa.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 868, tokens 53, triggered by: -0.01\n",
      "\u001b[35mQuốc gia, dân tộc thị trường tôn. Doanh nghiệp mà gắn mình với nó thì cũng vì vậy mà trường tồn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 869, tokens 134, triggered by: token limit\n",
      "\u001b[31mHình ảnh: Bộ trưởng Bộ TT&TT Nguyễn Mạnh Hùng phát biểu tại lễ kỷ niệm 30 năm thành lập Tập đoàn Công nghệ CMC.Và để tiếp nối, Chủ tịch Nguyễn Trung Chính đã gắn sứ mệnh mới của Tập đoàn CMC khi bước sang thập kỷ thứ ba với sứ mệnh phát triển đất nước:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 870, tokens 164, triggered by: token limit\n",
      "\u001b[32mSứ mệnh của CMC là sứ mệnh đóng góp cho sự phát triển của đất nước, gắn sứ mệnh phát triển của công ty với sứ mệnh phát triển của quốc gia, dân tộc. Đó là sứ mệnh xây dựng Việt Nam trở thành quốc gia mạnh về công nghệ số, đem công nghệ số phục vụ và chinh phục toàn cầu, đưa Việt Nam trở thành Digital HUB của không chỉ APAC mà còn là của thế giới. Hình ảnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 871, tokens 179, triggered by: token limit\n",
      "\u001b[34mChủ tịch Nguyễn Trung Chính phát biểu tại Lễ kỷ niệm 30 năm thành lập Tập đoàn Công nghệ CMC  Tuổi 30, CMC đã chọn một sứ mệnh mới, trách nhiệm mới cùng niềm khát khao mãnh mẽ về một tập đoàn thịnh vượng, đóng góp kiến tạo một Việt Nam hùng cường, khẳng định vị thế trên trường quốc tế và tiếp tục viết tiếp hành trình Kiến tạo Di sản số đầy tự hào!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 872, tokens 528, triggered by: token limit\n",
      "\u001b[35m211.HA TĂNG SỐ - BƯỚC CHẠY BÀ CHO THAM VONG TỶ ĐÔ CỔ CHỦ TÍCH HA THỂ MINH - HÌNH ẢNH CÔN MÃI \"GO GLOBAL\" - HÀNH TRÌNH VUỢN RA BIÊN LỢN PHÁT TRIỂN CÔNG NGHỆ LỢI TỪ NGHIÊN CỨU ỨNG DỤNG CMC UNIVERSITY - ĐẠI HỌC SỔ ĐÂU TIÊN CỦA VIỆT NAM KIỆN TẠO DI SẢN SỔ ĐÂU ẨN GIAI ĐOẠN 2013 - 2023 GIẢI THƯỞNG GIAI ĐOẠN 2013 - 2023 Từ hai thành một TIME dotCOM và câu chuyện chạp nhận thương đau để bước tiếp, đứng dưới và thắt vừng chải Thạm vọng đưa Việt Nam trở thành điểm kết nối hằng đầu khu vực Từ ISP đến CSP - Hành trình tự hào Một nhà lãnh đạo Tài - Tâm Một người thầy lớn, người anh lớn của CMC Một người thầm lặng, đau đầu với công việc đến những phút cuối cùng Câu chuyện bên lề:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 873, tokens 1318, triggered by: token limit\n",
      "\u001b[31m\"Tôi đã gặp anh Minh như thế nào?\" Hoa tiều của hai trình vuơn ra biến lớn Nguồn nhân lục - yêu tố sống còn Đồng chủ trì nệp capo phù tuyệt trắng và chiến thắng trong trái tim Nguồi CMC Ghi đầu Việt Nam lên bản đồ công nghệ thế giới Khát khao cống hiến Nghiên cứu thật - sản phẩm thật Mạnh dạt của sự sáng tạo Tiếng chuông đáu tiên Ước muốn xây dụng Việt Nam hùng cuống Những khó khăn và \"chuyen gia gỗ nút thật\" Tự hào hành trình 30 năm \"CMC hãy nhận lấy một sứ mệnh quốc gia\" KIỆN TẠO DI SẢN SỔ.## DẤU ẤN CHƯƠNG III CHẠY (2013 - 2023)  ## DẤU MỐC LỊCH SỬ 26/06/2014 Thành lập Viện Nghiên cứu Ứng dụng Công nghệ CMC (CMC Institute of Science and Technology - CIST, nay là CMC ATI)  08/05/2015 CMC Telecom ký kết thỏa thuận Đầu tư chiến lược với Tập đoàn Time DotCom Berhad (TIME) – một trong những công ty viễn thông hàng đầu của Malaysia  04/01/2017 CMC công bố chiến lược phát triển giai đoạn 2016 - 2018 tầm nhìn 2020 và hệ thống nhận diện thương hiệu mới  26/02/2017 Khai trương Trung tâm Sáng tạo CMC và ra mắt Quỹ sáng tạo CMC  31/03/2017 Thành lập CMC Global  07/11/2017 Khai trương CMC Japan tại Nhật Bản  09/04/2019 Ra mắt Hệ sinh thái Hạ tầng mở cho Doanh nghiệp và tổ chức C.OPE2N .DẤU MỐC LỊCH SỬ 11/04/2019 Ra mắt Công ty TNHH Tổng công ty Công nghệ & Giải pháp CMC 26/07/2019 CMC kí kết hợp tác đầu tư chiến lược CMC - Samsung SDS 2021 Thành lập CMC APAC tại Singapore 17/11/2022 Ra mắt Đại học CMC - Mô hình Đại học số đầu tiên của Việt Nam 15/08/2022 Khánh thành Tổ hợp Trung tâm dữ liệu và Không gian sáng tạo CMC Creative Space 08/05/2023 Thành lập CMC Korea tại Hàn Quốc  KIẾN TẠO DỊ SẢN SỐ 215.## GIẢI THƯỞNG GIAI ĐOAN 2013 - 2023  2014  Bảng khen doanh nhân tiêu biểu năm 2014 do UBND - Liên đoàn Lao động TP Hà Nội trao tặng cho anh Hà Thế Minh & anh Nguyễn Trung Chính  2015  Tập đoàn Công nghệ CMC xuất sắc dẫn đầu \"Top 5 đơn vị Công nghệ thông tin - Viễn thông 2015\"  Anh Nguyễn Trung Chính được bình chọn là Top 10 Doanh nhân xuất sắc  2017  Anh Nguyễn Trung Chính được bình chọn là Top 10 Nhân vật ảnh hưởng nhất đến Internet Việt Nam trong 10 năm (2007 - 2017)  2018  Anh Nguyễn Trung Chính được bình chọn là Top 10 Nhân vật ảnh hưởng nhất đến Internet Việt Nam trong 10 năm (2007 - 2017)  2019  CMC đạt Top 10 doanh nghiệp Công nghệ Thông tin - Viễn thông uy tín năm 2019 do Vietnam Report bình chọn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 874, tokens 406, triggered by: token limit\n",
      "\u001b[32mCMC TS đạt Top 10 doanh nghiệp công nghệ giải pháp phần mềm & cung ứng thiết bị công nghệ - Viễn thông uy tín năm 2019  CMC đạt giải thưởng ASOCIO 2019, giải thưởng CNTT uy tín của khu vực châu Á và châu Đại Dương  2020  CMC được HR ASIA ghi nhận là 1 trong các công ty có môi trường làm việc tốt nhất Châu Á năm 2020  CMC được đánh giá là Top 10 Doanh nghiệp CNTT - Viễn thông uy tín năm 2020 theo Viet-nam Report.2021 CMC lọt Top 5 Doanh nghiệp CNTT - Viễn thông uy tín 2018 – 2020 (Vietnam report) 2022 Data Center Tân Thuận đạt giải DC tốt nhất Việt Nam năm 2022 của Tạp chí Global Business Chủ tịch CMC được vinh danh “Top 10 Doanh nhân Việt Nam tiêu biểu 2022 Top 50 công ty kinh doanh hiệu quả nhất Việt Nam Tập đoàn Công nghệ CMC được vinh danh với 2 giải thưởng từ Asian Technology Excellence Awards 2022 2023 Chủ tịch Nguyễn Trung Chính được vinh danh Top 10 Doanh nhân Việt Nam tiêu biểu 2022.PHẦN II:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 875, tokens 154, triggered by: 0.14\n",
      "\u001b[34mKỲ  CMC  IN OUR HEART  CMC DIGITAL HERITAGE RACE  START  CRAFT.Phần II: Ký - CMC in our heart  Mạng Internet lên mạng Truyền hình cáp  Tác giả: Nguyễn Chi Triệng Trung tâm Kỹ thuật miền Bắc - CMC Telecom  Năm 2010 tôi quyết định dũng cộng việc Chuyên viên Kỹ thuật Truyền hình cáp tại Đài Truyền hình Hà Nội để đến với CMC Telecom.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 876, tokens 175, triggered by: 0.33\n",
      "\u001b[35mNhiều người bảo: “Làm kỹ thuật khó khăn, ở đâu chẳng chân như nhau, đổi làm gì?” . Chị mình tôi tin: CMC Telecom mới thành lập hai năm, mạng hạ tầng mình theo đuổi còn nhiều \"đất diễn\", đời kỹ thuật chi mà có thể. Sau hơn một năm đầu làm quen vùng đất mới, tôi được giao hai dự án triển khai Internet cho hộ gia đình kết hợp với đơn vị truyền hình cáp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 877, tokens 141, triggered by: -0.03\n",
      "\u001b[31mTích hợp internet vào đường cáp truyền hình cho Đài Truyền hình Hà Nội và Truyền hình cáp Việt Nam (VTVCab). Những năm 2012, hai đơn vị truyền hình cáp Hà Nội và Truyền hình cáp Việt Nam chỉ đơn thuần cung cấp truyền hình analog hữu tuyến, việc đưa Internet vào sóng truyền hình cáp đến từng hộ gia đình nghe rất “oách”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 878, tokens 77, triggered by: 0.17\n",
      "\u001b[32mDi dầu cũng giới thiệu: \"Minh làm CMC Telecom, đi đầu về Internet thế hệ mới.\".CMC family  Nói oai là thế nhưng những ngày đầu khởi động dự án, có hai anh em kỹ thuật :\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 879, tokens 154, triggered by: 0.22\n",
      "\u001b[34mTôi và anh Lê Mạnh Hùng (Hung.Lm), tự phong một phó giám đốc, một giám đốc. Hai anh em được anh Phó Đức Kiên, anh Đình Tuấn Trung và anh Đình Hoàng Tuấn giao nhiệm vụ triển khai và đào tạo hướng dẫn đối tác với dịch vụ EOC. Hai anh em mày mò đọc tài liệu, kết hợp cùng hãng Kangbo để triển khai dự án đầu tay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 880, tokens 74, triggered by: 0.16\n",
      "\u001b[35mTrước đó, tôi chỉ có kinh nghiệm vận hành, thiết kế hạ tầng truyền hình cáp. Hướng đi về Internet rất khác, mỗi ngày mình được học một kiến thức mới, lối cuốn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 881, tokens 64, triggered by: 0.23\n",
      "\u001b[31mTôi và anh Hùng hào hứng vô cùng. Ngày thì leo trèo cột điện hướng dẫn đối tác lắp đặt, cấu hình, tinh chỉnh tín hiệu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 882, tokens 71, triggered by: 0.33\n",
      "\u001b[32mTôi thì soạn cho nhanh để tài liệu hoàn thiện. Rồi cũng đến ngày hai anh em tôi đồng bộ chính tế sang đại \"training\", chi nhánh truyền hình về công nghệ mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 883, tokens 164, triggered by: 0.32\n",
      "\u001b[34mTôi vẫn nhớ như in cảm giác bồi hồi cùng nhóm thực hiện dự án CMTS bước lên hội trường hướng dẫn nhiều ngày cho toàn bộ các chi nhánh của VTVcab. Mấy anh kỹ thuật \"quên\" chảng bao giờ dám nghĩ được đứng giữa hội trường lớn, ở dưới học viên toàn những lãnh đạo kỹ thuật chi nhánh, chuyên viên tên tuổi ở đài truyền hình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 884, tokens 91, triggered by: 0.19\n",
      "\u001b[35mLâu nay, các sếp nói rất nhiều về uy tín CMC Telecom, đến hôm đó tôi mới thực sự hiểu mình đang làm dự án lớn, đem lại thêm dịch vụ add on ngoài việc kinh doanh truyền hình đơn thuần.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 885, tokens 102, triggered by: 0.13\n",
      "\u001b[31mCMC 31.Phần II: Ký - CMC in our heart Làm giảng viên được ba ngày, anh em chúng tôi lại lao ra đường cùng đối tác lập đặt đường truyền đến từng hộ gia đình. Đường thủ đô con phố nào, ngõ ngách nào cũng biết vị lộ mờ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 886, tokens 65, triggered by: 0.33\n",
      "\u001b[32mTừ hai anh em, nhóm đồng dần lên đến hơn 30 người. Anh Phó Đức Kiên, anh Đinh Hoàng Tuấn cùng xông pha cùng anh em đến từng đường truyền.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 887, tokens 59, triggered by: 0.19\n",
      "\u001b[34mCó khi giữa trưa, có lúc chập tối, anh em vẫn di nhau dang ở một cột cáp nào đó. Niềm vui ngày ấy giản di lắm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 888, tokens 198, triggered by: 0.26\n",
      "\u001b[35mKhi kiểm tra mọi thông số về tín hiệu truyền dẫn, ping, test mạng xong có được chất lượng internet tốt là đi uống bia ăn mừng. Thời điểm làm dự án truyền hình cáp cũng là lúc tôi nhìn thấy sự gắn bó khăng khít giữa đội sale (nhân viên kinh doanh) với anh em kỹ thuật. Sale cứ chốt được một đơn hộ gia đình mua truyền hình internet là chạy sang khoe: \"Anh em kỹ thuật chuẩn bị lên đường nhé\". Cuối tháng, đội sale hào hứng:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 889, tokens 67, triggered by: 0.29\n",
      "\u001b[31m\"Tháng này 500 hợp đồng online, tháng sau 1.000 hợp đồng online\". Hai đội truyền hình gặp đôi \"Ctel\" phần khôi bắt tay cảm ơn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 890, tokens 66, triggered by: 0.30\n",
      "\u001b[32mAi cũng hăng hái như giữa một vụ mùa, chờ nảy gặt, chờ kia tuốt lúa và hạnh phúc thành thoi khi cánh đồng đã trở gốc rạ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 891, tokens 63, triggered by: 0.14\n",
      "\u001b[34mChúng tôi tự hào khi biết tối nay, một gia đình giữa lòng Hà Nội vừa xem tivi vừa lên mạng đọc báo bằng Internet của CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 892, tokens 119, triggered by: token limit\n",
      "\u001b[35m.KỸ THUẬT MIỀN TRUNG VÀ  Những lần xử lý sự cố  Tác giả: Hoàng Thị Hằng Văn phòng Công ty - CMC Telecom  Những ngày tháng Sáu, thời tiết miền Trung nóng đành như một thiếu nữ, lúc thì nắng như đổ lửa, khi lại bất chợt mưa dông.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 893, tokens 184, triggered by: token limit\n",
      "\u001b[31mCác anh em kỹ thuật như Phạm Thành Vi – kỹ sư cơ điện thuộc TTKT miền Trung, có lẽ đã quen thuộc với “nàng thiếu nữ” này, bởi cứ có sự cố là anh em lại lao ra đường, không quản nắng cháy, không kể mưa rào. “Chuyện đang ngủ mà nhận cuộc gọi chạy đi xử lý sự cố là thường xuyên đấy mà”. Một buổi sáng nọ, tôi bốc máy gọi điện cho anh Vi để xin cái hẹn chia sẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 894, tokens 200, triggered by: token limit\n",
      "\u001b[32mLần trong tiếng gió, tiếng ồn ào của xe cộ ở đâu đây bên kia là giọng anh vang lên gấp gáp: “Alo, Vi đang đi công tác mà đang ở ngoài đường nữa, tối Vi về Vi gọi lại nghe”. Một mình cần cã mạng cơ điện của chi nhánh miền Trung nên hầu như thời gian trực xử lý sự cố của anh là 24/7, sẵn sàng đứng dậy đi bất cứ lúc nào, thời gian ở ngoài đường luôn nhiều hơn thời gian tại văn phòng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 895, tokens 104, triggered by: 0.20\n",
      "\u001b[34mSau vài lần hẹn lại, cuối cùng tôi cũng trao đổi được với anh qua điện thoại vào một buổi chiều muộn, sau khi xử lý xong một sự cố phát sinh. Anh hào hứng chia sẻ cùng tôi những câu chuyện, những kỷ.Phần II:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 896, tokens 149, triggered by: token limit\n",
      "\u001b[35mKý - CMC in our heart  niềm với nghề. Ngành nghề của kỹ thuật khá đặc thù khi công việc không được tính theo giờ hành chính, mà phải chạy theo sự vụ, bất kể ngày hay đêm. Có hôm 1-2h sáng đang ngủ ngon giấc thì nhận được cuộc gọi báo trạm mất điện, là anh Vi lại chuẩn bị đồ đạc khăn gói lên đường ngay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 897, tokens 166, triggered by: token limit\n",
      "\u001b[31mBạn cũng phỏng như một thói quen hỏi luôn: “Lại sự cố hả?”   “Nhớ hôm đó mất điện đúng cái trạm không có máy phát, mà ác quỷ thì chỉ duy trì được 5-6 tiếng thôi, vậy là anh em lại chạy trong đêm đi thuê máy phát và mua xăng. Khổ nỗi lúc nửa đêm thế thì có ai bán xăng cho mình đâu, thế là phải đi mất hơn 1 tiếng mới mua được xăng mang về.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 898, tokens 140, triggered by: token limit\n",
      "\u001b[32mSau đó anh em xử lý đến 6h sáng thì cũng xong, tinh bung về nghỉ ngơi thì lại nhận được cuộc gọi có trạm khác mất điện, thế là lại chạy đi luôn” - Anh Vi kể lại - “Nhưng may trạm đấy có máy phát điện nên Vi tranh thủ đi ăn bát phở rồi mới chạy qua, chứ không ăn thì gục ngã mất, haha”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 899, tokens 187, triggered by: 0.14\n",
      "\u001b[34mLại có hôm, anh Vi đang xin nghỉ phép về Quảng Bình ăn cưới, thì nhận được cuộc gọi có sự cố gấp ở Khánh Hòa, mà lúc đó ngoài anh ra có ai làm thay được nữa đâu. Vậy là không có nghỉ phép gì nữa hết, anh bắt xe khách đi thẳng vào Khánh Hòa luôn. “Cũng may là Vi chưa lấy vợ nên vẫn tự mình quyết định được thời gian đó” - Anh vừa cười vừa nói.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 900, tokens 81, triggered by: 0.19\n",
      "\u001b[35m“Trận lũ tháng 10/2022 là kỷ niệm khó quên trong cuộc đời”   Tháng 10/2022, miền Trung đón cơn bão lịch sử và hệ lụy kéo theo là lũ lụt nặng nề.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 901, tokens 112, triggered by: 0.30\n",
      "\u001b[31mNước dâng trắng xóa mọi miền, các nhà trạm.cũng như cơ sở vật chất của CTel ở miền Trung cũng chịu thiệt hại nghiêm trọng. Anh em miền Trung phải tâm gác lại nghĩa vụ với gia đình, quên ăn quên ngủ để đi xử lý sự cố.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 902, tokens 182, triggered by: 0.23\n",
      "\u001b[32mAnh Vi hồi tưởng lại: \"Vẫn nhớ như in hôm mưa lũt đấy, mình chạy đi ứng cứu trạm DNG001 - đấy là 1 trạm rất quan trọng vì nó đi quốc tế, lại là vị trí trọng điểm nối 2 đầu CVCS Bắc - Nam, nếu để mất tín hiệu thì thiệt hại nặng nề lắm. Trèo ngoe thay trạm này lại nằm ở vùng ngập lũ nặng của Đà Nẵng, trong không ra được mà ngoài cũng không vào được.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 903, tokens 259, triggered by: token limit\n",
      "\u001b[34mLúc đó công an còn không cho đi cơ, nên mấy anh em còn phải đi bộ mười mấy km vào. Tới lúc thông đường thì mới lấy xe chở máy phát vào ứng cứu được, cũng may mà có anh Hiệp có điện ở Hà Nội vào hỗ trợ Vi nữa. Đột đó Đà Nẵng thiệt hại nhiều lắm, vậy nên sau khi xử lý xong sự cố là bọn mình lại qua hỗ trợ các anh xử lý cấp, anh em quần quật hết cả tháng mới xuôi xuôi.\" Cuộc gọi kết thúc, nhưng những câu chuyện chất phác nhưng chứa đựng trong mình tình yêu lớn lao với công việc của anh Vi cứ quanh quẩn trong đầu tôi mãi.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 904, tokens 188, triggered by: 0.11\n",
      "\u001b[35mCó lẽ đúng như câu hát được vang lên trong tối Gala 15 Năm Từ Hao: \"Ai cũng chọn việc nhẹ nhàng, gian khó để đồng đội\", anh Vi cùng các anh em kỹ thuật luôn chọn về phần mình những công việc nặng nhọc, khó khăn, để cùng tạo nên sự phát triển của CTel như hiện tại. Miền Trung ơi, chỉ mong nắng đừng đổ lửa, mong trời đừng bão giông, để trên vai đồng đội tôi bớt những nhọc nhằn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 905, tokens 75, triggered by: 0.32\n",
      "\u001b[31m.Phần II: Kỷ - CMC in our heart HAI LẦN \"XUYÊN VIỆT\" ĐỂ NỐI LIÊN TUYẾN CẬP ĐƯỜNG TRỰC CVCS BẮC - NAM  Tác giả:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 906, tokens 71, triggered by: 0.28\n",
      "\u001b[32mTrần Văn Đức Trung tâm Kỹ thuật miền Nam - CMC Telecom  Tôi vào CTel vào một ngày hè năm 2011 với vị trí Chuyên viên phòng Kỹ thuật dự án của TTKT miền Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 907, tokens 77, triggered by: 0.15\n",
      "\u001b[34mNgày đó, CTel (lúc bấy giờ là CMC TI) vẫn còn là một công ty non trẻ trên thị trường với hạ tầng ít ỏi, chưa sở hữu được mạng truyền dẫn riêng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 908, tokens 192, triggered by: token limit\n",
      "\u001b[35mVì vậy chúng ta thiếu chủ động trong việc triển khai dịch vụ cho khách hàng và cũng chưa có nhiều cơ hội hợp tác với các đối tác lớn. Công việc của tôi tương chung như cụ thể trời, cho đến một ngày đầu năm 2017, Ban Lãnh đạo quyết định triển khai dự án xây dựng tuyến cáp đường trực CVCS nối liền 2 miền Bắc - Nam để nâng cấp hạ tầng của chính mình, tăng lợi thế cạnh tranh trên thị trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 909, tokens 137, triggered by: token limit\n",
      "\u001b[31mTôi nhận được lời đề nghị từ anh Lê Trọng Thanh - D.CEO và cũng là trưởng dự án - về việc gia nhập dự án với vai trò PM phụ trách gói xây dựng hạ tầng cáp. Biết rằng đây là cơ hội lớn để thử thách bản thân qua dự án quan trọng của công ty, tôi không ngần ngại gật đầu ngay.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 910, tokens 151, triggered by: token limit\n",
      "\u001b[32m.Những ngày đầu khi bắt tay vào dự án, tôi cùng anh Nguyễn Phú Kiều - PM tổng của toàn bộ dự án - phải cùng chuyên gia của TIME dotCom đi đọc chiều dài tuyến trực để khảo sát, đánh giá tình hình trước khi triển khai. Tuyến cáp có chiều dài bao nhiêu, cũng chính là bấy nhiêu km anh em cùng nhau rong ruổi trên đường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 911, tokens 123, triggered by: token limit\n",
      "\u001b[34mTôi khởi động chuyến đi bằng một chuyến bay dài từ Sài Gòn để gặp anh Kiều và đội tác tại Hà Nội. Từ đây, chúng tôi bắt đầu hành trình. Đến điểm Đồng Hôi, chúng tôi đổi xe sang xe của miền Trung để tiến khảo sát tuyến trực tại đây.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 912, tokens 138, triggered by: 0.28\n",
      "\u001b[35mHết địa phận miền Trung, tôi trạm Bình Định, anh em lại xe miền Nam đã chờ sẵn ở đó để đưa chúng tôi đi tiếp cho đến khi tôi trạm cuối là cửa khẩu Mộc Bài. Suốt chiều dài gần 2000km đọc dất nước ấy, chúng tôi phải sắp xếp lịch trình để làm sao hoàn thành nhanh nhất có thể.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 913, tokens 62, triggered by: 0.15\n",
      "\u001b[31mVơi phương châm lấy xe là nhà, lấy ghế làm giường, phần lớn thời gian.Phần II: Ký - CMC in our heart  của chúng tôi là ở trong ô tô.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 914, tokens 137, triggered by: 0.26\n",
      "\u001b[32mNgoài những lúc trao đổi công việc, anh em cũng tranh thủ chợp mắt cho lại sức, hoặc ăn với chút gì đó để lấy sức cho chặng tiếp theo. Lại có những điểm trạm ở sâu trong những vùng xa, xe có đi lại khó khăn, anh em vẫn phải cố gắng tiếp cận để khảo sát đúng thực tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 915, tokens 76, triggered by: 0.34\n",
      "\u001b[34mCũng nhờ việc sắp xếp lịch trình hợp lý mà anh em vẫn đảm bảo được sức khoẻ để hoàn tất chuyến đi \"phượt\" kéo dài rộng rã gần 20 ngày.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 916, tokens 57, triggered by: 0.22\n",
      "\u001b[35mKhi dự án chạy được nửa thời gian, tôi lại đi \"xuyên Việt\" một lần nữa để kiểm tra tiến độ, đánh giá nhà thầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 917, tokens 161, triggered by: token limit\n",
      "\u001b[31mLần này là đi với anh Thanh. Cũng may mỗi miền đều đã có nhân sự phụ trách dự án trực tiếp, chúng tôi đi đến điểm nào đều được hỗ trợ tận tình. Vị thế, cũng từng ấy chiều dài, cũng ngắn ấy thời gian, và đương nhiên đã quen với những chuyến đi dài, chúng tôi đều thấy lần thứ hai này nhẹ nhàng và thuận lợi hơn hẳn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 918, tokens 174, triggered by: token limit\n",
      "\u001b[32mNhìn lại hành trình 6 tháng đồng hành cùng tuyến trực, tôi tự thấy bản thân sao ngày đó nhiều năng lượng và \"trâu\" đến vậy. Bây giờ nếu được làm lại, chưa chắc tôi đã làm tốt được như ngày ấy. Có lẽ chính vì ý nghĩa lớn của dự án, không chỉ với CTel, mà với chính bản thân tôi, đã giúp tôi vượt qua tất cả để dầm thắm bản thân mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 919, tokens 154, triggered by: token limit\n",
      "\u001b[34mNhìn hạ tầng của CTel ngày một lớn mạnh, tôi cũng cảm thấy vui và tự hào vì mình được góp một phần công sức để xây dựng và phát triển nên chúng. .Save Memory  Điều tiếc nuối lớn nhất với tôi là cho đến khi kết thúc, những người đồng đội cùng đồng hành trong dự án chưa một lần được gặp mặt đông đủ cả đội.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 920, tokens 152, triggered by: token limit\n",
      "\u001b[35mNhững giờ họp căng thẳng, những khó khăn đã trải qua, những ngày cùng nhau rong ruổi suốt chiều dài đất nước đã trở thành kỷ niệm khó quên trên hành trình hơn 10 năm đồng hành cùng CTel của tôi. Giờ đây, tuyến cáp đường trục CVCS Bắc - Nam tổng chiều dài hơn 2.500 km đã trở thành một trong niềm tự hào của người CTel.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 921, tokens 148, triggered by: 0.33\n",
      "\u001b[31mCó những người đã rời đi, có những người còn ở lại, nhưng những đóng góp của họ cho dự án sẽ mãi là điều mà CTel luôn trân trọng và biết ơn ngày hôm nay. .Phần II: Ký - CMC in our heart NGƯỜI PHỤ NỮ VỚI HÀNH TRÌNH LÀM ĐẸP  VĂN PHÒNG CTEL CÓ TUYỆT - CTEL DUY TẤN:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 922, tokens 296, triggered by: token limit\n",
      "\u001b[32m\"CÁC CHÂU CHÍNH LÀ ĐỘNG LỰC ĐỂ CÓ DI LÀM MỖI NGÀY\" Tác giả: Nguyễn Thị Hằng Văn phòng công ty - CMC Telecom Tại Văn phòng CTel Duy Tấn, cứ sáng sáng, khi văn phòng còn vắng tanh bóng người, đã có một bóng dáng nhỏ bé cặm cụi quét dọn, lau từng chiếc bàn, gom từng mảnh rác, đặt lại gọn gàng từng đồ vật. Đôi chân nhanh nhẹn, bàn tay thoăn thoắt để cho kịp giờ vào làm của CTel. Đến khi mọi người lục tục kéo đến,  du khuôn mặt có luôn khuất sau lớp khẩu trang dày, nhìn đôi mắt nhéo lại và cái gật đầu khe của cô, tôi biết cô đang mỉm cười tươi chào mọi người.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 923, tokens 166, triggered by: token limit\n",
      "\u001b[34mHình ảnh đó đã gây ấn tượng đặc biệt với tôi suốt những tuần đầu tiên đi làm. Và cho đến tận bây giờ, khi đã là một nhân viên có chút \"kỳ cựu\" ở CTel, tôi hằng ngày vẫn luôn bắt gặp hình ảnh đó. Dường như, đó đã là một thói quen, một hình ảnh quá đỗi bình thường và bình yên mỗi sáng tại nơi tôi làm việc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 924, tokens 175, triggered by: token limit\n",
      "\u001b[35mTôi còn nhớ như in cái chiều 30 Tết năm 2022, khi mà nhà nhà quây quần bên nồi bánh chưng đỏ lửa, vẫn bóng người ấy khéo léo tỉa hoa, xếp quà bày biện bàn thờ công ty. Chỗ lẻ xống xuôi, cô lại đảo một vòng các tầng, kiểm tra kỳ lưỡng từng ngóc ngách trong văn phòng, để năm mới CTelers có một nơi làm việc sạch đẹp trong dịp.Khai Xuân.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 925, tokens 162, triggered by: 0.28\n",
      "\u001b[31mNăm nào cũng thế, cô luôn là người cuối cùng rời văn phòng, rồi lại vội vã chạy xe về cho kịp bữa cơm chiều cuối năm. Nếu không phải hôm đó tôi có việc cần lên công ty giải quyết, có lẽ cũng chẳng bao giờ tôi biết được cô đã hi sinh thời gian của bản thân và gia đình để thực hiện trách nhiệm \"cao quý\" đó gần 9 năm trời.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 926, tokens 189, triggered by: token limit\n",
      "\u001b[32mNgười phụ nữ ấy chúng tôi quen gọi với cái tên thân thương - cô Tuyết. Hơn 8 năm gắn bó với CTEL, là 8 năm cô làm bạn với từng thế hệ, từng con người, từng nhánh cây, từng vị trí nơi đây. Cô thuộc hết chỗ ngồi từng bộ phận, biết rõ hôm nay có nhân viên mới nào vào, nhân viên nào rời đi. Cô không chỉ thành thạo công việc của riêng mình, mà còn hỗ trợ tốt công việc của các bộ phận khác.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 927, tokens 197, triggered by: 0.28\n",
      "\u001b[34mHôm nào vị trí lệ tân, hành chính thiếu người, lại thấy cô tất bật đứng chỗ này, chạy chỗ kia \"support\" để các công việc vẫn diễn ra trơn tru, đều đặn. Tôi không biết từ lúc nào, trong lòng tôi đã coi cô như \"người phụ nữ\" thân thuộc nhất trong ngôi nhà CTel thân yêu này. Cô Tuyết vào CTEL từ ngày số lượng nhân sự công ty chỉ có 70 - 80 người, cô Tuyết là \"địa chỉ tin cậy\" được nhiều chị em CTEL xin tư vấn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 928, tokens 115, triggered by: 0.10\n",
      "\u001b[35mCô rõ địa chỉ nào mua xôi gà chuẩn, chỗ nào có hoa quả tươi ngon. Cô biết anh này thích món gì, chị này gu ăn uống ra sao. Cô dễ ý anh chị em trong văn phòng cô gì cần khó khăn để hỗ trợ kịp thời trong khả năng của cô.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 929, tokens 80, triggered by: 0.36\n",
      "\u001b[31mCMC 31.Phân II: Ký - CMC in our heart  Tiếng gọi \"cô Tuyết ơi\" đã trở thành câu cửa miệng quen thuộc, thân thương của mỗi lớp cán bộ nhân viên CTel trong biết bao năm trời.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 930, tokens 101, triggered by: token limit\n",
      "\u001b[32mTôi biết, cô Tuyết chỉ là một trong số ít những người đã và đang thầm lặng đồng góp vào hành trình 15 năm phát triển đầy tự hào của CTel, cũng như góp phần nhỏ bé vào sự phát triển lớn mạnh của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 931, tokens 183, triggered by: 0.36\n",
      "\u001b[34mHơn 8 năm trời qua, cô Tuyết vẫn ngày ngày lẳng lẽ ở đây, người phụ nữ với những nếp nhăn trên mặt, nét chân chim vấn in đầy trên đuôi mắt, cô lặng lẽ chứng kiến CTel với bao lần thăng trầm, đổi thay, khó khăn, sóng gió, rồi lại vươn mình mạnh mẽ. Người phụ nữ nhỏ bé ấy chưa một lần đòi hỏi về vật chất, cô tâm sự với tôi:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 932, tokens 57, triggered by: 0.05\n",
      "\u001b[35m\"với nhiều người, tiền bạc có thể quan trọng thật đấy, nhưng các cháu mới chính là động lực để cô đi làm mỗi ngày\"!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 933, tokens 207, triggered by: token limit\n",
      "\u001b[31m. .CHỨNG MINH LÀ NHỮNG CÔ GÁI SALE \"ÍT MẶC VÂY NHẤT\" NHÀ CMC GLOBAL  Tác giả: Vũ Thị Anh Thư Phòng kinh doanh Mega 2 - CMC Global  Hẳn mọi người đều nghĩ rằng, làm sale mà lại là con gái thì chắc phải chăm chút lắm, điệu đà lắm, mỗi ngày đi làm đều sẽ là những \"outfit\" thật rạng rỡ thật nổi bật. Ấy thế mà mọi người lại nói rằng \"MBU2 có lẽ là những nàng sale ít mặc váy nhất\".\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 934, tokens 93, triggered by: 0.32\n",
      "\u001b[32mChẳng mấy bắt ngó đâu khi chúng mình phải đi chuyển để họp và trao đổi với khách hàng rất nhiều do tính chất dự án. Có khi dự án ở 3 site, chúng mình ngồi 1 site và các sếp lại ngồi 1 site.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 935, tokens 68, triggered by: 0.21\n",
      "\u001b[34mLịch họp dày đặc nên chúng mình thường chọn những trang phục như quần dài ống suông, quần bò dài,. . . để di chuyển nhanh nhất, dễ dàng nhất.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 936, tokens 163, triggered by: token limit\n",
      "\u001b[35mCơ mà, chúng mình cũng chẳng để ý tới điều đó lắm đâu. Vì với cả Team miền công việc đặt hiệu quả tốt nhất, khách hàng hài lòng với dịch vụ công ty cung cấp, các sếp yên tâm giao nhiệm vụ mới, thì dù chẳng được váy vóc điệu đà, dù đầu tắt mặt tối, cả team vẫn luôn tươi cười, vui vẻ và tận hưởng lắm.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 937, tokens 97, triggered by: 0.32\n",
      "\u001b[31mMình nhớ có lần, tối đó sẽ có sự kiện công ty, cả team háo hức hẹn nhau phải cố gắng xong việc sớm, chuẩn bị lung linh tới tiệc. Nhưng làm sale mà, khách hàng cần support lúc nào, mình phải có.Phân II:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 938, tokens 67, triggered by: 0.36\n",
      "\u001b[32mKý - CMC in our heart  gắng hỗ trợ ngay lúc đó. Dù án có issue gấp, cả team tum tum làm cùng nhau, đến giờ ăn tiêc với và tối Hôi trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 939, tokens 162, triggered by: 0.30\n",
      "\u001b[34mChẳng make up, chẳng kịp là lượt váy áo, tóc tai có tí lộn xộn. Chúng mình như những cô lo lem tới bữa tiệc, nhưng lại chưa gặp chàng hoàng tử nào. Nói vui vậy thôi, chủ giải quyết xong issue cho khách hàng, là tui mình vui hơn làm công chúa luôn rồi. Mê lắm cảm giác cả Team cùng dỗ lên \"Xong rồi, quay thôi chi em ơi!\".\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 940, tokens 167, triggered by: token limit\n",
      "\u001b[35mLà người dẫn dắt cả team, mình luôn mong muốn làm sao có thể vừa giúp các bạn có trải nghiệm tuyệt vời nhất khi làm việc, vừa đào tạo, định hướng cho các bạn những lộ trình phát triển phù hợp nhất. Vì la Team Sale toàn con gái, nên có những lúc chúng mình gặp những rắc rối trong việc trao đổi, giao tiếp và giải quyết vấn đề cùng nhau.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 941, tokens 186, triggered by: 0.09\n",
      "\u001b[31mCó khi cả Team trầm lắng, chẳng ai nói với ai câu nào, mình cũng buồn lắm. Nhưng mình quyết tâm khắc phục và tháo bỏ nút thắt, lên kế hoạch cho Team cùng nhau đi dã ngoại, tâm sự và thẳng thắn giải quyết tất cả cùng nhau. Và chính nhờ cuộc Team Building đó, chúng mình hiểu nhau hơn, ngay sáng hôm sau không khí Team khác hẳn, mọi người lại coi mò với nhau như trước đây.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 942, tokens 141, triggered by: 0.13\n",
      "\u001b[32mThật tự hào và hạnh phúc khi có những người chi em như vậy  Và tất nhiên, bằng tất cả sự nỗ lực và cố gắng, MBU2 chứng minh có những thành tựu khiến mọi người sẽ trầm trồ: năm 2022, Account khách hàng của MBU2 chiếm gần 40% doanh thu toàn công ty; Khách hàng của MBU2 là khách hàng chiến lược, mô hình:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 943, tokens 75, triggered by: 0.31\n",
      "\u001b[34mMBU2 đã trải qua 2 thời kỳ đại dự án S500 và S1K. .CMC family  MBU2 đối với mình như 1 gia đình nhỏ và CMC Global, Tập đoàn CMC chính là 1 gia đình lớn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 944, tokens 110, triggered by: 0.28\n",
      "\u001b[35mChúng mình muốn gắn bó lâu thật lâu, muốn cống hiến và đem tất thảy những hoài bão, ước mơ chinh phục những khách hàng lớn nhất, khó tính nhất. Và các chị em MBU2 ơi, chị luôn luôn tự hào và hạnh phúc khi có được các em.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 945, tokens 139, triggered by: 0.28\n",
      "\u001b[31mMai yêu mọi người thật nhiều! .Phần II: Ký - CMC in our heart  CMC HUY HOÀNG HƯỚNG TƯƠNG LAI  Tác giả: Dương Huyền Trang Văn phòng Tập đoàn - CMC Telecom  Tháng 5 rợp trời hoa phượng Rạo rực say mê sức sống căng tràn Trái tim ngập trong nắng vàng Di sản muôn vàn, tình yêu và nỗi nhớ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 946, tokens 146, triggered by: 0.33\n",
      "\u001b[32m30 năm qua khó khăn dai dẳng “số” CMC minh chứng ngàn đều vượt qua Mấy ngàn “anh em” chung sức xây nhà Một ngôi nhà chung, xứng danh ngàn tỉ. Hướng thành công, là hướng của khát khao Bước chân chúng ta trải khắp miền đất Nước Từ Bắc vô Nam, mọi nẻo đường in bước Sức mạnh đồng lòng, ý chí CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 947, tokens 153, triggered by: token limit\n",
      "\u001b[34mTháng Năm hè về ta vẫn bước đi Đà Nẵng - Hội An thẳng đường ta tiến Hành trình 30 năm chúng ta còn tiếp diễn Di sản để đời, ta kiến tạo tương lai. CMC nhiều khi nhanh như đàn Dinh hướng mục tiêu đời khi phải đánh liều Để rồi thành công gặt hái ngày một nhiều CMC vững bền, như Phượng lửa vút cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 948, tokens 144, triggered by: 0.32\n",
      "\u001b[35mMọi thành công đều phải đạp lên chông gai CMC ơi, sát vai cùng vững bước Hôm nay ước ao, ngày mai phải đạt được CMC huy hoàng cất bước vượt tương lai. .CMC CREATIVE SPACE TÂN THUẬN TRÁI TIM MIỀN NAM  Tác giả: Phuong Bui Ban NS&PTNT - CMC Corp  Khó khăn và thử thách là một gia vị không thể thiếu trong cuộc sống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 949, tokens 117, triggered by: 0.20\n",
      "\u001b[31mNhững người bước qua con bảo với lòng kiên trì và quyết tâm sẽ nhận được niềm vui ngọt ngào. CMC Creative Space Tân Thuận là niềm tự hào, là tình yêu của hơn 6000 Người CMC, là thành quả của nỗ lực ngày đêm trong thời điểm cả nước gồng mình với dịch bệnh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 950, tokens 127, triggered by: 0.22\n",
      "\u001b[32mCuộc chạy đua với những điều vô hình  Chiều ngày 08/07/2021, một buổi chiều lịch sử đối với những người dân của Thành phố mang tên Bác – những giờ phút cuối cùng trước khi Thành phố thực hiện cách ly xã hội trong vòng 15 ngày do diễn biến phức tạp của dịch Covid-19.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 951, tokens 58, triggered by: 0.24\n",
      "\u001b[34mNhững con số đủ sức làm choáng mình đối những trái tim kiên cường nhất: 314 ca bệnh được ghi nhận trong ngày tại Thành phố Hồ Chí Minh.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 952, tokens 109, triggered by: 0.17\n",
      "\u001b[35mMột thành phố vốn sôi động, nhộn nhịp giờ chìm trong không khí xo xác và tiêu điều. Khu Chế xuất Tân Thuận - Phường Tân Thuận Đông, Quận 7 hôm ấy vắng và hơn mọi ngày rất nhiều, tất cả hội hả như đang trong một cuộc đua.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 953, tokens 87, triggered by: 0.22\n",
      "\u001b[31mChi khác rằng, trong chẳng đua thực tế, chúng ta biết mình cần chạy đến một đích đến cụ thể. .Phần II: Ký - CMC in our heart  Còn ở chặng đua lần này tất thấy đều thật mơ hồ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 954, tokens 57, triggered by: 0.21\n",
      "\u001b[32mTải lô đất 2728, công trường xây dựng CMC Creative Space đang ngồn ngộn nào những bê tông, những khung kính, sắt thép.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 955, tokens 84, triggered by: 0.14\n",
      "\u001b[34mNhững người kỹ sư với vàng đơn giấy tờ cần thiết để kịp “giờ giỏi nghiệm”, chuẩn bị thức ăn và như yếu phẩm cần thiết cho một nhóm nhỏ công nhân nhận nhiệm vụ ở lại công trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 956, tokens 54, triggered by: token limit\n",
      "\u001b[35mHọ đâu thể ngờ được rằng, 15 ngày - 1 tháng - 2 tháng - 4 tháng sau đó, cả thành phố mới được thức dậy.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 957, tokens 159, triggered by: token limit\n",
      "\u001b[31m\"Sau đó các cung đường bị lockdown hết nên anh em công nhân, bảo vệ của nhà thầu không đi đâu được chỉ có tiếp tế đồ ăn vào trong đó thôi, nhưng tới thời gian sau gần như không được hỗ trợ nữa, anh em công nhân thời điểm đó chỉ ăn mì gói và cơm trắng thôi, tôi ho lắm.\" (Anh Phan Gia Khánh - Quản lý tòa nhà CMC Creative Space xúc động nhớ lại).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 958, tokens 161, triggered by: token limit\n",
      "\u001b[32mTrong giông bão ta thấy mình mạnh mẽ hơn  Ngay từ khi bắt đầu khởi công xây dựng vào tháng 12/2019, Dự án Không gian Sáng tạo CMC (CMC Creative Space) đã gây tiếng vang trong cộng đồng với tâm nhìn trở thành tổ hợp không gian làm việc đẳng cấp; đặc biệt là Data Center hiện đại nhất Việt Nam,t khẳng định vị thế trên bản đồ Data Center thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 959, tokens 170, triggered by: token limit\n",
      "\u001b[34mĐể đảm bảo tiến độ thi công, một màn hình được dựng lên tại \"đại bản doanh\" CMC Tower - Duy Tân, Cầu Giấy; sẵn sàng cập nhật.và chỉ đạo thi công 24/7. Đội kỹ thuật Data Center hộp ngày đêm, hộp xuyên quốc gia với đối tác TIME dotCom và đối tác thiết kế Singapore để đảm bảo tiến độ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 960, tokens 179, triggered by: token limit\n",
      "\u001b[35mCó những thời điểm, khối lượng công việc gấp hai, gấp ba. Các thành viên của tổ dự án và hơn 200 công nhân xây dựng hoạt động ngày đêm với một mục tiêu duy nhất: hiện thực hóa toà nhà ước mơ của người CMC với tốc độ - kỳ luật cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 961, tokens 132, triggered by: 0.31\n",
      "\u001b[31mDịch bệnh khiến công trình ngưng động 4 tháng trời. Khi thành phố thức giấc, tổ dự án đối mặt với những thách thức khó khăn hơn: bảng mọi giải phải đẩy nhanh tiến độ thi công!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 962, tokens 176, triggered by: 0.31\n",
      "\u001b[32mMừng 8 Tết Nhận Đán (2022), trong khi khắp nơi hàn hoan không khí chào xuân mới, văn phòng của tổ Dự án tại Hà Nội càng thắng hơn bao giờ hết. Dịch bệnh khiến mấy mốc năm im, công trường động bảng kéo theo nhiều cơ hội kinh doanh rơi vào bế tắc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 963, tokens 111, triggered by: 0.27\n",
      "\u001b[34mTình thế cấp bách, một nhóm chuyên gia về Data Center của CMC Telecom nhận lệnh: \"Vào năm vùng ở Tân Thuận, chưa xong dự án chưa về.\"  Sản bay Nội Bài vắng lặng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 964, tokens 158, triggered by: 0.07\n",
      "\u001b[35mChằng trai trẻ Lê Minh Hiệu - Giám đốc Khoải Data Center CMC Telecom tay xách hành lý đơn giản, miệng đeo khẩu trang kín mít, nhanh chóng đưa giấy tờ nhanh qua cửa an ninh, chỉ mong sao đừng để bị chặn lại vì những thủ tục phức tạp ngày dịch. Di cũng là anh Phó Đức Kiên - Phó Tổng giám đốc CMC Telecom.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 965, tokens 61, triggered by: 0.10\n",
      "\u001b[31m.Phần II: Ký - CMC in our heart  Hai anh mang sự quyết tâm và trái tim người CMC, sẵn sàng tiến về trái tim miền Nam - CMC Creative Space Tân Thuận.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 966, tokens 101, triggered by: 0.34\n",
      "\u001b[32mMột văn phòng đã chiến được lấp lên ở tòa nhà mới chỉ xây xong phần thô. Tất cả quản lý và nhà thầu được yêu cầu có mặt chỉ đạo công nhân trực tiếp và họp rà soát tiến độ, chất lượng thi công mỗi ngày cùng tổ dự án.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 967, tokens 172, triggered by: token limit\n",
      "\u001b[34mKhu chế xuất Tân Thuận ghi dấu những ngày tháng lịch sử, công trường CMC Creative Space chưa một phút dừng hoạt động bất kể ngày đêm. Sau tháng chạy đua nước rút cùng CMC Creative Space Tân Thuận là sau tháng tăng ca không biết đến ngày nghỉ. Tiếng máy xúc, máy khoan, tiếng kim loại chưa từng ngơi nghỉ như nối thay trái tim nhiệt huyết và quyết tâm cháy bỏng của người CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 968, tokens 97, triggered by: 0.21\n",
      "\u001b[35mTrái tim miền Nam  CMC Creative Space là công trình thể hiện khát vọng, ý chí vươn lên ngang tầm thế giới của CMC. Với tổng kinh phí lên đến 1500 tỷ đồng, nơi đây là khu phức hợp gồm 3 khối nhà chính:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 969, tokens 92, triggered by: 0.19\n",
      "\u001b[31mBlock A và B có chức năng văn phòng có tổng diện tích sàn lên tới 57000 m2, Block DC là Trung tâm dữ liệu có tổng diện tích sàn 10.000 m2. Sau khi hoàn thiện, dự án truyền tải mạnh mẽ thông điệp của CMC:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 970, tokens 107, triggered by: token limit\n",
      "\u001b[32mCông nghệ hiện đại, sáng tạo và thân thiện với môi trường. .Trái tim của tòa nhà nằm ở giữa, là trung tâm dữ liệu lớn nhất Việt Nam: Tần Thuận Data Center được xem là Trung tâm Dữ liệu hiện đại nhất Việt Nam với quy mô 1.200 tủ rack.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 971, tokens 191, triggered by: token limit\n",
      "\u001b[34mTrung tâm Dữ liệu được xây dựng dựa trên những tiêu chuẩn an toàn cao nhất cùng hàng loạt tiêu chuẩn đặc biệt về bảo mật dành riêng cho một DC như TVRA, Chứng chỉ Uptime Tier III (TCDD & TCCF), tiêu chuẩn TIA 942, PCI DSS, ISO… Trong đó, TVRA (Threats, Vulnerability and Risk Assessment) là tiêu chuẩn bảo mật và chống rủi ro cấp độ cao áp dụng cho DC được Ngân hàng Nhà nước Singapore đề xuất áp dụng cho các DC trong nước và quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 972, tokens 139, triggered by: token limit\n",
      "\u001b[35mCMC Creative Space nói chung và Data Center Tần Thuận nói riêng đã vượt qua 115 bài test với các tiêu chuẩn, quy định rất cao theo tổ chức đánh giá quốc tế. Đây là bước đánh dấu khởi đầu để Việt Nam trở thành digital hub của khu vực, mang theo niềm hy vọng trở thành trái tim trong hoạt động chuyển đổi số tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 973, tokens 174, triggered by: token limit\n",
      "\u001b[31mTự hào màu áo CMC  Những ngày tháng 04/2022, những dòng xanh màu áo CMC đổ về Tần Thuận trong không khí vui tươi và phấn khởi. Anh em CMC từ khắp mọi nơi giờ tại Thành phố Hồ Chí Minh giờ về chung một mái nhà, cùng hợp tác, phát triển. .Ngày 25/08/2022, CMC Creative Space vinh dự được đón Chủ tịch nước đến dự lễ khánh trương Trung tâm Dữ liệu CMC Data Center.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 974, tokens 116, triggered by: 0.05\n",
      "\u001b[32mLễ khai trương CMC Data Center Tân Thuận còn có sự tham dự của Bộ trưởng Bộ Thông tin & Truyền thông Nguyễn Mạnh Hùng; Bộ trưởng Bộ Khoa học Công nghệ Huỳnh Thành Đạt, lãnh đạo Bộ Kế hoạch và Đầu tư, UBND TP.HCM, Đà Nẵng, Cần Thơ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 975, tokens 52, triggered by: 0.18\n",
      "\u001b[34m. . Phát biểu tại buổi lễ khai trương, Chủ tịch nước đương thời - ông Nguyễn Xuân Phúc nhận mạnh:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 976, tokens 133, triggered by: 0.32\n",
      "\u001b[35m\"Tôi biểu dương Tập đoàn Công nghệ CMC đã có những bước phát triển thắng lợi, tốc độ tăng trưởng hàng năm rất cao, đạt được nhiều thành tựu, giải thưởng nội bật trong nước và quốc tế. Đặc biệt Tập đoàn luôn chú trọng, đầu tư nghiên cứu phát triển các công nghệ mới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 977, tokens 201, triggered by: token limit\n",
      "\u001b[31mTôi hy vọng Trung tâm Dữ liệu CMC Tân Thuận sẽ là trái tim trong hoạt động chuyển đổi số. Việc đầu tư thực hiện xây dựng trung tâm dữ liệu với tiêu chuẩn kỹ thuật cao hiện đại và an toàn là một bước tiến rất đột phá, có ý nghĩa quan trọng góp phần đẩy nhanh quá trình phát triển kinh tế số của nước.\"  Sau tất cả, một CMC Creative Space đã thành hình, sừng sững hiện ngang khiến trái tim bao người CMC rung lên hai chữ TỰ HÀO!\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 978, tokens 54, triggered by: 0.17\n",
      "\u001b[32m.BAN BIÊN TẬP Xin trân trọng cảm ơn sự đồng góp và tham gia của:  1. Ban cố vấn Sử ký CMC 30:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 979, tokens 196, triggered by: token limit\n",
      "\u001b[34mMr. Nguyễn Trung Chính - Chủ tịch HĐQT/ CT ĐHTD - Trưởng ban Chỉ đạo Mr. Hồ Thanh Tùng - Tổng giám đốc Tập đoàn Mr. Lê Thanh Hiếu - Phó chủ tịch điều hành/ Giám đốc Tài chính Tập đoàn Mr. Ngô Trọng Sơn - Phó chủ tịch điều hành Tập đoàn/ TGB CMC Telecom Mr. Nguyễn Hồng Sơn - Cố vấn Chủ tịch HĐQT Mr. Đặng Ngọc Bảo - Phó chủ tịch cấp cao Tập đoàn/ Tổng giám đốc CMC Global Mr.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 980, tokens 94, triggered by: 0.29\n",
      "\u001b[35mNguyễn Ngọc Bình - Hiệu trưởng Trường Đại học CMC Mr. Nguyễn Phước Hải - Tổng giám đốc CMS Mr. Trần Lê Thu - Chánh văn phòng Tập đoàn Ms. Nguyễn Thanh Luu - Trưởng Ban Marcom CMC Coip  2.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 981, tokens 195, triggered by: token limit\n",
      "\u001b[31mBan Nội dung Sử ký CMC 30: Mr. Nguyễn Trung Chính - Chủ tịch HĐQT/ CT ĐHTD - Tổng biên tập/ Phê duyệt nội dung Mr. Nguyễn Hồng Sơn - Cố vấn Chủ tịch HĐQT Ms. Nguyễn Thị Thu Hoài - Trưởng phòng Đào tạo & PT Văn hóa CMC Corp Ms. Bùi Thu Phương - CV Phát triển văn hóa CMC Coip Ms. Lại Phương Hiền - CV Sáng tạo CMC Corp Ms. Dương Huong Thao - Trưởng nhóm ECC CMC Global Ms. Vũ Mai Anh - CV ECC CMC Global Ms.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 982, tokens 137, triggered by: 0.40\n",
      "\u001b[32mNguyễn Thị Thùy Tiên - CV Phát triển văn hóa CMC Telecom  3. Ban Thiết kế, dựng E-book Mr. Chu Minh Quý - Chuyên viên E-learning CMC Corp Ms. Bùi Thu Phương - CV Phát triển văn hóa CMC Coip Ms. Nguyễn Thị Thu Hoài - Trưởng phòng Đào tạo & PT Văn hóa CMC Corp.4. Điều phối Dự án Sự kiện CMC 30:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 983, tokens 60, triggered by: 0.28\n",
      "\u001b[34mMs. Nguyễn Thị Thu Hoài - Trưởng phòng Đào tạo & PT văn hóa CMC Corp Ms. Bùi Thu Phượng - CV Phát triển văn hóa CMC Corp  5.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 984, tokens 197, triggered by: token limit\n",
      "\u001b[35mTham gia phỏng vấn: Mr. Nguyễn Trung Chính Mr. Hồ Thanh Tùng Mr. Nguyễn Hồng Sơn Mr. Tạ Hoàng Linh Mr. Ngô Trọng Hiếu Mr. Đặng Ngọc Bình Mr. Hồ Như Hải Mr. Nguyễn Việt Bách Mr. Phạm Văn Trùng Mr. Lê Quang Trưng Ms. Trần Mỹ Lệ Mr. Nguyễn Phước Hải  Ms. Hoàng Thị Lai Mr. Nguyễn Kim Cường Mr. Lê Quang Thành Mr. Hà Thế Phượng Ms. Ngô Xuân Cảnh Ms. Nguyễn Thanh Nhàn Mr. Nguyễn Việt Bách Ms.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 985, tokens 67, triggered by: 0.39\n",
      "\u001b[31mPhan Gia Khánh Mr. Bùi Thị Hường Giang Mr. Hà Đức Minh Ms. Nguyễn Tường Vy Ms. Trần Thị Sơn Ms. Tô Việt Thu Trang Ms. Nguyễn Thị Luyện Mr.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 986, tokens 162, triggered by: 0.42\n",
      "\u001b[32mNguyễn Tiến Dũng  6. Thu âm Audio: Mr. Đặng Cao Cường Ms. Nguyễn Thị Thu Hoài Ms. Bùi Thu Phượng Ms. Phạm Thu Thảo Ms. Nguyễn Phi Nga Ms. Lai Phương Hiền Ms. Kim Ngân Mr. Đỗ Việt Ninh  Ms. Nông Linh Chi Ms. Bùi Thị Thủy Linh Mr. Trần Đức Trung Ms. Nguyễn Ngọc Châm Ms. Lê Thu Hồng Ms. Nguyễn Khánh Chi Mr. Nguyễn Trần Định Ms.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 987, tokens 136, triggered by: final split\n",
      "\u001b[34mTrần Hải Anh  7. Tài liệu tham khảo: - Báo cáo thường niên Tập đoàn CMC - Báo Người CMC - Các văn bản quyết định của Tập đoàn CMC - Sử ký CMC Telecom - 15 năm tự hào - Các bài viết, thông tin trên fanpage Người CMC, fanpage CTV trong Tập đoàn  Bộ phận Phát triển Văn hóa Tập đoàn CMC thực hiện\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chunks_stas = statistic_chunking(docs=[documents])\n",
    "statistic_chunking.print(chunks_stas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('“Vậy tại sao, ở thị trường Việt Nam, mình không tự tạo nên một công  ty có thể vừa kinh doanh và lắp ráp máy tính thương hiệu Việt mà  không cần phụ thuộc vào các nước khác” - anh Chính suy nghĩ.', 195)\n"
     ]
    }
   ],
   "source": [
    "chunk_list=[x.content for x in chunks_stas[0]]\n",
    "chunk_lengths = [(chunk,len(chunk)) for chunk in chunk_list]\n",
    "print(max(chunk_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Các bạn đồng nghiệp CMC thân mến, Đối với mỗi người, tuổi 30 đánh dấu sự trưởng thành, vững vàng; là giai đoạn chuyển mình  với những hoài bão, khát khao cống hiến và mang lại nhiều giá trị hơn cho cuộc đời.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_stas[0][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Calculate the length of each chunk\n",
    "chunk_lengths = [len(chunk) for chunk in chunk_list]\n",
    "\n",
    "# Step 2: Remove outliers using the 1.5*IQR rule\n",
    "q1 = np.percentile(chunk_lengths, 25)\n",
    "q3 = np.percentile(chunk_lengths, 75)\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - 1.5 * iqr\n",
    "upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "# Filter out chunk lengths outside of the lower and upper bounds\n",
    "filtered_chunk_lengths = [length for length in chunk_lengths if lower_bound <= length <= upper_bound]\n",
    "\n",
    "# Step 3: Define the bins for the ranges (0-20, 20-40, etc.)\n",
    "bins = np.arange(0, max(filtered_chunk_lengths) + 20, 20)  # Adjust the bin size if needed (20 in this case)\n",
    "\n",
    "# Step 4: Plot histogram of filtered chunk lengths with defined bins\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.hist(chunk_lengths, bins=bins, edgecolor='black')\n",
    "\n",
    "# Step 5: Customize the x-axis labels to be more dense\n",
    "plt.xticks(np.arange(0, max(chunk_lengths) + 50, 50))  # Make x-axis labels denser\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Chunk Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Chunk Lengths by Groups (Outliers Removed)')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_text=[x.content for x in chunks_stas[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MongoDB connection successful!\n",
      "Server information: {'version': '8.0.3', 'gitVersion': '89d97f2744a2b9851ddfb51bdf22f687562d9b06', 'targetMinOS': 'Windows 7/Windows Server 2008 R2', 'modules': [], 'allocator': 'tcmalloc-gperf', 'javascriptEngine': 'mozjs', 'sysInfo': 'deprecated', 'versionArray': [8, 0, 3, 0], 'openssl': {'running': 'Windows SChannel'}, 'buildEnvironment': {'distmod': 'windows', 'distarch': 'x86_64', 'cc': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.31.31107 for x64', 'ccflags': '/nologo /WX /FImongo/platform/basic.h /fp:strict /EHsc /W3 /wd4068 /wd4244 /wd4267 /wd4290 /wd4351 /wd4355 /wd4373 /wd4800 /wd4251 /wd4291 /we4013 /we4099 /we4930 /errorReport:none /MD /O2 /Oy- /bigobj /utf-8 /permissive- /Zc:__cplusplus /Zc:sizedDealloc /volatile:iso /diagnostics:caret /std:c++20 /Gw /Gy /Zc:inline', 'cxx': 'cl: Microsoft (R) C/C++ Optimizing Compiler Version 19.31.31107 for x64', 'cxxflags': '/TP', 'linkflags': '/nologo /DEBUG /INCREMENTAL:NO /LARGEADDRESSAWARE /OPT:REF', 'target_arch': 'x86_64', 'target_os': 'windows', 'cppdefines': 'SAFEINT_USE_INTRINSICS 0 PCRE2_STATIC NDEBUG BOOST_ALL_NO_LIB _UNICODE UNICODE _SILENCE_CXX17_ALLOCATOR_VOID_DEPRECATION_WARNING _SILENCE_CXX17_OLD_ALLOCATOR_MEMBERS_DEPRECATION_WARNING _SILENCE_CXX17_CODECVT_HEADER_DEPRECATION_WARNING _SILENCE_ALL_CXX20_DEPRECATION_WARNINGS _CONSOLE _CRT_SECURE_NO_WARNINGS _ENABLE_EXTENDED_ALIGNED_STORAGE _SCL_SECURE_NO_WARNINGS _WIN32_WINNT 0x0A00 BOOST_USE_WINAPI_VERSION 0x0A00 NTDDI_VERSION 0x0A000000 ABSL_FORCE_ALIGNED_ACCESS BOOST_ENABLE_ASSERT_DEBUG_HANDLER BOOST_FILESYSTEM_NO_CXX20_ATOMIC_REF BOOST_LOG_NO_SHORTHAND_NAMES BOOST_LOG_USE_NATIVE_SYSLOG BOOST_LOG_WITHOUT_THREAD_ATTR BOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS BOOST_SYSTEM_NO_DEPRECATED BOOST_THREAD_USES_DATETIME BOOST_THREAD_VERSION 5'}, 'bits': 64, 'debug': False, 'maxBsonObjectSize': 16777216, 'storageEngines': ['devnull', 'wiredTiger'], 'ok': 1.0}\n",
      "Data inserted successfully!\n",
      "Databases: ['admin', 'cmc_data', 'cmc_data_2', 'cmc_data_3', 'config', 'local']\n",
      "Collections in 'cmc_data': ['resource', 'counters']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Connect to the MongoDB server\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "server_info = client.server_info()  # Will throw an exception if not connected\n",
    "print(\"MongoDB connection successful!\")\n",
    "print(\"Server information:\", server_info)\n",
    "\n",
    "# Access the database and collections\n",
    "db = client['cmc_data_3']\n",
    "collection = db['resource']\n",
    "counter_collection = db['counters']  # Collection to store the counter for auto-increment\n",
    "\n",
    "# Function to get the next auto-incrementing id\n",
    "def get_next_id():\n",
    "    counter_doc = counter_collection.find_one_and_update(\n",
    "        {'_id': 'resource_id'},\n",
    "        {'$inc': {'count': 1}},\n",
    "        upsert=True,\n",
    "        return_document=True\n",
    "    )\n",
    "    return counter_doc['count']\n",
    "\n",
    "# Prepare documents for insertion\n",
    "current_month = datetime.now().strftime('%Y-%m')\n",
    "docs = [{'_id': get_next_id(), 'page_content': x.content, 'date': current_month, 'source': 'Su ky CMC30.pdf'} for x in chunks_stas[0]]\n",
    "\n",
    "# Insert documents into the collection\n",
    "collection.insert_many(docs)\n",
    "print(\"Data inserted successfully!\")\n",
    "\n",
    "# List databases and collections for verification\n",
    "print(\"Databases:\", client.list_database_names())\n",
    "print(\"Collections in 'cmc_data':\", db.list_collection_names())\n",
    "\n",
    "# Close the connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-09', '2024-10', '2024-10', None, '2024-10', '2023-01']\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "# Updated date formats with added format to handle '14 October 2024'\n",
    "date_formats = [\"%d/%m/%Y\", \"Th%m %d, %Y\", \"%d-%m-%Y\", \"%d %B %Y\",\"%Y-%m\"]\n",
    "\n",
    "def parse_date(date_str):\n",
    "    # Skip non-string entries or NaN values\n",
    "    if not isinstance(date_str, str) or date_str == \"\":\n",
    "        return None\n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, fmt)\n",
    "            return date_obj.strftime(\"%Y-%m\")  # Convert to desired format\n",
    "        except ValueError:\n",
    "            continue\n",
    "    raise ValueError(f\"Date format for '{date_str}' not recognized\")\n",
    "\n",
    "dates = [\"09/09/2022\", \"Th10 04, 2024\", \"08-10-2024\", '', '14 October 2024','2023-01']\n",
    "\n",
    "# Example usage in list comprehension with handling for floats\n",
    "formatted_dates = [parse_date(str(date_str)) if not (isinstance(date_str, float) and math.isnan(date_str)) else None for date_str in dates]\n",
    "print(formatted_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def handling_csv(dir,csv_path):\n",
    "    df=pd.read_csv(dir+'/'+csv_path)\n",
    "    print('number of documents:', df.shape[0])\n",
    "    if len(df.columns)>3:\n",
    "        # Combine 'title' and 'date' with 'content'\n",
    "        df['content'] = df['title'] + ' ' + df['date'].astype(str) + '\\n' + df['content']\n",
    "\n",
    "        # Drop 'title' and 'date' columns\n",
    "        df.drop(columns=['title'], inplace=True)    \n",
    "\n",
    "        date=df['date'].to_list()\n",
    "        formatted_date=[parse_date(date_str) for date_str in date]\n",
    "        print('lastest date updated:', formatted_date[0])\n",
    "    elif len(df.columns)==3:\n",
    "        date=df['date'].to_list()\n",
    "        formatted_date=[parse_date(date_str) for date_str in date]\n",
    "        print('lastest date updated:', formatted_date[0])\n",
    "    else:\n",
    "        current_month = datetime.now().strftime('%Y-%m')\n",
    "        formatted_date=[current_month for x in range(df.shape[0])]\n",
    "\n",
    "    # Step 3: Remove rows where 'content' is NaN or missing\n",
    "    df = df.dropna(subset=['content'])\n",
    "    # Step 4: Ensure that all values in 'content' are strings\n",
    "    df['content'] = df['content'].astype(str)\n",
    "    docs=df['content'].to_list()\n",
    "    url_sources=df['url'].to_list()\n",
    "    chunks=statistic_chunking(docs)\n",
    "    statistic_chunking.print(chunks[0])\n",
    "\n",
    "    \n",
    "    chunk_content=[]\n",
    "    for idx,each_doc in enumerate(chunks):\n",
    "        if formatted_date[idx]:\n",
    "            chunk_content.extend([{\n",
    "                'page_content':content.content,\n",
    "                'date':formatted_date[idx],\n",
    "                'url': url_sources[idx]\n",
    "            } for content in each_doc if len(content.content)>10])\n",
    "    print(chunk_content[:10])\n",
    "    client =MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cmc_data_3']\n",
    "\n",
    "    collection = db['resource']\n",
    "    counter_collection = db['counters']  # Collection to store the counter for auto-increment\n",
    "    def get_next_id():\n",
    "        counter_doc = counter_collection.find_one_and_update(\n",
    "            {'_id': 'resource_id'},\n",
    "            {'$inc': {'count': 1}},\n",
    "            upsert=True,\n",
    "            return_document=True\n",
    "        )\n",
    "        return counter_doc['count']\n",
    "    chunk_docs=[{'_id': get_next_id(),'page_content':x['page_content'],'date': x['date'],'source':csv_path, 'url': x['url']} for x in chunk_content]\n",
    "    collection.insert_many(documents=chunk_docs)\n",
    "\n",
    "    client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-08 12:34:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 282\n",
      "lastest date updated: 2024-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-08 12:34:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "\u001b[32m2024-11-08 12:34:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-08 12:34:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "\u001b[32m2024-11-08 12:34:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\u001b[32m2024-11-08 12:34:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-08 12:34:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-08 12:34:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "\u001b[32m2024-11-08 12:34:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "\u001b[32m2024-11-08 12:34:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "\u001b[32m2024-11-08 12:34:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "\u001b[32m2024-11-08 12:34:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-08 12:34:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "\u001b[32m2024-11-08 12:34:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "\u001b[32m2024-11-08 12:34:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "\u001b[32m2024-11-08 12:34:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "\u001b[32m2024-11-08 12:34:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "\u001b[32m2024-11-08 12:34:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "\u001b[32m2024-11-08 12:34:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "\u001b[32m2024-11-08 12:34:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-08 12:34:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n",
      "\u001b[32m2024-11-08 12:34:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "\u001b[32m2024-11-08 12:34:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-08 12:34:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-08 12:34:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.65it/s]\n",
      "\u001b[32m2024-11-08 12:34:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "\u001b[32m2024-11-08 12:34:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "\u001b[32m2024-11-08 12:34:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "\u001b[32m2024-11-08 12:34:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-08 12:34:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "\u001b[32m2024-11-08 12:34:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-08 12:34:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-08 12:34:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-08 12:34:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "\u001b[32m2024-11-08 12:34:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.75it/s]\n",
      "\u001b[32m2024-11-08 12:34:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
      "\u001b[32m2024-11-08 12:34:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n",
      "\u001b[32m2024-11-08 12:34:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "\u001b[32m2024-11-08 12:34:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "\u001b[32m2024-11-08 12:34:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n",
      "\u001b[32m2024-11-08 12:34:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "\u001b[32m2024-11-08 12:34:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "\u001b[32m2024-11-08 12:34:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "\u001b[32m2024-11-08 12:34:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "\u001b[32m2024-11-08 12:34:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "\u001b[32m2024-11-08 12:34:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "\u001b[32m2024-11-08 12:34:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "\u001b[32m2024-11-08 12:34:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "\u001b[32m2024-11-08 12:34:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.17it/s]\n",
      "\u001b[32m2024-11-08 12:34:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.32it/s]\n",
      "\u001b[32m2024-11-08 12:34:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.10it/s]\n",
      "\u001b[32m2024-11-08 12:34:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-08 12:34:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "\u001b[32m2024-11-08 12:34:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "\u001b[32m2024-11-08 12:34:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "\u001b[32m2024-11-08 12:34:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "\u001b[32m2024-11-08 12:34:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "\u001b[32m2024-11-08 12:34:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "\u001b[32m2024-11-08 12:34:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "\u001b[32m2024-11-08 12:34:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "\u001b[32m2024-11-08 12:34:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.26it/s]\n",
      "\u001b[32m2024-11-08 12:34:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "\u001b[32m2024-11-08 12:34:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "\u001b[32m2024-11-08 12:34:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.30it/s]\n",
      "\u001b[32m2024-11-08 12:34:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "\u001b[32m2024-11-08 12:34:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "\u001b[32m2024-11-08 12:34:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\u001b[32m2024-11-08 12:35:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "\u001b[32m2024-11-08 12:35:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "\u001b[32m2024-11-08 12:35:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "\u001b[32m2024-11-08 12:35:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "\u001b[32m2024-11-08 12:35:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n",
      "\u001b[32m2024-11-08 12:35:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-08 12:35:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-08 12:35:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-08 12:35:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "\u001b[32m2024-11-08 12:35:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-08 12:35:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.28it/s]\n",
      "\u001b[32m2024-11-08 12:35:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "\u001b[32m2024-11-08 12:35:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-08 12:35:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-08 12:35:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "\u001b[32m2024-11-08 12:35:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-08 12:35:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "\u001b[32m2024-11-08 12:35:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "\u001b[32m2024-11-08 12:35:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-08 12:35:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "\u001b[32m2024-11-08 12:35:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "\u001b[32m2024-11-08 12:35:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "\u001b[32m2024-11-08 12:35:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\u001b[32m2024-11-08 12:35:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "\u001b[32m2024-11-08 12:35:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.22it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.29it/s]\n",
      "\u001b[32m2024-11-08 12:35:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "\u001b[32m2024-11-08 12:35:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-08 12:35:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n",
      "\u001b[32m2024-11-08 12:35:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-08 12:35:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-08 12:35:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "\u001b[32m2024-11-08 12:35:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "\u001b[32m2024-11-08 12:35:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.51it/s]\n",
      "\u001b[32m2024-11-08 12:35:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n",
      "\u001b[32m2024-11-08 12:35:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "\u001b[32m2024-11-08 12:35:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "\u001b[32m2024-11-08 12:35:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "\u001b[32m2024-11-08 12:35:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "\u001b[32m2024-11-08 12:35:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.09it/s]\n",
      "\u001b[32m2024-11-08 12:35:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "\u001b[32m2024-11-08 12:35:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.90it/s]\n",
      "\u001b[32m2024-11-08 12:35:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.17it/s]\n",
      "\u001b[32m2024-11-08 12:35:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.69it/s]\n",
      "\u001b[32m2024-11-08 12:35:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "\u001b[32m2024-11-08 12:35:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "\u001b[32m2024-11-08 12:35:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "\u001b[32m2024-11-08 12:35:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.00it/s]\n",
      "\u001b[32m2024-11-08 12:35:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "\u001b[32m2024-11-08 12:35:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "\u001b[32m2024-11-08 12:35:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.71it/s]\n",
      "\u001b[32m2024-11-08 12:35:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\u001b[32m2024-11-08 12:35:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.67it/s]\n",
      "\u001b[32m2024-11-08 12:35:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "\u001b[32m2024-11-08 12:35:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.92it/s]\n",
      "\u001b[32m2024-11-08 12:35:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "\u001b[32m2024-11-08 12:35:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "\u001b[32m2024-11-08 12:35:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "\u001b[32m2024-11-08 12:35:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "\u001b[32m2024-11-08 12:35:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.93it/s]\n",
      "\u001b[32m2024-11-08 12:35:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.54it/s]\n",
      "\u001b[32m2024-11-08 12:35:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.57it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.37it/s]\n",
      "\u001b[32m2024-11-08 12:35:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "\u001b[32m2024-11-08 12:35:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-08 12:35:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.37it/s]\n",
      "\u001b[32m2024-11-08 12:35:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.44it/s]\n",
      "\u001b[32m2024-11-08 12:35:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "\u001b[32m2024-11-08 12:35:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "\u001b[32m2024-11-08 12:35:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-08 12:35:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "\u001b[32m2024-11-08 12:35:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\u001b[32m2024-11-08 12:35:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "\u001b[32m2024-11-08 12:35:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-08 12:35:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "\u001b[32m2024-11-08 12:35:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "\u001b[32m2024-11-08 12:35:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "\u001b[32m2024-11-08 12:35:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "\u001b[32m2024-11-08 12:36:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "\u001b[32m2024-11-08 12:36:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "\u001b[32m2024-11-08 12:36:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-08 12:36:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-08 12:36:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-08 12:36:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "\u001b[32m2024-11-08 12:36:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.61s/it]\n",
      "\u001b[32m2024-11-08 12:36:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "\u001b[32m2024-11-08 12:36:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.28it/s]\n",
      "\u001b[32m2024-11-08 12:36:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "\u001b[32m2024-11-08 12:36:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-08 12:36:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "\u001b[32m2024-11-08 12:36:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "\u001b[32m2024-11-08 12:36:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "\u001b[32m2024-11-08 12:36:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "\u001b[32m2024-11-08 12:36:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-08 12:36:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-08 12:36:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "\u001b[32m2024-11-08 12:36:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "\u001b[32m2024-11-08 12:36:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-08 12:36:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-08 12:36:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n",
      "\u001b[32m2024-11-08 12:36:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\u001b[32m2024-11-08 12:36:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-08 12:36:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-08 12:36:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "\u001b[32m2024-11-08 12:36:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\u001b[32m2024-11-08 12:36:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\u001b[32m2024-11-08 12:36:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-08 12:36:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "\u001b[32m2024-11-08 12:36:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\u001b[32m2024-11-08 12:36:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\u001b[32m2024-11-08 12:36:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-08 12:37:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "\u001b[32m2024-11-08 12:37:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\u001b[32m2024-11-08 12:37:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-08 12:37:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\u001b[32m2024-11-08 12:37:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "\u001b[32m2024-11-08 12:37:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\u001b[32m2024-11-08 12:37:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-08 12:37:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-08 12:37:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "\u001b[32m2024-11-08 12:37:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "\u001b[32m2024-11-08 12:37:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "\u001b[32m2024-11-08 12:37:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-08 12:37:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-08 12:37:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "\u001b[32m2024-11-08 12:37:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "\u001b[32m2024-11-08 12:37:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-08 12:37:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "\u001b[32m2024-11-08 12:37:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\u001b[32m2024-11-08 12:37:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "\u001b[32m2024-11-08 12:37:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-08 12:37:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\u001b[32m2024-11-08 12:37:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "\u001b[32m2024-11-08 12:37:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\u001b[32m2024-11-08 12:37:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\u001b[32m2024-11-08 12:37:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "\u001b[32m2024-11-08 12:37:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "\u001b[32m2024-11-08 12:37:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-08 12:37:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "\u001b[32m2024-11-08 12:37:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\u001b[32m2024-11-08 12:37:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-08 12:37:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\u001b[32m2024-11-08 12:38:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.63s/it]\n",
      "\u001b[32m2024-11-08 12:38:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "\u001b[32m2024-11-08 12:38:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-08 12:38:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "\u001b[32m2024-11-08 12:38:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "\u001b[32m2024-11-08 12:38:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "\u001b[32m2024-11-08 12:38:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-08 12:38:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
      "\u001b[32m2024-11-08 12:38:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "\u001b[32m2024-11-08 12:38:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-08 12:38:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "\u001b[32m2024-11-08 12:38:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-08 12:38:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-08 12:38:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "\u001b[32m2024-11-08 12:38:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "\u001b[32m2024-11-08 12:38:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-08 12:38:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "\u001b[32m2024-11-08 12:38:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "\u001b[32m2024-11-08 12:38:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "\u001b[32m2024-11-08 12:38:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "\u001b[32m2024-11-08 12:38:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\u001b[32m2024-11-08 12:38:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "\u001b[32m2024-11-08 12:38:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.39s/it]\n",
      "\u001b[32m2024-11-08 12:38:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "\u001b[32m2024-11-08 12:38:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "\u001b[32m2024-11-08 12:38:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\u001b[32m2024-11-08 12:39:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "\u001b[32m2024-11-08 12:39:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "\u001b[32m2024-11-08 12:39:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "\u001b[32m2024-11-08 12:39:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.54it/s]\n",
      "\u001b[32m2024-11-08 12:39:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-08 12:39:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "\u001b[32m2024-11-08 12:39:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.18s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "\u001b[32m2024-11-08 12:39:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "\u001b[32m2024-11-08 12:39:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "\u001b[32m2024-11-08 12:39:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "\u001b[32m2024-11-08 12:39:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-08 12:39:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "\u001b[32m2024-11-08 12:39:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "\u001b[32m2024-11-08 12:39:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "\u001b[32m2024-11-08 12:39:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-08 12:39:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 100, triggered by: 0.06\n",
      "\u001b[31mHỘI NGHỊ NGHIÊN CỨU KHOA HỌC SINH VIÊN TRƯỜNG ĐẠI HỌC CMC NĂM HỌC 2023 – 2024 VÀ TRIỂN LÃM CÔNG TRÌNH NGHIÊN CỨU KHOA HỌC SINH VIÊN\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 86, triggered by: token limit\n",
      "\u001b[32m------------- Ngày 25 tháng 10 vừa qua, Trường Đại học CMC long trọng tổ chức “Hội nghị Nghiên cứu Khoa học sinh viên” năm học 2023 – 2024 và triển lãm các công trình nghiên cứu khoa học sinh viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 200, triggered by: token limit\n",
      "\u001b[34mHội nghị được tổ chức nhằm tuyên dương và ghi nhận những nỗ lực nghiên cứu của các nhóm nghiên cứu khoa học (NCKH) trong năm học 2023 – 2024; phát động và triển khai hoạt động sinh viên NCKH trong toàn trường; hình thành khả năng NCKH độc lập, năng lực tự học, tính năng động và tư duy đổi mới sáng tạo của sinh viên Trường Đại học CMC. Tại Hội nghị, 25 nhóm sinh viên báo cáo và bảo vệ công trình NCKH trước các Hội đồng phản biện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 152, triggered by: 0.05\n",
      "\u001b[35mMỗi nhóm được thuyết trình đề tài NCKH của mình và nhận những lời nhận xét, góp ý bổ sung từ Hội đồng. Nhìn chung, đề tài NCKH của sinh viên Trường Đại học CMC đều được Hội đồng đánh giá cao về tính sáng tạo, tính cấp thiết và tính ứng dụng trong thực tiễn cũng như sự nỗ lực của các em trong quá trình thực hiện NCKH.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 50, triggered by: 0.33\n",
      "\u001b[31m️ Theo đó, kết quả chung cuộc đối với các đề tài NCKH sinh viên năm học 2023 – 2024 được tổng kết như sau:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 60, triggered by: 0.26\n",
      "\u001b[32m– Giải Nhất thuộc về các đề tài: + Đề tài “Hình ảnh “hải nữ”ở đảo Jeju (qua bộ phim Chào mừng đến Samdal-ri)”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 67, triggered by: 0.11\n",
      "\u001b[34mNhóm sinh viên Khoa Ngôn ngữ thực hiện: Nguyễn Thị Hồng Linh, Đỗ Hà Vy, Phùng Thị Bích Hạnh, Nguyễn Tú Anh; Giảng viên hướng dẫn:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 119, triggered by: 0.20\n",
      "\u001b[35mTS. Hoàng Thị Yến . + Đề tài “Phương pháp phát hiện xâm nhập trên thiết bị chuyển giao dữ liệu trong IoT công nghiệp”. Nhóm sinh viên Khoa Công nghệ Thông tin và Truyền thông thực hiện: Nguyễn Bình Nam, Nguyễn Trung Du, Hoàng Minh Hải; Giảng viên hướng dẫn: TS. Đặng Minh Tuấn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 127, triggered by: 0.24\n",
      "\u001b[31m– Giải Nhì thuộc về các đề tài: + Đề tài “Các yếu tố ảnh hưởng đến ý định sử dụng dịch vụ Xanh SM Bike của giới trẻ tại Hà Nội”. Nhóm sinh viên Khoa Kinh doanh và Quản lý thực hiện: Nguyễn Thanh Nam, Lê Ngọc Linh, Đào Thị Ngoan; Giảng viên hướng dẫn:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 116, triggered by: 0.09\n",
      "\u001b[32mThS. Trương Thùy Trang. + Đề tài “Web AI dự đoán giá cổ phiếu sử dụng mô hình chuỗi thời gian”. Nhóm sinh viên Khoa Công nghệ Thông tin và Truyền thông thực hiện: Ngô Đức Thuận, Hoàng Minh Hải; Giảng viên hướng dẫn: TS. Ngô Hoàng Huy, TS. Phạm Thị Kim Dung.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 51, triggered by: 0.37\n",
      "\u001b[34m– Giải Ba thuộc về các đề tài: + Đề tài “Báo cáo nghiên cứu thiết kế poster chuyển động quảng cáo Coca-cola”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 83, triggered by: 0.27\n",
      "\u001b[35mSinh viên Khoa Mỹ thuật và Thiết kế thực hiện: Đỗ Nam Phong; Giảng viên hướng dẫn: ThS. Nguyễn Minh Kiên. + Đề tài “Xây dựng mô hình phân loại giọng nói theo vùng miền”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 100, triggered by: 0.12\n",
      "\u001b[31mNhóm sinh viên Khoa Công nghệ Thông tin và Truyền thông thực hiện: Nguyễn Tiến Luyện, Phan Thị Phương Linh, Hoàng Minh Hải; Giảng viên hướng dẫn: TS. Phạm Thị Anh Lê, Ths. Nguyễn Tiến Đồng, Ths. Phạm Đăng Nguyên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 73, triggered by: 0.15\n",
      "\u001b[32m– Giải Ấn tượng thuộc về các đề tài: + Đề tài “Tác động của video có thời lượng ngắn tới hành vi mua hàng của người tiêu dùng trẻ tại Thành phố Hà Nội”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 53, triggered by: 0.14\n",
      "\u001b[34mNhóm sinh viên Khoa Kinh doanh và Quản lý thực hiện: Vũ Hải Nam, Phan Ngọc Ánh, Ngô Tiến Công; Giảng viên hướng dẫn:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 133, triggered by: 0.20\n",
      "\u001b[35mTS. Nguyễn Thị Phi Nga. + Đề tài “Hệ thống điểm danh tự động bằng nhận dạng khuôn mặt”. Nhóm sinh viên Khoa Công nghệ Thông tin và Truyền thông thực hiện: Nguyễn Thu Phương, Lại Hoàng Duy, Nguyễn Tấn Phát, Nguyễn Đình Quang Vinh; Giảng viên hướng dẫn: TS. Vũ Văn Trường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 17, tokens 118, triggered by: 0.37\n",
      "\u001b[31mCác đề tài đạt giải đã góp phần tạo ra các công trình nghiên cứu đầy tính ứng dụng cao nhằm giải quyết một số vấn đề của khoa học và thực tiễn, qua đó khẳng định năng lực nghiên cứu, sự tiến bộ, trưởng thành của sinh viên Trường Đại học CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 18, tokens 12, triggered by: final split\n",
      "\u001b[32m#CMC #NgườiCMC #CMCUni\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'HỘI NGHỊ NGHIÊN CỨU KHOA HỌC SINH VIÊN TRƯỜNG ĐẠI HỌC CMC NĂM HỌC 2023 – 2024 VÀ TRIỂN LÃM CÔNG TRÌNH NGHIÊN CỨU KHOA HỌC SINH VIÊN', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': '------------- Ngày 25 tháng 10 vừa qua, Trường Đại học CMC long trọng tổ chức “Hội nghị Nghiên cứu Khoa học sinh viên” năm học 2023 – 2024 và triển lãm các công trình nghiên cứu khoa học sinh viên.', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': 'Hội nghị được tổ chức nhằm tuyên dương và ghi nhận những nỗ lực nghiên cứu của các nhóm nghiên cứu khoa học (NCKH) trong năm học 2023 – 2024; phát động và triển khai hoạt động sinh viên NCKH trong toàn trường; hình thành khả năng NCKH độc lập, năng lực tự học, tính năng động và tư duy đổi mới sáng tạo của sinh viên Trường Đại học CMC. Tại Hội nghị, 25 nhóm sinh viên báo cáo và bảo vệ công trình NCKH trước các Hội đồng phản biện.', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': 'Mỗi nhóm được thuyết trình đề tài NCKH của mình và nhận những lời nhận xét, góp ý bổ sung từ Hội đồng. Nhìn chung, đề tài NCKH của sinh viên Trường Đại học CMC đều được Hội đồng đánh giá cao về tính sáng tạo, tính cấp thiết và tính ứng dụng trong thực tiễn cũng như sự nỗ lực của các em trong quá trình thực hiện NCKH.', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': '️ Theo đó, kết quả chung cuộc đối với các đề tài NCKH sinh viên năm học 2023 – 2024 được tổng kết như sau:', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': '– Giải Nhất thuộc về các đề tài: + Đề tài “Hình ảnh “hải nữ”ở đảo Jeju (qua bộ phim Chào mừng đến Samdal-ri)”.', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': 'Nhóm sinh viên Khoa Ngôn ngữ thực hiện: Nguyễn Thị Hồng Linh, Đỗ Hà Vy, Phùng Thị Bích Hạnh, Nguyễn Tú Anh; Giảng viên hướng dẫn:', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': 'TS. Hoàng Thị Yến . + Đề tài “Phương pháp phát hiện xâm nhập trên thiết bị chuyển giao dữ liệu trong IoT công nghiệp”. Nhóm sinh viên Khoa Công nghệ Thông tin và Truyền thông thực hiện: Nguyễn Bình Nam, Nguyễn Trung Du, Hoàng Minh Hải; Giảng viên hướng dẫn: TS. Đặng Minh Tuấn.', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': '– Giải Nhì thuộc về các đề tài: + Đề tài “Các yếu tố ảnh hưởng đến ý định sử dụng dịch vụ Xanh SM Bike của giới trẻ tại Hà Nội”. Nhóm sinh viên Khoa Kinh doanh và Quản lý thực hiện: Nguyễn Thanh Nam, Lê Ngọc Linh, Đào Thị Ngoan; Giảng viên hướng dẫn:', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}, {'page_content': 'ThS. Trương Thùy Trang. + Đề tài “Web AI dự đoán giá cổ phiếu sử dụng mô hình chuỗi thời gian”. Nhóm sinh viên Khoa Công nghệ Thông tin và Truyền thông thực hiện: Ngô Đức Thuận, Hoàng Minh Hải; Giảng viên hướng dẫn: TS. Ngô Hoàng Huy, TS. Phạm Thị Kim Dung.', 'date': '2024-10', 'url': 'https://www.facebook.com/share/p/Sg1AdmHrL467rbRd/'}]\n"
     ]
    }
   ],
   "source": [
    "handling_csv('data_for_chunks','combined_posts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def handling_csv_2(dir,csv_path,url):\n",
    "    df=pd.read_csv(dir+'/'+csv_path)\n",
    "    print('number of documents:', df.shape[0])\n",
    "    if len(df.columns)>2:\n",
    "        # Combine 'title' and 'date' with 'content'\n",
    "        df['content'] = df['title'] + ' ' + df['date'].astype(str) + '\\n' + df['content']\n",
    "\n",
    "        # Drop 'title' and 'date' columns\n",
    "        df.drop(columns=['title'], inplace=True)    \n",
    "\n",
    "        date=df['date'].to_list()\n",
    "        formatted_date=[parse_date(date_str) for date_str in date]\n",
    "        print('lastest date updated:', formatted_date[0])\n",
    "    else:\n",
    "        current_month = datetime.now().strftime('%Y-%m')\n",
    "        formatted_date=[current_month for x in range(df.shape[0])]\n",
    "    # Step 3: Remove rows where 'content' is NaN or missing\n",
    "    df = df.dropna(subset=['content'])\n",
    "    # Step 4: Ensure that all values in 'content' are strings\n",
    "    df['content'] = df['content'].astype(str)\n",
    "    docs=df['content'].to_list()\n",
    "    chunks=statistic_chunking(docs)\n",
    "    statistic_chunking.print(chunks[0])\n",
    "\n",
    "    \n",
    "    chunk_content=[]\n",
    "    for idx,each_doc in enumerate(chunks):\n",
    "        if formatted_date[idx]:\n",
    "            chunk_content.extend([{\n",
    "                'page_content':content.content,\n",
    "                'date':formatted_date[idx]\n",
    "            } for content in each_doc if len(content.content)>10])\n",
    "    print(chunk_content[:10])\n",
    "    client =MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cmc_data_3']\n",
    "\n",
    "    collection = db['resource']\n",
    "    counter_collection = db['counters']  # Collection to store the counter for auto-increment\n",
    "    def get_next_id():\n",
    "        counter_doc = counter_collection.find_one_and_update(\n",
    "            {'_id': 'resource_id'},\n",
    "            {'$inc': {'count': 1}},\n",
    "            upsert=True,\n",
    "            return_document=True\n",
    "        )\n",
    "        return counter_doc['count']\n",
    "    chunk_docs=[{'_id': get_next_id(),'page_content':x['page_content'],'date': x['date'],'source':csv_path, 'url': url} for x in chunk_content]\n",
    "    collection.insert_many(documents=chunk_docs)\n",
    "\n",
    "    client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-08 00:48:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.23s/it]\n",
      "\u001b[32m2024-11-08 00:48:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.43s/it]\n",
      "\u001b[32m2024-11-08 00:48:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 116, triggered by: 0.23\n",
      "\u001b[31mVề CMC Tập đoàn Công nghệ CMC là tập đoàn số toàn cầu, đẳng cấp quốc tế. Thành lập từ năm 1993, CMC đã khẳng định vị thế trên thị trường Việt Nam và nhiều nước trên thế giới thông qua những hoạt động kinh doanh chủ lực ở 4 khối:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 165, triggered by: 0.27\n",
      "\u001b[32mKhối Hạ tầng số, Khối Công nghệ & Giải pháp, Khối Kinh doanh Quốc tế, Khối Nghiên cứu và Giáo dục 1,900,269,960,000 VND Vốn điều lệ   190.026.996 Số cổ phần 5.000+ Cán bộ, nhân viên 31năm thành lập và phát triển Ở Việt Nam, Tập đoàn CMC được biết đến như một đối tác tin cậy và uy tín trong các dự án ICT cấp trung và lớn trong các lĩnh vực:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 55, triggered by: 0.23\n",
      "\u001b[34mChính phủ, Giáo dục, Thuế, Kho bạc, Hải quan, Bảo hiểm, Điện lực, Ngân hàng, Tài chính và các Doanh nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 62, triggered by: 0.33\n",
      "\u001b[35mTầm nhìn và Sứ mệnh Với khát khao và đam mê, CMC phấn đấu trở thành Tập đoàn Công nghệ Thông tin và Viễn thông hàng đầu thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 121, triggered by: 0.36\n",
      "\u001b[31mDẫn đầu các làn sóng công nghệ mới, nỗ lực phát triển những sản phẩm - dịch vụ - giải pháp công nghệ đẳng cấp thế giới, mang lại những giá trị vượt trội cho khách hàng, góp phần nâng cao vị thế Việt Nam trong kỷ nguyên số, xây dựng đất nước hùng cường.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 166, triggered by: 0.24\n",
      "\u001b[32mGiá trị cốt lõi: 4C (Creativity, C-Speed, Commitment, Customer Centricity). Mọi hành động của người CMC đều xuất phát từ trái tim Hướng Khách Hàng. Bằng khát khao và đam mê Sáng Tạo không ngừng nghỉ, người CMC quyết tâm vươn tới tốc độ nhanh nhất, Tốc Độ Ánh Sáng, trong cả tư duy và hành động để truyền cảm hứng và thực hiện tốt những Cam Kết của mình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 70, triggered by: 0.27\n",
      "\u001b[34mĐịnh hướng chiến lược 2021 - 2025:01 Trở thành Tập đoàn Số toàn cầu, đẳng cấp quốc tế. Tập trung phát triển kinh doanh ở 3 lĩnh vực:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 51, triggered by: 0.34\n",
      "\u001b[35mGiải pháp Công nghệ, Kinh doanh Quốc tế và Dịch vụ Viễn thông. Định hướng chiến lược 2021 - 2025:02\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 162, triggered by: token limit\n",
      "\u001b[31mXây dựng năng lực chuyên sâu về giải pháp chuyên ngành và các công nghệ lõi, xây dựng Hệ sinh thái hạ tầng mở cho doanh nghiệp và tổ chức (C.OPE2N), cung cấp đa dịch vụ cho khách hàng, là nền tảng kết nối với các hãng giải pháp công nghệ hàng đầu trên thế giới. Định hướng chiến lược 2021 - 2025:03 Tập trung vào các thị trường chiến lược:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 60, triggered by: 0.42\n",
      "\u001b[32mTài chính ngân hàng, doanh nghiệp, chính phủ và mở rộng phát triển thị trường quốc tế. Định hướng chiến lược 2021 - 2025:04\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 102, triggered by: 0.27\n",
      "\u001b[34mMục tiêu đạt quy mô 1 tỷ USD và 10.000 nhân sự vào năm 2025, trong đó doanh thu khối Giải pháp Công nghệ là 10.000 tỷ VNĐ, khối Dịch vụ Viên thông là 10.000 tỷ VNĐ và khối Kinh doanh Quốc tế là 5.000 tỷ VNĐ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 50, triggered by: 0.31\n",
      "\u001b[35mÔng Nguyễn Trung Chính,Chủ tịch HĐQT/Chủ tịch Điều hành Tập đoàn,- Trình độ chuyên môn:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 179, triggered by: 0.33\n",
      "\u001b[31mKỹ sư Điện tử viễn thông,- Tốt nghiệp Trường Đại học Bách khoa, khoa Kỹ thuật điện tử (1987),- Là trụ cột quan trọng nhất trong việc đưa CMC từ một - Công ty tin học 20 thành viên ban đầu trở thành Tập đoàn CMC hiện nay.,- Là người nhiệt huyết và quyết liệt trong điều hành và quản trị công ty.,- Khả năng nắm bắt, nhận định thị trường rất nhạy bén và đưa ra các chỉ đạo sáng suốt.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 50, triggered by: 0.46\n",
      "\u001b[32mÔng Kim Jung Wuk,Thành viên HĐQT,- 1/1995: Tham gia công tác tại Công ty Daewoo Corporation (Xây dựng),- 2/2004:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 170, triggered by: 0.22\n",
      "\u001b[34mTham gia công tác tại Công ty Samsung SDS,- 12/2015: Trưởng Bộ phận Kinh doanh Giải pháp Logistics & Chuỗi cung cấp,- 12/2016: Trưởng Nhóm Tư vấn SCM (Quản lý Chuỗi cung cấp),- 3/2020: Chủ tịch kiêm Giám đốc điều hành Công ty Samsung ASIA PACIFIC,- 7/2020: Thành viên Hội đồng quản trị tại Công ty Cổ phần Tập đoàn Công nghệ CMC Ông Gum Ki Ho,Thành viên HĐQT,- 2/1992:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 121, triggered by: 0.27\n",
      "\u001b[35mGia nhập Samsung SDS,- 2003 – 2013: Network Infra Team Leader – Công ty Samsung SDS,- 2014: Cloud Infra Team Leader (Vice President) – Công ty Samsung SDS,- 2015 – 2020: Cloud Service Manger – Công ty Samsung SDS,- 2021: External AM Team Leader (Senior Vice President) – Công ty Samsung SDS,- 2022: External AM Manager (Executive Vice President) – Công ty Samsung SDS,- 12/2022 đến nay: SDSV/ SDSAP CEO\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 17, tokens 58, triggered by: 0.35\n",
      "\u001b[31mÔng Lê Việt Hà,Thành viên HĐQT,- 2001 – 2004: Contacts International Hospitality Group - Trợ lý Giám đốc Điều hành,- 07/2004- 12/2005:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 18, tokens 196, triggered by: token limit\n",
      "\u001b[32mTrung tâm đầu tư Báo Việt - Kinh tế viên thẩm định đầu tư,- 01/2006-03/2007: Công ty TNHH Quản lý Quỹ đầu tư chứng khoán Bảo Việt - Phụ trách phân tích đầu tư chứng khoán,- 04/2007 - 07/2007: Công ty CP Chứng khoán Sài Gòn (SSI) - Trợ lý dự án thành lập Công ty Quản lý Quỹ SSI,- 08/2007-05/2011: Công ty TNHH Quản lý Quỹ SSI (SSIAM) - Giám đốc Đầu tư cổ phiếu,- 05/2011 - 12/2011:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 19, tokens 147, triggered by: 0.37\n",
      "\u001b[34mCông ty CP Xuất nhập khẩu Tồng hợp Hà Nội - Phó Ban Kế hoạch Đầu tư,- 01/2012-01/2016: Công ty CP Quản lý Quỹ đầu tư chứng khoán An Bình - Phó Tổng Giám đốc,- 01/2016-Nay: Công tỵ CP Quản lý Quỹ đầu tư chứng khoán An Bình - Tổng Giám đốc Ông Hà Thế Vinh,Thành viên HĐQT,- 07/2017-10/2018:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 20, tokens 188, triggered by: token limit\n",
      "\u001b[35mKĩ sư phần mềm tại Amazon Web Services (Seattle, Washington, USA),- 01/2019-11/2020: Chuyên viên phân tích dữ liệu tại Time DotCom Berhad (Shah A lam, Selangor, Malaysia),- 6/2019 – Nay: Thành viên Hội đồng quản trị tại Công ty Cổ phần Tập đoàn Công nghệ CMC,- 11/2020 – Nay: Thành viên ban Công Nghệ và Chuyển đổi số tại Công ty Cổ phần Tập đoàn Công nghệ CMC,- 11/2020 - 04/2022: Trợ lý Chủ tịch ,- 05/2022 - 06/2023:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 21, tokens 65, triggered by: 0.33\n",
      "\u001b[31mGiám đốc Sản phẩm Công ty CMC Cyber Security ,- 07/2023 - Nay: Giám đốc Vận hành Công ty CMC Cyber Security Ông Nguyễn Danh Lam,Thành viên HĐQT,- 1983-1986:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 22, tokens 100, triggered by: 0.42\n",
      "\u001b[32mCông tác tại Liên Đoàn Vật lý địa chất, Tổng cục địa chất,- 1986-1993: Công tác tại Viện Năng lượng- Bộ năng lượng,- 1993-1995: Công tác tại Viện công nghệ Vi điện tử-Viện Công nghệ,- 1995 đến nay:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 23, tokens 55, triggered by: 0.37\n",
      "\u001b[34mGiám đốc công ty Lam Phương,- 26/6/2017 đến nay: Thành viên Hội đồng quản trị Công ty Cổ phần Tập đoàn Công nghệ CMC\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 24, tokens 55, triggered by: 0.42\n",
      "\u001b[35mÔng Nguyễn Minh Đức,Thành viên HĐQT,- 1983: Tốt nghiệp Đại học Bách khoa Hà Nội,- 3/1984 – 7/1985:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 25, tokens 142, triggered by: 0.38\n",
      "\u001b[31mKỹ sư – Viện Kinh tế Kỹ thuật Dệt may, phụ trách về nghiên cứu phát triển và kế hoạch đầu tư,- 8/1985 – 4/1987: Đi nghĩa vụ quân sự, Đơn vị D16, Sư đoàn 392, Quân khu I,- 5/1987 – 7/1996: Kỹ sư – Viện Kinh tế Kỹ thuật Dệt may,- 8/1996 – 12/1999:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 26, tokens 81, triggered by: 0.38\n",
      "\u001b[32mCông ty Dịch vụ XNK Thương mại Hà Nội,- 1/2000 – 6/2001: Phụ trách chương trình phát triển khu vực kinh tế tư nhân – Đại sứ quán Đan Mạch,- 7/2001 – 12/2005:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 27, tokens 71, triggered by: 0.43\n",
      "\u001b[34mTrưởng đại diện – Văn phòng Đại diện Diethelm Technology tại Hà Nội,- 1/2006 – nay: Giám đốc Công ty TNHH Thương mại và Dịch vụ DTSC,- 5/2007 – nay:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 28, tokens 50, triggered by: 0.38\n",
      "\u001b[35mThành viên HĐQT Công ty CP Tập đoàn Công nghệ CMC Ông Nguyễn Phước Hải,Thành viên HĐQT,- 1992- 1995:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 29, tokens 188, triggered by: token limit\n",
      "\u001b[31mCán bộ kinh doanh tại Công ty TNHH Leasa, Ucraina,- 1996- 1997: Cán bộ kinh doanh tại Công ty TNHH Máy tính Truyền thông CMC,- 1998- 4/1999: Trưởng phòng kinh doanh tại Công ty TNHH Máy tính Truyền thông CMC,- 5/1999 - 1/2007: Giám đốc Công ty TNHH Sàn xuất và dịch vụ Máy tính Thể Trung (nay là CMS),- 2/2007 – nay: Tổng Giám đốc Công ly TNHH Máy tính CMS (nay là CMS),- 2/2007 - nay:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 30, tokens 130, triggered by: 0.44\n",
      "\u001b[32mThành viên Hội đồng quản trị Công ty Cổ phần Tập đoàn Công nghệ CMC,- 4/2007 - 8/2020: Phó Tổng Giám đốc Công ty Cổ phần Tập đoàn Công nghệ CMC,- 8/2020 – nay: Phó Chủ tịch Cấp cao Tập đoàn/ Giám đổc Quản trị Công ty Cổ phần Tập đoàn Công nghệ CMC\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 31, tokens 192, triggered by: token limit\n",
      "\u001b[34mÔng Trương Tuấn Lâm,Thành viên HĐQT,- 1995: Kỹ sư CNTT tại Tổng Công ty Bảo hiểm Việt Nam,- 1998: Phụ trách phòng Tin học Phi Nhân thọ tại Tổng Công ty Bảo hiểm Việt Nam,- 2001: Trưởng phòng Quản lý hệ thống - Trung Tâm thông tin Bào Việt - Tổng Công ty Bảo hiểm Việt Nam,- 2005: Phó giám đốc Trung tâm thông tin - Bảo Việt Nhân thọ,- 2007: Phó ban Công nghệ Tin học - Tập đoàn Bảo Việt,- 2008:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 32, tokens 171, triggered by: final split\n",
      "\u001b[35mTrưởng Ban Vận hành và Quản trị Hệ thống CNTT - Tập đoàn Bảo Việt,- 2011: Phó Giám Đốc CNTT - Tập đoàn Bào Việt,- 2015: Phó Giám đốc Chi nhánh Trung Tâm CNTT Tập đoàn Bảo Việt,- 2016 đến nay: Thành viên Hội đồng quản trị tại Công ty Cổ phần Tập đoàn Công nghệ CMC,- 2021 đến này: Giám đốc Chi nhành Trung tâm CNTT Tập đoàn Bảo Việt\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'Về CMC Tập đoàn Công nghệ CMC là tập đoàn số toàn cầu, đẳng cấp quốc tế. Thành lập từ năm 1993, CMC đã khẳng định vị thế trên thị trường Việt Nam và nhiều nước trên thế giới thông qua những hoạt động kinh doanh chủ lực ở 4 khối:', 'date': '2024-11'}, {'page_content': 'Khối Hạ tầng số, Khối Công nghệ & Giải pháp, Khối Kinh doanh Quốc tế, Khối Nghiên cứu và Giáo dục 1,900,269,960,000 VND Vốn điều lệ   190.026.996 Số cổ phần 5.000+ Cán bộ, nhân viên 31năm thành lập và phát triển Ở Việt Nam, Tập đoàn CMC được biết đến như một đối tác tin cậy và uy tín trong các dự án ICT cấp trung và lớn trong các lĩnh vực:', 'date': '2024-11'}, {'page_content': 'Chính phủ, Giáo dục, Thuế, Kho bạc, Hải quan, Bảo hiểm, Điện lực, Ngân hàng, Tài chính và các Doanh nghiệp.', 'date': '2024-11'}, {'page_content': 'Tầm nhìn và Sứ mệnh Với khát khao và đam mê, CMC phấn đấu trở thành Tập đoàn Công nghệ Thông tin và Viễn thông hàng đầu thế giới.', 'date': '2024-11'}, {'page_content': 'Dẫn đầu các làn sóng công nghệ mới, nỗ lực phát triển những sản phẩm - dịch vụ - giải pháp công nghệ đẳng cấp thế giới, mang lại những giá trị vượt trội cho khách hàng, góp phần nâng cao vị thế Việt Nam trong kỷ nguyên số, xây dựng đất nước hùng cường.', 'date': '2024-11'}, {'page_content': 'Giá trị cốt lõi: 4C (Creativity, C-Speed, Commitment, Customer Centricity). Mọi hành động của người CMC đều xuất phát từ trái tim Hướng Khách Hàng. Bằng khát khao và đam mê Sáng Tạo không ngừng nghỉ, người CMC quyết tâm vươn tới tốc độ nhanh nhất, Tốc Độ Ánh Sáng, trong cả tư duy và hành động để truyền cảm hứng và thực hiện tốt những Cam Kết của mình.', 'date': '2024-11'}, {'page_content': 'Định hướng chiến lược 2021 - 2025:01 Trở thành Tập đoàn Số toàn cầu, đẳng cấp quốc tế. Tập trung phát triển kinh doanh ở 3 lĩnh vực:', 'date': '2024-11'}, {'page_content': 'Giải pháp Công nghệ, Kinh doanh Quốc tế và Dịch vụ Viễn thông. Định hướng chiến lược 2021 - 2025:02', 'date': '2024-11'}, {'page_content': 'Xây dựng năng lực chuyên sâu về giải pháp chuyên ngành và các công nghệ lõi, xây dựng Hệ sinh thái hạ tầng mở cho doanh nghiệp và tổ chức (C.OPE2N), cung cấp đa dịch vụ cho khách hàng, là nền tảng kết nối với các hãng giải pháp công nghệ hàng đầu trên thế giới. Định hướng chiến lược 2021 - 2025:03 Tập trung vào các thị trường chiến lược:', 'date': '2024-11'}, {'page_content': 'Tài chính ngân hàng, doanh nghiệp, chính phủ và mở rộng phát triển thị trường quốc tế. Định hướng chiến lược 2021 - 2025:04', 'date': '2024-11'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "handling_csv_2('data_for_chunks','about.csv','https://www.cmc.com.vn/introduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-08 00:52:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-08 00:52:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-08 00:52:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "\u001b[32m2024-11-08 00:52:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "\u001b[32m2024-11-08 00:52:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "\u001b[32m2024-11-08 00:52:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 196, triggered by: token limit\n",
      "\u001b[31mTổng Công ty Công nghệ & Giải pháp CMC (CMC TS) Giải pháp công nghệ - Dẫn đầu thành công Với đội ngũ 1000 nhân sự toàn quốc, Tổng Công ty Công nghệ & Giải pháp CMC (CMC TS) là TOP 1 Doanh nghiệp tư vấn, triển khai các giải pháp Chuyển đổi số và Bảo mật cho tổ chức, doanh nghiệp tại Việt Nam. CMC TS đặt mục tiêu vào năm 2025 đạt mốc doanh thu 10 nghìn tỷ đồng và quy mô nhân sự 3000 người.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 98, triggered by: 0.20\n",
      "\u001b[32mCông ty tập trung vào các 7 mảng giải pháp (7 big moves) gồm: Chuyển đổi số và Trải nghiệm khách hàng, Điện toán đám mây, Bảo mật, Giải pháp Made by CMC, Dịch vụ Dữ liệu, Smart Industries, Hiện đại hoá hạ tầng di sản.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 80, triggered by: 0.30\n",
      "\u001b[34m.Hạ tầng thông minh. Tư vấn, thiết kế và triển khai hệ thống CNTT. Hạ tầng CNTT, Thiết bị, IoT. Máy chủ truyền thống. Máy chủ UNIX. Hạ tầng siêu hội tụ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 91, triggered by: 0.24\n",
      "\u001b[35mLicenses.Chuyển đổi số. Tư vấn và triển khai giải pháp chuyển đổi số tổng thể. Hiện đại hóa hệ thống legacy. Cloud Transformation. Customer360. Ứng dụng chuyển đổi số (CMIS, C-Invoice, CA, HRM, CRM, ERP, C-Contract, EPM.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 181, triggered by: token limit\n",
      "\u001b[31m. .). Phân tích dữ liệu & AI.Dịch vụ CNTT. Thuê ngoài dịch vụ CNTT: Bảo hành, bảo trì hạ tầng CNTT; Dịch vụ hạ tầng Trung tâm dữ liệu; Dịch vụ hệ thống. Giải pháp dịch vụ hạ tầng Hybrid và Private Cloud. Dịch vụ mạng và dịch vụ an ninh an toàn thông tin. Dịch vụ sao lưu, lưu trữ. Giải pháp và dịch vụ, phần mềm quản trị doanh nghiệp toàn diện.Giải pháp ngành\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 191, triggered by: 0.32\n",
      "\u001b[32mTài chính Ngân hàng, Bảo hiểm, Chứng khoán, Hành chính công, Viễn thông, Sản xuất,  Năng lượng, Du lịch, Bán lẻ, Thương mại điện tử, Y tế, Giáo dục, Vận tải - Hàng không. . . .An ninh an toàn thông tin. Dịch vụ tư vấn bảo mật: Kiến trúc bảo mật, Đánh giá tuân thủ PCI DSS/ISO, Đánh giá rủi ro bảo mật. . . . Dịch vụ bảo mật và Dịch vụ ủy quyền giám sát an ninh mạng CMC SOC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 43, triggered by: final split\n",
      "\u001b[34mBảo mật hệ thống CNTT: IoT, Thiết bị đầu cuối, Bảo mật nền tảng đám mây. . .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'Tổng Công ty Công nghệ & Giải pháp CMC (CMC TS) Giải pháp công nghệ - Dẫn đầu thành công Với đội ngũ 1000 nhân sự toàn quốc, Tổng Công ty Công nghệ & Giải pháp CMC (CMC TS) là TOP 1 Doanh nghiệp tư vấn, triển khai các giải pháp Chuyển đổi số và Bảo mật cho tổ chức, doanh nghiệp tại Việt Nam. CMC TS đặt mục tiêu vào năm 2025 đạt mốc doanh thu 10 nghìn tỷ đồng và quy mô nhân sự 3000 người.', 'date': '2024-11'}, {'page_content': 'Công ty tập trung vào các 7 mảng giải pháp (7 big moves) gồm: Chuyển đổi số và Trải nghiệm khách hàng, Điện toán đám mây, Bảo mật, Giải pháp Made by CMC, Dịch vụ Dữ liệu, Smart Industries, Hiện đại hoá hạ tầng di sản.', 'date': '2024-11'}, {'page_content': '.Hạ tầng thông minh. Tư vấn, thiết kế và triển khai hệ thống CNTT. Hạ tầng CNTT, Thiết bị, IoT. Máy chủ truyền thống. Máy chủ UNIX. Hạ tầng siêu hội tụ.', 'date': '2024-11'}, {'page_content': 'Licenses.Chuyển đổi số. Tư vấn và triển khai giải pháp chuyển đổi số tổng thể. Hiện đại hóa hệ thống legacy. Cloud Transformation. Customer360. Ứng dụng chuyển đổi số (CMIS, C-Invoice, CA, HRM, CRM, ERP, C-Contract, EPM.', 'date': '2024-11'}, {'page_content': '. .). Phân tích dữ liệu & AI.Dịch vụ CNTT. Thuê ngoài dịch vụ CNTT: Bảo hành, bảo trì hạ tầng CNTT; Dịch vụ hạ tầng Trung tâm dữ liệu; Dịch vụ hệ thống. Giải pháp dịch vụ hạ tầng Hybrid và Private Cloud. Dịch vụ mạng và dịch vụ an ninh an toàn thông tin. Dịch vụ sao lưu, lưu trữ. Giải pháp và dịch vụ, phần mềm quản trị doanh nghiệp toàn diện.Giải pháp ngành', 'date': '2024-11'}, {'page_content': 'Tài chính Ngân hàng, Bảo hiểm, Chứng khoán, Hành chính công, Viễn thông, Sản xuất,  Năng lượng, Du lịch, Bán lẻ, Thương mại điện tử, Y tế, Giáo dục, Vận tải - Hàng không. . . .An ninh an toàn thông tin. Dịch vụ tư vấn bảo mật: Kiến trúc bảo mật, Đánh giá tuân thủ PCI DSS/ISO, Đánh giá rủi ro bảo mật. . . . Dịch vụ bảo mật và Dịch vụ ủy quyền giám sát an ninh mạng CMC SOC.', 'date': '2024-11'}, {'page_content': 'Bảo mật hệ thống CNTT: IoT, Thiết bị đầu cuối, Bảo mật nền tảng đám mây. . .', 'date': '2024-11'}, {'page_content': 'Công ty TNHH CMC Consulting (CMC Consulting) Tư vấn và Triển khai SAP ERP Quản trị doanh nghiệp hiệu quả CMC Consulting tiền thân là Công ty Cổ phần Liên doanh Ciber-CMC, được thành lập từ năm 2008 dựa trên sự hợp tác giữa Tập đoàn Công nghệ CMC (Việt Nam) và Ciber (Hoa Kỳ). Đến năm 2018, Ciber - CMC trở thành liên doanh giữa tập đoàn CMC với Approxima (Đan Mạch).', 'date': '2024-11'}, {'page_content': 'Cho tới nay, CMC Consulting duy trì danh hiệu là Đối tác Vàng (Gold Partner) của SAP Việt Nam, là nhà cung cấp uy tín với hơn 15 năm kinh nghiệm trong lĩnh vực tư vấn - triển khai giải pháp Quản trị doanh nghiệp.', 'date': '2024-11'}, {'page_content': 'Bằng việc kết hợp thế mạnh của Tập đoàn công nghệ CMC hàng đầu Việt Nam với kinh nghiệm chuyên môn trong lĩnh vực cung ứng dịch vụ quản trị doanh nghiệp, CMC Consulting đã cung cấp thành công dịch vụ Tư vấn và Triển khai cho các tập đoàn lớn trong nước và quốc tế với trọng tâm chuyên sâu về nền tảng số ERP, tập trung nghiên cứu, tư vấn và giải quyết triệt để những bài toán Quản trị vận hành doanh nghiệp đa ngành.', 'date': '2024-11'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "handling_csv_2('data_for_chunks','service_product.csv','https://www.cmc.com.vn/technology-and-solution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-08 00:55:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:05<00:00,  2.76s/it]\n",
      "\u001b[32m2024-11-08 00:55:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.64s/it]\n",
      "\u001b[32m2024-11-08 00:55:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "\u001b[32m2024-11-08 00:55:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-08 00:55:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-08 00:55:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "\u001b[32m2024-11-08 00:55:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "\u001b[32m2024-11-08 00:56:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 175, triggered by: 0.26\n",
      "\u001b[31mNỗ lực xây dựng năng lực công nghệ chuyên sâu.Với định hướng trở thành Tập đoàn quốc tế, dẫn đầu chuyển đổi số, CMC xây dựng năng lực chuyên sâu về giải pháp chuyên ngành và các công nghệ lõi, xây dựng hệ sinh thái nền tảng mở cho doanh nghiệp, cung cấp đa dịch vụ cho khách hàng, là nền tảng kết nối với các hãng giải pháp công nghệ trên thế giới.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 163, triggered by: token limit\n",
      "\u001b[32m01,Triển khai giải pháp SAP Innovation Business cho doanh nghiệp,Năm 2017, Ciber-CMC cùng với SAP IBS Shanghai triển khai thành công dự án “Bất động sản Bán lẻ” cho Tập đoàn Vin Group. Dự án sử dụng giải pháp mới của SAP Innovation Business - giải pháp SAP RE CD là một giải pháp mới được đưa vào nghiên cứu và phát triển bởi nhóm SAP IBS Thượng Hải và đã được triển khai rất thành công tại Thượng Hải 3 năm trở lại đây.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 188, triggered by: token limit\n",
      "\u001b[34m02,Hệ thống CNTT toàn diện cho doanh nghiệp,Với 26 năm kinh nghiệm triển khai hệ thống CNTT cho doanh nghiệp và tổ chức, CMC tự hào cung cấp các giải pháp quản lý tác vụ cho doanh nghiệp một cách tối ưu nhất trên hệ thống CNTT, tích hợp với các giải pháp của nhiều hãng công nghệ hàng đầu thế giới. Hiện nay CMC có hơn 3000 khách hàng là Bộ Ban ngành, hiệp hội, doanh nghiệp lớn trên cả nước.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 200, triggered by: token limit\n",
      "\u001b[35m03,Giải pháp dịch vụ chuyên ngành (theo giải pháp của hãng),CMC tự hào là đối tác của hơn 30 hãng công nghệ trên thế giới, đặc biệt đang là Đối tác Vàng – Cấp độ đối tác lớn nhất của Microsoft. CMC đại diện cho các hãng triển khai và phát triển các giải pháp và dịch vụ về hệ thống, hạ tầng CNTT, các giải pháp vận hành và quản trị tổng thể cho trung tâm dữ liệu dựa trên các sản phẩm và công nghệ mới nhất cho khách hàng trong nước và khu vực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 194, triggered by: token limit\n",
      "\u001b[31m04,Tư vấn, triển khai Hoạch định nguồn lực doanh nghiệp – ERP,Các doanh nghiệp thời kỳ chuyển đổi số có nhu cầu cấp thiết triển khai hệ thống ERP (Hoạch định nguồn lực doanh nghiệp), giúp doanh nghiệp đồng bộ thông tin, minh bạch và kiểm soát số liệu một cách chính xác, thống nhất, giúp Ban lãnh đạo theo dõi sát hơn hoạt động kinh doanh và đưa ra những quyết định nhanh chóng trong việc vận hành hệ thống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 104, triggered by: 0.06\n",
      "\u001b[32m05,Cung cấp, lắp đặt thiết bị CNTT thông dụng,Những sản phẩm CNTT đơn giản đã được hãng công nghệ hoặc nhà cung cấp hoàn thiện với độ phổ dụng cao: PC, laptop, máy in, thiết bị mạng, máy chủ chuyên dụng (Intel, Unix-based).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 68, triggered by: 0.17\n",
      "\u001b[34m. . Bao gồm lắp đặt, mua mới, nâng cấp hoặc tái tục bản quyền phần mềm. 06,Xử lý dữ liệu cho doanh nghiệp (Data Management),Bao gồm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 124, triggered by: 0.32\n",
      "\u001b[35mGiải pháp phân tích dữ liệu lớn: Big data, Data warehouse. Lưu trữ và phục hồi dữ liệu: backup restore, DC-DR. . . 07,Hệ thống xử lý tác nghiệp cho doanh nghiệp ngành tiêu dùng & bán lẻ,CMC phát triển các hệ thống phần mềm đa dạng, tùy theo nhu cầu của khách hàng, bao gồm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 85, triggered by: 0.31\n",
      "\u001b[31mPhần mềm hóa đơn điện tử C-Invoice ; Phần mềm kế toán online CeAC ; Hệ thống cổng thanh toán trực tuyến ; Hệ thống thương mại điện tử, bán hàng trực tuyến (E-Commerce) dành cho doanh nghiệp. . .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 142, triggered by: token limit\n",
      "\u001b[32m08,Tư vấn, thiết kế, xây dựng cho doanh nghiệp các giải pháp an toàn thông tin hiệu quả,CMC cung cấp dịch vụ tổ chức giám sát, báo cáo, phản ứng và xử lý các vấn đề liên quan tới sự an toàn và bảo mật cho hệ thống dưới hình thức thuê nhân sự giám sát hoặc thuê hạ tầng và quản lý giám sát.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 147, triggered by: token limit\n",
      "\u001b[34m09,Giải pháp phát hiện và phòng thủ mã độc CMDD (Tiền thân CISE),Là phần mềm bảo vệ máy tính một cách toàn diện với dịch vụ hỗ trợ kỹ thuật đến từ các chuyên gia hàng đầu. Được phát triển cho các khách hàng có nhu cầu quản lý tài nguyên máy tính, phòng chống virus một cách tổng thể và tập trung, hỗ trợ các mạng cỡ lớn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 166, triggered by: token limit\n",
      "\u001b[35m10,Giải pháp phòng chống mã hóa dữ liệu CMC CryptoSHIELD,Được phát triển và công bố vào năm 2017, phần mềm CMC CryptoShield giúp người dùng, phát hiện và cảnh báo các mối nguy cơ từ Ransomware một cách nhanh chóng, chính xác, cách ly hệ thống kịp thời, tự động sao lưu dữ liệu khi máy tính có dấu hiệu bị tấn công, tự động cập nhật, phát hiện các biến thể mới của mã độc.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 136, triggered by: token limit\n",
      "\u001b[31m11,Trung tâm Điều hành An ninh mạng thế hệ mới CMC NextGen SOC,SOC là một trung tâm điều hành an ninh mạng có nhiệm vụ theo dõi, phát hiện, cách ly, xử lý các sự cố và chịu trách nhiệm về mức độ an toàn của toàn bộ hệ thống thông tin của tổ chức với tần suất giám sát, hoạt động 24/7.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 180, triggered by: token limit\n",
      "\u001b[32mCMC NextGen SOC là trung tâm điều hành an ninh mạng tiên phong tại Việt Nam tích hợp thành công trí tuệ nhân tạo (Artificial Intelligence - AI) và công nghệ Automation (tự động hóa) nhằm tối ưu hóa các hoạt động phát hiện tấn công, cách ly và phân tích lưu vết phục vụ điều tra số. 12,Dịch vụ triển khai toàn diện giải pháp SAP/Microsoft Dynamics CRM,CMC cung cấp dịch vụ triển khai toàn diện các giải pháp của SAP/Microsoft Dynamics CRM, gồm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 121, triggered by: token limit\n",
      "\u001b[34mCung cấp nguồn lực nâng cấp, lập trình hệ thống SAP/Microsoft Dynamics CRM ; Triển khai giải pháp Quản lý quan hệ khách hàng Microsoft Dynamics CRM ; Dịch vụ tích hợp hệ thống SAP vào các hệ thống khác ; Chuyển đổi hệ thống SAP ECC sang SAP S4HANA. 13,Giải pháp ảo hóa và điện toán đám mây:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 170, triggered by: 0.31\n",
      "\u001b[35mPrivate Cloud, Hybrid Cloud, SaaS,Cùng với sự phát triển của công nghệ điện toán đám mây, các giải pháp ảo hóa và điện toán đám mây sẽ giúp doanh nghiệp giải quyết hiệu quả các bài toán về khả năng mở rộng, nâng cấp thiết bị, mức độ bảo mật và sẵn sàng của dữ liệu, cùng với đó là chi phí đầu tư và chi phí vận hành hệ thống CNTT. 14,Giải pháp hạ tầng mạng:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 17, tokens 176, triggered by: token limit\n",
      "\u001b[31mLAN/WAN, Wireless, Network Monitoring. . .,Giải pháp hạ tầng mạng do CMC cung cấp là một hệ thống giải pháp khá rộng bao gồm nhiều giải pháp khác nhau: giải pháp mạng LAN, giải pháp mạng WAN, giải pháp mạng không dây, giải pháp mạng và truyền thông hợp nhất, giải pháp mạng và bảo mật… mang tính đặc thù của ngành và phù hợp với quy mô của doanh nghiệp. 15,Dịch vụ CNTT:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 18, tokens 110, triggered by: 0.39\n",
      "\u001b[32mIT Onsite, IT Helpdesk,CMC cung cấp các dịch vụ CNTT đa dạng gồm: Cho thuê thiết bị CNTT, IT Onsite, IT Helpdesk, Dịch vụ sửa chữa ; Bảo hành mở rộng, Bảo trì hệ thống, Dịch vụ cơ sở dữ liệu ; Quản trị ủy quyền. . .\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 19, tokens 56, triggered by: 0.14\n",
      "\u001b[34m16,Phân phối các sản phẩm CNTT,CMC đang là đơn vị phân phối: máy tính Acer, máy tính CMS, màn hình ViewSonic, bảng tương tác Samsung Flip\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 20, tokens 52, triggered by: 0.30\n",
      "\u001b[35mGIẢI PHÁP ĐA NGÀNH.Triển khai giải pháp SAP Innovation Business mảng \"Bất động sản Bán lẻ\" cho Vin Group.VIN GROUP.CHIA SẺ\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 21, tokens 146, triggered by: 0.42\n",
      "\u001b[31mThách thức.Vin Group là tập đoàn đa ngành hàng đầu Việt Nam. .Năm 2017, Ciber-CMC cùng với SAP IBS Shanghai triển khai thành công dự án “Bất động sản Bán lẻ” cho Tập đoàn Vin Group. Giải pháp.Dự án sử dụng giải pháp mới của SAP Innovation Business.Giải pháp SAP RE CD là một giải pháp mới được đưa vào nghiên cứu và phát triển bởi nhóm SAP IBS Thượng Hải.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 22, tokens 195, triggered by: 0.29\n",
      "\u001b[32mSAP RE CD đã được triển khai rất thành công tại Thượng Hải 3 năm trở lại đây. Với thành công của dự án đầu tiên cho Vin Group, SAP và Ciber-CMC đang tiếp tục gấp rút để chuẩn bị dự án thứ hai cho Vin Group trong việc triển khai dự án bất động sản xây dựng và quản lý dự án bất động sản. .Ciber-CMC chính thức trở thành đối tác của SAP trong việc cung cấp độc quyền về dịch vụ triển khai giải pháp bất động sản tại Việt Nam và khu vực châu Á.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 23, tokens 198, triggered by: 0.21\n",
      "\u001b[34mGIẢI PHÁP ĐA NGÀNH.Triển khai Windows 10 Enterprise và Microsoft Office 365 Plus cho EVN.Tập đoàn Điện lực Việt Nam (EVN). Thách thức.Khách hàng và nhân viên của EVN phàn nàn rằng họ cần sử dụng phần mềm Office phiên bản mới hơn so máy tính không mở được Office 2007. .Phần mềm Windows cho khách hàng là Windows 7, tốc độ chậm, không kịp xử lý các giao dịch với dung lượng lớn. Giải pháp.CMC triển khai giải pháp Microsoft 365 ProPlus và hệ điều hành Windows 10 cho toàn hệ thống của EVN.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 24, tokens 62, triggered by: 0.27\n",
      "\u001b[35m.Giải pháp mang lại kết quả hữu ích cho người sử dụng. EVN đã triển khai thành công Windows 10 và Microsoft Office 365 trong toàn hệ thống và giao dịch với khách hàng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 25, tokens 62, triggered by: 0.19\n",
      "\u001b[31m.Người dùng phản hồi tốt, thuận tiện và dễ sử dụng. GIẢI PHÁP ĐA NGÀNH.Triển khai giải pháp Microsoft 365 Enterprise cho Prudential, Sovico.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 26, tokens 130, triggered by: 0.21\n",
      "\u001b[32m. . . Prudential, Sovico. . . . Thách thức.Khách hàng doanh nghiệp cần công cụ phần mềm toàn diện giúp giải quyết email, giao dịch hàng ngày, lưu trữ dữ liệu và xử lý khối lượng công việc lớn. .Các công cụ phải được đồng nhất trên một nền tảng để tiết kiệm thời gian và dễ dàng quản lý.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 27, tokens 139, triggered by: 0.22\n",
      "\u001b[34mGiải pháp.CMC mang đến cho khách hàng giải pháp hiệu quả. .CMC triển khai giải pháp Microsoft 365 Enterprise E3 cho Prudential năm 2018 và Microsoft 365 Enterprise F1 cho Sovico Holings (tập đoàn sở hữu Vietjet Air và Phú Long Real Estate) năm 2017. Microsoft 365 cung cấp một giải pháp công nghệ tích hợp đơn nhất được thiết kế dành cho các doanh nghiệp đang phát triển.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 28, tokens 82, triggered by: final split\n",
      "\u001b[35m.Cho phép nhân viên trao đổi, cộng tác và hoàn thành công việc một cách hiệu quả nhất. .Bảo vệ dữ liệu mà không cần hệ thống quản lý CNTT phức tạp hoặc thiết bị tại chỗ đắt đỏ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'Nỗ lực xây dựng năng lực công nghệ chuyên sâu.Với định hướng trở thành Tập đoàn quốc tế, dẫn đầu chuyển đổi số, CMC xây dựng năng lực chuyên sâu về giải pháp chuyên ngành và các công nghệ lõi, xây dựng hệ sinh thái nền tảng mở cho doanh nghiệp, cung cấp đa dịch vụ cho khách hàng, là nền tảng kết nối với các hãng giải pháp công nghệ trên thế giới.', 'date': '2024-11'}, {'page_content': '01,Triển khai giải pháp SAP Innovation Business cho doanh nghiệp,Năm 2017, Ciber-CMC cùng với SAP IBS Shanghai triển khai thành công dự án “Bất động sản Bán lẻ” cho Tập đoàn Vin Group. Dự án sử dụng giải pháp mới của SAP Innovation Business - giải pháp SAP RE CD là một giải pháp mới được đưa vào nghiên cứu và phát triển bởi nhóm SAP IBS Thượng Hải và đã được triển khai rất thành công tại Thượng Hải 3 năm trở lại đây.', 'date': '2024-11'}, {'page_content': '02,Hệ thống CNTT toàn diện cho doanh nghiệp,Với 26 năm kinh nghiệm triển khai hệ thống CNTT cho doanh nghiệp và tổ chức, CMC tự hào cung cấp các giải pháp quản lý tác vụ cho doanh nghiệp một cách tối ưu nhất trên hệ thống CNTT, tích hợp với các giải pháp của nhiều hãng công nghệ hàng đầu thế giới. Hiện nay CMC có hơn 3000 khách hàng là Bộ Ban ngành, hiệp hội, doanh nghiệp lớn trên cả nước.', 'date': '2024-11'}, {'page_content': '03,Giải pháp dịch vụ chuyên ngành (theo giải pháp của hãng),CMC tự hào là đối tác của hơn 30 hãng công nghệ trên thế giới, đặc biệt đang là Đối tác Vàng – Cấp độ đối tác lớn nhất của Microsoft. CMC đại diện cho các hãng triển khai và phát triển các giải pháp và dịch vụ về hệ thống, hạ tầng CNTT, các giải pháp vận hành và quản trị tổng thể cho trung tâm dữ liệu dựa trên các sản phẩm và công nghệ mới nhất cho khách hàng trong nước và khu vực.', 'date': '2024-11'}, {'page_content': '04,Tư vấn, triển khai Hoạch định nguồn lực doanh nghiệp – ERP,Các doanh nghiệp thời kỳ chuyển đổi số có nhu cầu cấp thiết triển khai hệ thống ERP (Hoạch định nguồn lực doanh nghiệp), giúp doanh nghiệp đồng bộ thông tin, minh bạch và kiểm soát số liệu một cách chính xác, thống nhất, giúp Ban lãnh đạo theo dõi sát hơn hoạt động kinh doanh và đưa ra những quyết định nhanh chóng trong việc vận hành hệ thống.', 'date': '2024-11'}, {'page_content': '05,Cung cấp, lắp đặt thiết bị CNTT thông dụng,Những sản phẩm CNTT đơn giản đã được hãng công nghệ hoặc nhà cung cấp hoàn thiện với độ phổ dụng cao: PC, laptop, máy in, thiết bị mạng, máy chủ chuyên dụng (Intel, Unix-based).', 'date': '2024-11'}, {'page_content': '. . Bao gồm lắp đặt, mua mới, nâng cấp hoặc tái tục bản quyền phần mềm. 06,Xử lý dữ liệu cho doanh nghiệp (Data Management),Bao gồm:', 'date': '2024-11'}, {'page_content': 'Giải pháp phân tích dữ liệu lớn: Big data, Data warehouse. Lưu trữ và phục hồi dữ liệu: backup restore, DC-DR. . . 07,Hệ thống xử lý tác nghiệp cho doanh nghiệp ngành tiêu dùng & bán lẻ,CMC phát triển các hệ thống phần mềm đa dạng, tùy theo nhu cầu của khách hàng, bao gồm:', 'date': '2024-11'}, {'page_content': 'Phần mềm hóa đơn điện tử C-Invoice ; Phần mềm kế toán online CeAC ; Hệ thống cổng thanh toán trực tuyến ; Hệ thống thương mại điện tử, bán hàng trực tuyến (E-Commerce) dành cho doanh nghiệp. . .', 'date': '2024-11'}, {'page_content': '08,Tư vấn, thiết kế, xây dựng cho doanh nghiệp các giải pháp an toàn thông tin hiệu quả,CMC cung cấp dịch vụ tổ chức giám sát, báo cáo, phản ứng và xử lý các vấn đề liên quan tới sự an toàn và bảo mật cho hệ thống dưới hình thức thuê nhân sự giám sát hoặc thuê hạ tầng và quản lý giám sát.', 'date': '2024-11'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "handling_csv_2('data_for_chunks','solution_story.csv','https://www.cmc.com.vn/cmc-technology-institute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 20:57:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.35it/s]\n",
      "\u001b[32m2024-11-07 20:57:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n",
      "\u001b[32m2024-11-07 20:57:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "\u001b[32m2024-11-07 20:57:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.29it/s]\n",
      "\u001b[32m2024-11-07 20:57:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "\u001b[32m2024-11-07 20:57:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.69it/s]\n",
      "\u001b[32m2024-11-07 20:57:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "\u001b[32m2024-11-07 20:58:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 13.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.70it/s]\n",
      "\u001b[32m2024-11-07 20:58:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "\u001b[32m2024-11-07 20:58:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "\u001b[32m2024-11-07 20:58:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "\u001b[32m2024-11-07 20:58:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "\u001b[32m2024-11-07 20:58:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.27it/s]\n",
      "\u001b[32m2024-11-07 20:58:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.53it/s]\n",
      "\u001b[32m2024-11-07 20:58:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "\u001b[32m2024-11-07 20:58:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "\u001b[32m2024-11-07 20:58:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.70it/s]\n",
      "\u001b[32m2024-11-07 20:58:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "\u001b[32m2024-11-07 20:58:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "\u001b[32m2024-11-07 20:58:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 176, triggered by: 0.33\n",
      "\u001b[31mdịch vụ và sản phẩm CMC Telecom-DỊCH VỤ INTERNET CÁP QUANG - FTTX Tiên phong đưa công nghệ GPON vào Việt Nam CMC Telecom cung cấp dịch vụ Internet cáp quang tới các hộ gia đình, các doanh nghiệp trong building, các chuỗi cửa hàng, quán game với nhu cầu cao cấp về tốc độ, ổn định, cam kết băng thông quốc tế. .100% hạ tầng cáp quang Sử dụng công nghệ GPON tiên tiến với hạ tầng quang được ngầm hoá 95%.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 56, triggered by: 0.31\n",
      "\u001b[32mCam kết băng thông quốc tế Dịch vụ Internet cáp quang của CMC Telecom cam kết tốc độ và băng thông quốc tế. Tích hợp dịch vụ VAS\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 41, triggered by: final split\n",
      "\u001b[34mTích hợp với các dịch vụ giá trị gia tăng như: Tổng đài ảo, Thoại IP, Wifi Marketing.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'dịch vụ và sản phẩm CMC Telecom-DỊCH VỤ INTERNET CÁP QUANG - FTTX Tiên phong đưa công nghệ GPON vào Việt Nam CMC Telecom cung cấp dịch vụ Internet cáp quang tới các hộ gia đình, các doanh nghiệp trong building, các chuỗi cửa hàng, quán game với nhu cầu cao cấp về tốc độ, ổn định, cam kết băng thông quốc tế. .100% hạ tầng cáp quang Sử dụng công nghệ GPON tiên tiến với hạ tầng quang được ngầm hoá 95%.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/internet-cap-quang-ftth/'}, {'page_content': 'Cam kết băng thông quốc tế Dịch vụ Internet cáp quang của CMC Telecom cam kết tốc độ và băng thông quốc tế. Tích hợp dịch vụ VAS', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/internet-cap-quang-ftth/'}, {'page_content': 'Tích hợp với các dịch vụ giá trị gia tăng như: Tổng đài ảo, Thoại IP, Wifi Marketing.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/internet-cap-quang-ftth/'}, {'page_content': 'dịch vụ và sản phẩm CMC Telecom-DỊCH VỤ INTERNET LEASED LINE Kết nối riêng biệt với Internet Leased Line.Không chia sẻ băng thông Kết nối quốc tế trực tiếp, không chia sẻ băng thông.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/internet-kenh-thue-rieng-ill/'}, {'page_content': 'Độ sẵn sàng và tin cậy Các hướng kết nối quốc tế đa dạng đảm bảo kết nối ổn định. Giám sát, hỗ trợ riêng biệt', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/internet-kenh-thue-rieng-ill/'}, {'page_content': 'Hệ thống giám sát 24/7, chủ động cung cấp và cảnh báo khi có sự cố.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/internet-kenh-thue-rieng-ill/'}, {'page_content': 'dịch vụ và sản phẩm CMC Telecom-DỊCH VỤ P2P – DỊCH VỤ KẾT NỐI ĐIỂM TỚI ĐIỂM', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/truyen-dan-kenh-thue-rieng-p2p/'}, {'page_content': 'Hoàn toàn riêng biệt và bảo mật cao nhất với P2P Bảo mật thông tin tuyệt đối dành cho những doanh nghiệp có mục đích truyền dữ liệu an toàn với đường truyền cáp quang độc lập và riêng biệt.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/truyen-dan-kenh-thue-rieng-p2p/'}, {'page_content': 'Có khả năng truyền tải tốc độ lớn mà không phụ thuộc vào nhà cung cấp.Không giới hạn về tốc độ Đường truyền vật lý dành riêng và không chia sẻ băng thông Bảo mật dữ liệu tuyệt đối Kênh truyền hoàn toàn riêng biệt ngay cả với nhà mạng, bảo mật là tuyệt đối', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/truyen-dan-kenh-thue-rieng-p2p/'}, {'page_content': 'Cam kết chất lượng dịch vụ Cam kết gián đoạn dịch vụ không lớn hơn 1%/năm. Hỗ trợ 24/7', 'date': '2024-11', 'url': 'https://cmctelecom.vn/san-pham/dich-vu-kenh-truyen-internet/truyen-dan-kenh-thue-rieng-p2p/'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunks=handling_csv('data_for_chunks','product_cmc_telecom_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 20:59:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 580\n",
      "lastest date updated: 2024-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 20:59:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "\u001b[32m2024-11-07 20:59:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 20:59:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\u001b[32m2024-11-07 20:59:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "\u001b[32m2024-11-07 20:59:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "\u001b[32m2024-11-07 20:59:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\u001b[32m2024-11-07 20:59:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 20:59:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
      "\u001b[32m2024-11-07 20:59:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "\u001b[32m2024-11-07 20:59:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "\u001b[32m2024-11-07 20:59:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.04s/it]\n",
      "\u001b[32m2024-11-07 21:00:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.90s/it]\n",
      "\u001b[32m2024-11-07 21:00:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.50s/it]\n",
      "\u001b[32m2024-11-07 21:00:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:00:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\u001b[32m2024-11-07 21:00:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "\u001b[32m2024-11-07 21:00:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "\u001b[32m2024-11-07 21:00:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 21:00:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "\u001b[32m2024-11-07 21:00:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.70s/it]\n",
      "\u001b[32m2024-11-07 21:00:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "\u001b[32m2024-11-07 21:00:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 21:00:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 21:00:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.88s/it]\n",
      "\u001b[32m2024-11-07 21:00:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 21:00:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\u001b[32m2024-11-07 21:00:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 21:00:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 21:01:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "\u001b[32m2024-11-07 21:01:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\u001b[32m2024-11-07 21:01:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.42s/it]\n",
      "\u001b[32m2024-11-07 21:01:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 21:01:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "\u001b[32m2024-11-07 21:01:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 21:01:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "\u001b[32m2024-11-07 21:01:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n",
      "\u001b[32m2024-11-07 21:01:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/it]\n",
      "\u001b[32m2024-11-07 21:01:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.13s/it]\n",
      "\u001b[32m2024-11-07 21:01:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 21:01:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 21:01:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:01:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.72s/it]\n",
      "\u001b[32m2024-11-07 21:01:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\u001b[32m2024-11-07 21:01:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "\u001b[32m2024-11-07 21:01:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\u001b[32m2024-11-07 21:01:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "\u001b[32m2024-11-07 21:01:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 21:02:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
      "\u001b[32m2024-11-07 21:02:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "\u001b[32m2024-11-07 21:02:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 21:02:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 21:02:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.41s/it]\n",
      "\u001b[32m2024-11-07 21:02:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "\u001b[32m2024-11-07 21:02:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.72s/it]\n",
      "\u001b[32m2024-11-07 21:02:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n",
      "\u001b[32m2024-11-07 21:02:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.90s/it]\n",
      "\u001b[32m2024-11-07 21:02:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 21:02:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 21:02:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "\u001b[32m2024-11-07 21:02:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "\u001b[32m2024-11-07 21:02:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.63s/it]\n",
      "\u001b[32m2024-11-07 21:02:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.04s/it]\n",
      "\u001b[32m2024-11-07 21:02:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "\u001b[32m2024-11-07 21:03:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 21:03:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\u001b[32m2024-11-07 21:03:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.40s/it]\n",
      "\u001b[32m2024-11-07 21:03:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 21:03:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 21:03:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n",
      "\u001b[32m2024-11-07 21:03:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "\u001b[32m2024-11-07 21:03:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-07 21:03:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "\u001b[32m2024-11-07 21:03:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "\u001b[32m2024-11-07 21:03:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "\u001b[32m2024-11-07 21:03:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.90it/s]\n",
      "\u001b[32m2024-11-07 21:03:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.45s/it]\n",
      "\u001b[32m2024-11-07 21:03:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "\u001b[32m2024-11-07 21:03:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 21:03:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n",
      "\u001b[32m2024-11-07 21:03:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "\u001b[32m2024-11-07 21:03:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.83s/it]\n",
      "\u001b[32m2024-11-07 21:04:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.77s/it]\n",
      "\u001b[32m2024-11-07 21:04:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.91s/it]\n",
      "\u001b[32m2024-11-07 21:04:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "\u001b[32m2024-11-07 21:04:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "\u001b[32m2024-11-07 21:04:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 21:04:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 21:04:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 21:04:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.29s/it]\n",
      "\u001b[32m2024-11-07 21:04:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.44s/it]\n",
      "\u001b[32m2024-11-07 21:04:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\u001b[32m2024-11-07 21:04:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\n",
      "\u001b[32m2024-11-07 21:04:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.08s/it]\n",
      "\u001b[32m2024-11-07 21:04:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 21:05:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "\u001b[32m2024-11-07 21:05:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 21:05:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "\u001b[32m2024-11-07 21:05:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "\u001b[32m2024-11-07 21:05:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 21:05:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:05:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 21:05:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.80it/s]\n",
      "\u001b[32m2024-11-07 21:05:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.31s/it]\n",
      "\u001b[32m2024-11-07 21:05:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 21:05:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "\u001b[32m2024-11-07 21:05:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 21:05:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\u001b[32m2024-11-07 21:05:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\u001b[32m2024-11-07 21:05:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-07 21:05:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 21:05:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 21:05:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n",
      "\u001b[32m2024-11-07 21:05:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 21:05:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "\u001b[32m2024-11-07 21:05:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n",
      "\u001b[32m2024-11-07 21:06:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "\u001b[32m2024-11-07 21:06:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "\u001b[32m2024-11-07 21:06:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "\u001b[32m2024-11-07 21:06:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n",
      "\u001b[32m2024-11-07 21:06:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 21:06:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 21:06:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "\u001b[32m2024-11-07 21:06:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 21:06:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 21:06:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 21:06:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "\u001b[32m2024-11-07 21:06:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 21:06:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 21:06:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\u001b[32m2024-11-07 21:06:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\u001b[32m2024-11-07 21:06:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\u001b[32m2024-11-07 21:06:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-07 21:06:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 21:06:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.53s/it]\n",
      "\u001b[32m2024-11-07 21:06:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.74s/it]\n",
      "\u001b[32m2024-11-07 21:06:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "\u001b[32m2024-11-07 21:06:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.16s/it]\n",
      "\u001b[32m2024-11-07 21:07:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.17s/it]\n",
      "\u001b[32m2024-11-07 21:07:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.32s/it]\n",
      "\u001b[32m2024-11-07 21:07:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "\u001b[32m2024-11-07 21:07:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "\u001b[32m2024-11-07 21:07:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n",
      "\u001b[32m2024-11-07 21:07:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 21:07:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.95s/it]\n",
      "\u001b[32m2024-11-07 21:07:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-07 21:07:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 21:07:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "\u001b[32m2024-11-07 21:07:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-07 21:07:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.22s/it]\n",
      "\u001b[32m2024-11-07 21:07:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.53s/it]\n",
      "\u001b[32m2024-11-07 21:07:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.73s/it]\n",
      "\u001b[32m2024-11-07 21:07:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "\u001b[32m2024-11-07 21:07:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.06s/it]\n",
      "\u001b[32m2024-11-07 21:08:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "\u001b[32m2024-11-07 21:08:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\u001b[32m2024-11-07 21:08:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.50s/it]\n",
      "\u001b[32m2024-11-07 21:08:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\u001b[32m2024-11-07 21:08:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "\u001b[32m2024-11-07 21:08:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 21:08:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n",
      "\u001b[32m2024-11-07 21:08:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.66s/it]\n",
      "\u001b[32m2024-11-07 21:08:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\u001b[32m2024-11-07 21:08:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n",
      "\u001b[32m2024-11-07 21:08:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\u001b[32m2024-11-07 21:08:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
      "\u001b[32m2024-11-07 21:08:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\u001b[32m2024-11-07 21:08:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 21:08:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.56s/it]\n",
      "\u001b[32m2024-11-07 21:08:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 21:08:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n",
      "\u001b[32m2024-11-07 21:08:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "\u001b[32m2024-11-07 21:08:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "\u001b[32m2024-11-07 21:09:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.94s/it]\n",
      "\u001b[32m2024-11-07 21:09:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 21:09:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\u001b[32m2024-11-07 21:09:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 21:09:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "\u001b[32m2024-11-07 21:09:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\u001b[32m2024-11-07 21:09:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "\u001b[32m2024-11-07 21:09:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "\u001b[32m2024-11-07 21:09:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n",
      "\u001b[32m2024-11-07 21:09:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 21:09:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n",
      "\u001b[32m2024-11-07 21:09:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "\u001b[32m2024-11-07 21:09:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.89s/it]\n",
      "\u001b[32m2024-11-07 21:09:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "\u001b[32m2024-11-07 21:09:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "\u001b[32m2024-11-07 21:09:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "\u001b[32m2024-11-07 21:09:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 21:09:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "\u001b[32m2024-11-07 21:09:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.02s/it]\n",
      "\u001b[32m2024-11-07 21:10:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "\u001b[32m2024-11-07 21:10:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 21:10:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 21:10:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\u001b[32m2024-11-07 21:10:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 21:10:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "\u001b[32m2024-11-07 21:10:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\u001b[32m2024-11-07 21:10:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "\u001b[32m2024-11-07 21:10:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "\u001b[32m2024-11-07 21:10:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.85s/it]\n",
      "\u001b[32m2024-11-07 21:10:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "\u001b[32m2024-11-07 21:10:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 21:10:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "\u001b[32m2024-11-07 21:10:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "\u001b[32m2024-11-07 21:10:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 21:10:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\u001b[32m2024-11-07 21:10:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 21:10:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\u001b[32m2024-11-07 21:10:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "\u001b[32m2024-11-07 21:10:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 21:10:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.52s/it]\n",
      "\u001b[32m2024-11-07 21:10:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "\u001b[32m2024-11-07 21:10:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 21:10:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n",
      "\u001b[32m2024-11-07 21:11:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "\u001b[32m2024-11-07 21:11:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\u001b[32m2024-11-07 21:11:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "\u001b[32m2024-11-07 21:11:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "\u001b[32m2024-11-07 21:11:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\u001b[32m2024-11-07 21:11:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 21:11:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 21:11:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 21:11:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 21:11:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 21:11:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\u001b[32m2024-11-07 21:11:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "\u001b[32m2024-11-07 21:11:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\n",
      "\u001b[32m2024-11-07 21:11:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 21:11:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n",
      "\u001b[32m2024-11-07 21:11:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 21:11:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\u001b[32m2024-11-07 21:11:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\u001b[32m2024-11-07 21:11:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "\u001b[32m2024-11-07 21:11:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 21:12:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 21:12:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/it]\n",
      "\u001b[32m2024-11-07 21:12:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n",
      "\u001b[32m2024-11-07 21:12:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 21:12:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:12:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "\u001b[32m2024-11-07 21:12:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n",
      "\u001b[32m2024-11-07 21:12:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.15s/it]\n",
      "\u001b[32m2024-11-07 21:12:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\n",
      "\u001b[32m2024-11-07 21:12:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\u001b[32m2024-11-07 21:12:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 21:12:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n",
      "\u001b[32m2024-11-07 21:12:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n",
      "\u001b[32m2024-11-07 21:12:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.58s/it]\n",
      "\u001b[32m2024-11-07 21:12:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.64s/it]\n",
      "\u001b[32m2024-11-07 21:13:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 21:13:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "\u001b[32m2024-11-07 21:13:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n",
      "\u001b[32m2024-11-07 21:13:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "\u001b[32m2024-11-07 21:13:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 21:13:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 21:13:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 21:13:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "\u001b[32m2024-11-07 21:13:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 21:13:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\u001b[32m2024-11-07 21:13:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\u001b[32m2024-11-07 21:13:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "\u001b[32m2024-11-07 21:13:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 21:13:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "\u001b[32m2024-11-07 21:13:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.19s/it]\n",
      "\u001b[32m2024-11-07 21:13:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:13:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.94s/it]\n",
      "\u001b[32m2024-11-07 21:14:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.60s/it]\n",
      "\u001b[32m2024-11-07 21:14:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 21:14:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 21:14:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\u001b[32m2024-11-07 21:14:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-07 21:14:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "\u001b[32m2024-11-07 21:14:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "\u001b[32m2024-11-07 21:14:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 21:14:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\n",
      "\u001b[32m2024-11-07 21:14:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "\u001b[32m2024-11-07 21:14:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.70s/it]\n",
      "\u001b[32m2024-11-07 21:14:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\u001b[32m2024-11-07 21:14:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\u001b[32m2024-11-07 21:14:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 21:14:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "\u001b[32m2024-11-07 21:14:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n",
      "\u001b[32m2024-11-07 21:14:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.74s/it]\n",
      "\u001b[32m2024-11-07 21:14:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "\u001b[32m2024-11-07 21:14:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n",
      "\u001b[32m2024-11-07 21:14:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 21:14:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 21:15:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 21:15:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "\u001b[32m2024-11-07 21:15:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\u001b[32m2024-11-07 21:15:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 21:15:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 21:15:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "\u001b[32m2024-11-07 21:15:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.70s/it]\n",
      "\u001b[32m2024-11-07 21:15:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "\u001b[32m2024-11-07 21:15:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 21:15:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.22s/it]\n",
      "\u001b[32m2024-11-07 21:15:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 21:15:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "\u001b[32m2024-11-07 21:15:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 21:15:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.59s/it]\n",
      "\u001b[32m2024-11-07 21:15:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.66s/it]\n",
      "\u001b[32m2024-11-07 21:15:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 21:16:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "\u001b[32m2024-11-07 21:16:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.12s/it]\n",
      "\u001b[32m2024-11-07 21:16:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 21:16:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "\u001b[32m2024-11-07 21:16:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.43s/it]\n",
      "\u001b[32m2024-11-07 21:16:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "\u001b[32m2024-11-07 21:16:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 21:16:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 21:16:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 21:16:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:16:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "\u001b[32m2024-11-07 21:16:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.31s/it]\n",
      "\u001b[32m2024-11-07 21:16:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-07 21:16:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 21:16:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 21:17:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
      "\u001b[32m2024-11-07 21:17:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "\u001b[32m2024-11-07 21:17:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 21:17:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 21:17:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\u001b[32m2024-11-07 21:17:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n",
      "\u001b[32m2024-11-07 21:17:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 21:17:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "\u001b[32m2024-11-07 21:17:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 21:17:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "\u001b[32m2024-11-07 21:17:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.79s/it]\n",
      "\u001b[32m2024-11-07 21:17:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "\u001b[32m2024-11-07 21:17:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 21:17:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 21:17:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:10<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-07 21:17:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.79s/it]\n",
      "\u001b[32m2024-11-07 21:17:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 21:17:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 21:18:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "\u001b[32m2024-11-07 21:18:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "\u001b[32m2024-11-07 21:18:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "\u001b[32m2024-11-07 21:18:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\u001b[32m2024-11-07 21:18:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.84s/it]\n",
      "\u001b[32m2024-11-07 21:18:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 21:18:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "\u001b[32m2024-11-07 21:18:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 21:18:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 21:18:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "\u001b[32m2024-11-07 21:18:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\u001b[32m2024-11-07 21:18:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "\u001b[32m2024-11-07 21:18:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.99s/it]\n",
      "\u001b[32m2024-11-07 21:18:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\u001b[32m2024-11-07 21:18:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 21:18:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\u001b[32m2024-11-07 21:18:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-07 21:18:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-07 21:18:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\u001b[32m2024-11-07 21:18:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 21:18:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-07 21:18:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-07 21:18:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-07 21:18:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "\u001b[32m2024-11-07 21:18:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\u001b[32m2024-11-07 21:18:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "\u001b[32m2024-11-07 21:18:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 21:19:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 21:19:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.96s/it]\n",
      "\u001b[32m2024-11-07 21:19:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n",
      "\u001b[32m2024-11-07 21:19:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:20<00:00, 10.12s/it]\n",
      "\u001b[32m2024-11-07 21:19:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.60s/it]\n",
      "\u001b[32m2024-11-07 21:19:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 21:19:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 21:19:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 21:20:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.06s/it]\n",
      "\u001b[32m2024-11-07 21:20:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.38s/it]\n",
      "\u001b[32m2024-11-07 21:20:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "\u001b[32m2024-11-07 21:20:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\u001b[32m2024-11-07 21:20:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 21:20:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\u001b[32m2024-11-07 21:20:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.41it/s]\n",
      "\u001b[32m2024-11-07 21:20:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 21:20:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\u001b[32m2024-11-07 21:20:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "\u001b[32m2024-11-07 21:20:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 21:20:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n",
      "\u001b[32m2024-11-07 21:20:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 21:20:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 21:20:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n",
      "\u001b[32m2024-11-07 21:20:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "\u001b[32m2024-11-07 21:20:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.59s/it]\n",
      "\u001b[32m2024-11-07 21:20:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 21:20:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "\u001b[32m2024-11-07 21:21:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.94s/it]\n",
      "\u001b[32m2024-11-07 21:21:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\u001b[32m2024-11-07 21:21:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 21:21:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:21:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "\u001b[32m2024-11-07 21:21:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "\u001b[32m2024-11-07 21:21:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "\u001b[32m2024-11-07 21:21:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "\u001b[32m2024-11-07 21:21:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:21:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "\u001b[32m2024-11-07 21:21:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 21:21:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 21:21:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-07 21:21:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2024-11-07 21:21:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n",
      "\u001b[32m2024-11-07 21:21:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 21:21:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n",
      "\u001b[32m2024-11-07 21:21:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "\u001b[32m2024-11-07 21:21:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n",
      "\u001b[32m2024-11-07 21:21:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 21:21:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\u001b[32m2024-11-07 21:22:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n",
      "\u001b[32m2024-11-07 21:22:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "\u001b[32m2024-11-07 21:22:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 21:22:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
      "\u001b[32m2024-11-07 21:22:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 21:22:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 21:22:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 21:22:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-07 21:22:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "\u001b[32m2024-11-07 21:22:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 21:22:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\u001b[32m2024-11-07 21:22:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n",
      "\u001b[32m2024-11-07 21:22:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\u001b[32m2024-11-07 21:22:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 21:22:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "\u001b[32m2024-11-07 21:22:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.06s/it]\n",
      "\u001b[32m2024-11-07 21:22:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.24s/it]\n",
      "\u001b[32m2024-11-07 21:22:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 21:22:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 21:22:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "\u001b[32m2024-11-07 21:22:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.20s/it]\n",
      "\u001b[32m2024-11-07 21:22:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "\u001b[32m2024-11-07 21:22:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\u001b[32m2024-11-07 21:22:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-07 21:23:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 21:23:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "\u001b[32m2024-11-07 21:23:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "\u001b[32m2024-11-07 21:23:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-07 21:23:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "\u001b[32m2024-11-07 21:23:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.33s/it]\n",
      "\u001b[32m2024-11-07 21:23:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\u001b[32m2024-11-07 21:23:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n",
      "\u001b[32m2024-11-07 21:23:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 21:23:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "\u001b[32m2024-11-07 21:23:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "\u001b[32m2024-11-07 21:23:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 21:23:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\u001b[32m2024-11-07 21:23:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 21:23:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
      "\u001b[32m2024-11-07 21:23:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\u001b[32m2024-11-07 21:23:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/it]\n",
      "\u001b[32m2024-11-07 21:23:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 21:23:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.35s/it]\n",
      "\u001b[32m2024-11-07 21:23:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n",
      "\u001b[32m2024-11-07 21:24:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "\u001b[32m2024-11-07 21:24:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\u001b[32m2024-11-07 21:24:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\u001b[32m2024-11-07 21:24:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 21:24:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\u001b[32m2024-11-07 21:24:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.14it/s]\n",
      "\u001b[32m2024-11-07 21:24:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 21:24:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "\u001b[32m2024-11-07 21:24:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 21:24:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 21:24:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 21:24:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 21:24:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "\u001b[32m2024-11-07 21:24:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "\u001b[32m2024-11-07 21:24:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 21:24:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.00s/it]\n",
      "\u001b[32m2024-11-07 21:24:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.56s/it]\n",
      "\u001b[32m2024-11-07 21:24:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.21s/it]\n",
      "\u001b[32m2024-11-07 21:24:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "\u001b[32m2024-11-07 21:24:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 21:24:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "\u001b[32m2024-11-07 21:24:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.24s/it]\n",
      "\u001b[32m2024-11-07 21:24:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 21:25:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "\u001b[32m2024-11-07 21:25:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n",
      "\u001b[32m2024-11-07 21:25:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "\u001b[32m2024-11-07 21:25:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 21:25:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "\u001b[32m2024-11-07 21:25:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2024-11-07 21:25:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 21:25:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.69s/it]\n",
      "\u001b[32m2024-11-07 21:25:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.65s/it]\n",
      "\u001b[32m2024-11-07 21:25:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 21:25:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 21:25:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 21:25:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "\u001b[32m2024-11-07 21:25:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "\u001b[32m2024-11-07 21:25:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.74s/it]\n",
      "\u001b[32m2024-11-07 21:25:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 21:25:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 21:25:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "\u001b[32m2024-11-07 21:25:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.95s/it]\n",
      "\u001b[32m2024-11-07 21:26:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "\u001b[32m2024-11-07 21:26:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "\u001b[32m2024-11-07 21:26:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 21:26:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.17s/it]\n",
      "\u001b[32m2024-11-07 21:26:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]\n",
      "\u001b[32m2024-11-07 21:26:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "\u001b[32m2024-11-07 21:26:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "\u001b[32m2024-11-07 21:26:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 21:26:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.65s/it]\n",
      "\u001b[32m2024-11-07 21:26:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\u001b[32m2024-11-07 21:26:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-07 21:26:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "\u001b[32m2024-11-07 21:26:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\u001b[32m2024-11-07 21:26:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "\u001b[32m2024-11-07 21:26:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.87it/s]\n",
      "\u001b[32m2024-11-07 21:26:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 21:26:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "\u001b[32m2024-11-07 21:26:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "\u001b[32m2024-11-07 21:26:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "\u001b[32m2024-11-07 21:26:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n",
      "\u001b[32m2024-11-07 21:26:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "\u001b[32m2024-11-07 21:26:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\u001b[32m2024-11-07 21:26:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 21:26:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-07 21:26:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-07 21:26:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\u001b[32m2024-11-07 21:26:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "\u001b[32m2024-11-07 21:27:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 21:27:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-07 21:27:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 21:27:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.95s/it]\n",
      "\u001b[32m2024-11-07 21:27:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 21:27:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.84s/it]\n",
      "\u001b[32m2024-11-07 21:27:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\u001b[32m2024-11-07 21:27:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\u001b[32m2024-11-07 21:27:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.30s/it]\n",
      "\u001b[32m2024-11-07 21:27:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
      "\u001b[32m2024-11-07 21:27:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.15s/it]\n",
      "\u001b[32m2024-11-07 21:27:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.18s/it]\n",
      "\u001b[32m2024-11-07 21:27:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 21:27:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\u001b[32m2024-11-07 21:27:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\u001b[32m2024-11-07 21:27:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-07 21:27:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\u001b[32m2024-11-07 21:27:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "\u001b[32m2024-11-07 21:28:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.18s/it]\n",
      "\u001b[32m2024-11-07 21:28:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "\u001b[32m2024-11-07 21:28:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "\u001b[32m2024-11-07 21:28:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "\u001b[32m2024-11-07 21:28:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "\u001b[32m2024-11-07 21:28:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "\u001b[32m2024-11-07 21:28:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "\u001b[32m2024-11-07 21:28:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 21:28:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.86it/s]\n",
      "\u001b[32m2024-11-07 21:28:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "\u001b[32m2024-11-07 21:28:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "\u001b[32m2024-11-07 21:28:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "\u001b[32m2024-11-07 21:28:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 21:28:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      "\u001b[32m2024-11-07 21:28:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 21:28:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n",
      "\u001b[32m2024-11-07 21:28:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "\u001b[32m2024-11-07 21:28:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\u001b[32m2024-11-07 21:28:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n",
      "\u001b[32m2024-11-07 21:28:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "\u001b[32m2024-11-07 21:28:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "\u001b[32m2024-11-07 21:28:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "\u001b[32m2024-11-07 21:28:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "\u001b[32m2024-11-07 21:28:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\u001b[32m2024-11-07 21:28:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\u001b[32m2024-11-07 21:29:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\u001b[32m2024-11-07 21:29:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-07 21:29:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 221, triggered by: token limit\n",
      "\u001b[31mCMC Telecom và Check Point hợp tác nâng cao an ninh mạng cho doanh nghiệp Việt Nam Th11 01, 2024 Trước sự gia tăng của các cuộc tấn công mạng đầy tinh vi, nhu cầu của doanh nghiệp về các giải pháp bảo mật mạnh mẽ và toàn diện đã trở nên cấp bách hơn bao giờ hết. Để đáp ứng yêu cầu này, CMC Telecom đã hợp tác cùng Check Point – một trong những hãng bảo mật hàng đầu thế giới – và chính thức trở thành nhà cung cấp dịch vụ quản lý An toàn Thông tin (MSSP – Managed Security Service Provider) tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 205, triggered by: token limit\n",
      "\u001b[32mVới vai trò là đối tác cung cấp dịch vụ quản lý An toàn Thông tin (MSSP) của Check Point, CMC Telecom không chỉ cung cấp các giải pháp, sản phẩm mà còn đảm nhiệm toàn bộ quy trình triển khai, vận hành, giám sát và xử lý sự cố. Điều này có nghĩa là, từ việc lắp đặt hệ thống, giám sát liên tục 24/7 cho đến khi xử lý các sự cố phát sinh, CMC Telecom sẽ luôn đồng hành cùng khách hàng, đảm bảo rằng hệ thống của họ luôn được bảo vệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 180, triggered by: 0.33\n",
      "\u001b[34mHai sản phẩm nổi bật nhất chính là Harmony Endpoint và CloudGuard Network Security – Không chỉ đảm bảo an toàn cho hệ thống mạng, thiết bị đầu cuối và hạ tầng đám mây, mà còn giúp các doanh nghiệp tối ưu hoá hoạt động và chi phí. Harmony Endpoint là giải pháp bảo mật điểm cuối (endpoint security) được thiết kế để bảo vệ từ sớm hệ thống của doanh nghiệp khỏi các mối đe dọa như mã độc, ransomware, phishing, malware và các cuộc tấn công zero-day.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 87, triggered by: 0.43\n",
      "\u001b[35mSản phẩm này không chỉ ngăn chặn các mối đe dọa tiềm năng đối với điểm cuối (endpoint) mà còn nhanh chóng giảm thiểu các tác động với khả năng phát hiện (detection) và phản hồi tự động (response).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 126, triggered by: token limit\n",
      "\u001b[31mMô hình Harmony Endpoint – Check Point Những tính năng chính của Harmony Endpoint có thể kể đến là: Phòng chống Ransomware: Harmony Endpoint sử dụng công nghệ phát hiện và ngăn chặn mã độc tiên tiến, giúp phát hiện kịp thời và ngăn chặn các cuộc tấn công ransomware trước khi chúng có thể gây thiệt hại nghiêm trọng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 187, triggered by: 0.24\n",
      "\u001b[32mNgăn chặn các mối đe dọa Zero-day: Được tích hợp các cơ chế phân tích và học máy (Machine Learning), Harmony Endpoint có khả năng xác định và vô hiệu hóa các mối đe dọa Zero-day tiềm ẩn, ngăn chặn các cuộc tấn công chưa từng có tiền lệ. Tích hợp khả năng phục hồi hệ thống: Harmony Endpoint không chỉ ngăn chặn mà còn có khả năng phục hồi các dữ liệu bị mã độc mã hóa, đảm bảo hoạt động liên tục cho doanh nghiệp.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 159, triggered by: 0.46\n",
      "\u001b[34mQuản lý tập trung: Giải pháp này cung cấp một nền tảng quản lý tập trung, giúp doanh nghiệp dễ dàng theo dõi và kiểm soát tình hình an ninh của toàn bộ hệ thống. Với Harmony Endpoint, các doanh nghiệp có thể yên tâm rằng rủi ro từ các nguy cơ tấn công mạng được giảm thiểu tối đa, nhờ vào sự bảo vệ toàn diện cho các thiết bị đầu cuối trong hệ thống.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 59, triggered by: 0.45\n",
      "\u001b[35mSản phẩm giúp rút ngắn thời gian phục hồi sau sự cố, đảm bảo hoạt động kinh doanh luôn liên tục và không gián đoạn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 85, triggered by: token limit\n",
      "\u001b[31mCloudGuard Network Security là giải pháp an ninh dành riêng cho các hệ thống điện toán đám mây, đảm bảo tính bảo mật cao nhất cho các tài nguyên và ứng dụng của doanh nghiệp trên môi trường đám mây.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 150, triggered by: 0.36\n",
      "\u001b[32mTrong bối cảnh ngày càng nhiều doanh nghiệp chuyển đổi sang sử dụng các nền tảng điện toán đám mây, CloudGuard Network Security được thiết kế để bảo vệ tối đa hệ thống mạng, ngăn chặn các cuộc tấn công và tối ưu hóa việc quản lý bảo mật trên môi trường này. Mô hình CloudGuard Network Security – Check Point Những tính năng chính của CloudGuard Network Security bao gồm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 87, triggered by: 0.27\n",
      "\u001b[34mBảo vệ khỏi các mối đe dọa phức tạp: Với công nghệ Threat Prevention của Check Point, CloudGuard Network Security giúp bảo vệ doanh nghiệp khỏi các cuộc tấn công phức tạp như malware, phishing, và các cuộc tấn công DDoS.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 76, triggered by: 0.15\n",
      "\u001b[35mKiểm soát truy cập chi tiết: Cho phép doanh nghiệp quản lý và kiểm soát chi tiết các truy cập vào hệ thống mạng đám mây, giảm thiểu rủi ro từ các truy cập trái phép.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 112, triggered by: 0.37\n",
      "\u001b[31mTích hợp với các nền tảng đám mây hàng đầu: CloudGuard Network Security có khả năng tích hợp với các nền tảng đám mây phổ biến như AWS, Microsoft Azure, và Google Cloud, giúp quản lý và bảo mật dễ dàng trên mọi hạ tầng đám mây mà doanh nghiệp sử dụng.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 184, triggered by: token limit\n",
      "\u001b[32mTự động hoá quy trình bảo mật: CloudGuard Network Security có khả năng tự động hoá các quy trình bảo mật, từ việc phát hiện các mối đe dọa cho đến xử lý sự cố, giúp giảm thiểu công sức và chi phí cho doanh nghiệp. Theo các chuyên gia bảo mật của CMC Telecom chia sẻ, với CloudGuard Network Security, các doanh nghiệp có thể triển khai hạ tầng đám mây một cách an toàn và linh hoạt, giảm thiểu lo ngại về nguy cơ bảo mật.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 183, triggered by: token limit\n",
      "\u001b[34mCác tính năng bảo vệ tự động và phân tích mối đe dọa theo thời gian thực của CloudGuard Network Security giúp doanh nghiệp giảm thiểu nguy cơ bị tấn công, bảo vệ dữ liệu nhạy cảm và đảm bảo tuân thủ các quy định bảo mật nghiêm ngặt. Hợp tác với Check Point đươc coi như một phần quan trọng trong chiến lược của CMC Telecom nhằm xây dựng một hệ sinh thái bảo mật toàn diện cho khách hàng tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 140, triggered by: final split\n",
      "\u001b[35mHướng tới mục tiêu hỗ trợ các doanh nghiệp nâng cao năng lực phòng thủ mạng và bảo vệ tài sản số, MC Telecom sẽ tiếp tục không ngừng cải tiến dịch vụ, cung cấp cho khách hàng giải pháp bảo mật hiệu quả và đồng hành cùng họ trong suốt hành trình phát triển. #CMCTelecom #MSSP #HarmonyEndpoint #CloudGuardNetworkSecurity #Security\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'CMC Telecom và Check Point hợp tác nâng cao an ninh mạng cho doanh nghiệp Việt Nam Th11 01, 2024 Trước sự gia tăng của các cuộc tấn công mạng đầy tinh vi, nhu cầu của doanh nghiệp về các giải pháp bảo mật mạnh mẽ và toàn diện đã trở nên cấp bách hơn bao giờ hết. Để đáp ứng yêu cầu này, CMC Telecom đã hợp tác cùng Check Point – một trong những hãng bảo mật hàng đầu thế giới – và chính thức trở thành nhà cung cấp dịch vụ quản lý An toàn Thông tin (MSSP – Managed Security Service Provider) tại Việt Nam.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Với vai trò là đối tác cung cấp dịch vụ quản lý An toàn Thông tin (MSSP) của Check Point, CMC Telecom không chỉ cung cấp các giải pháp, sản phẩm mà còn đảm nhiệm toàn bộ quy trình triển khai, vận hành, giám sát và xử lý sự cố. Điều này có nghĩa là, từ việc lắp đặt hệ thống, giám sát liên tục 24/7 cho đến khi xử lý các sự cố phát sinh, CMC Telecom sẽ luôn đồng hành cùng khách hàng, đảm bảo rằng hệ thống của họ luôn được bảo vệ.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Hai sản phẩm nổi bật nhất chính là Harmony Endpoint và CloudGuard Network Security – Không chỉ đảm bảo an toàn cho hệ thống mạng, thiết bị đầu cuối và hạ tầng đám mây, mà còn giúp các doanh nghiệp tối ưu hoá hoạt động và chi phí. Harmony Endpoint là giải pháp bảo mật điểm cuối (endpoint security) được thiết kế để bảo vệ từ sớm hệ thống của doanh nghiệp khỏi các mối đe dọa như mã độc, ransomware, phishing, malware và các cuộc tấn công zero-day.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Sản phẩm này không chỉ ngăn chặn các mối đe dọa tiềm năng đối với điểm cuối (endpoint) mà còn nhanh chóng giảm thiểu các tác động với khả năng phát hiện (detection) và phản hồi tự động (response).', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Mô hình Harmony Endpoint – Check Point Những tính năng chính của Harmony Endpoint có thể kể đến là: Phòng chống Ransomware: Harmony Endpoint sử dụng công nghệ phát hiện và ngăn chặn mã độc tiên tiến, giúp phát hiện kịp thời và ngăn chặn các cuộc tấn công ransomware trước khi chúng có thể gây thiệt hại nghiêm trọng.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Ngăn chặn các mối đe dọa Zero-day: Được tích hợp các cơ chế phân tích và học máy (Machine Learning), Harmony Endpoint có khả năng xác định và vô hiệu hóa các mối đe dọa Zero-day tiềm ẩn, ngăn chặn các cuộc tấn công chưa từng có tiền lệ. Tích hợp khả năng phục hồi hệ thống: Harmony Endpoint không chỉ ngăn chặn mà còn có khả năng phục hồi các dữ liệu bị mã độc mã hóa, đảm bảo hoạt động liên tục cho doanh nghiệp.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Quản lý tập trung: Giải pháp này cung cấp một nền tảng quản lý tập trung, giúp doanh nghiệp dễ dàng theo dõi và kiểm soát tình hình an ninh của toàn bộ hệ thống. Với Harmony Endpoint, các doanh nghiệp có thể yên tâm rằng rủi ro từ các nguy cơ tấn công mạng được giảm thiểu tối đa, nhờ vào sự bảo vệ toàn diện cho các thiết bị đầu cuối trong hệ thống.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Sản phẩm giúp rút ngắn thời gian phục hồi sau sự cố, đảm bảo hoạt động kinh doanh luôn liên tục và không gián đoạn.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'CloudGuard Network Security là giải pháp an ninh dành riêng cho các hệ thống điện toán đám mây, đảm bảo tính bảo mật cao nhất cho các tài nguyên và ứng dụng của doanh nghiệp trên môi trường đám mây.', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}, {'page_content': 'Trong bối cảnh ngày càng nhiều doanh nghiệp chuyển đổi sang sử dụng các nền tảng điện toán đám mây, CloudGuard Network Security được thiết kế để bảo vệ tối đa hệ thống mạng, ngăn chặn các cuộc tấn công và tối ưu hóa việc quản lý bảo mật trên môi trường này. Mô hình CloudGuard Network Security – Check Point Những tính năng chính của CloudGuard Network Security bao gồm:', 'date': '2024-11', 'url': 'https://cmctelecom.vn/bai-viet/cmc-telecom-va-check-point-hop-tac-nang-cao-an-ninh-mang-cho-doanh-nghiep-viet-nam/'}]\n"
     ]
    }
   ],
   "source": [
    "chunks=handling_csv('data_for_chunks','tintuc_cmc_telecom_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 21:29:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 324\n",
      "lastest date updated: 2024-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "\u001b[32m2024-11-07 21:29:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 21:29:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "\u001b[32m2024-11-07 21:29:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-07 21:29:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 21:29:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.20s/it]\n",
      "\u001b[32m2024-11-07 21:29:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.87s/it]\n",
      "\u001b[32m2024-11-07 21:29:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 21:29:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\u001b[32m2024-11-07 21:29:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "\u001b[32m2024-11-07 21:29:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "\u001b[32m2024-11-07 21:29:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\u001b[32m2024-11-07 21:29:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 21:29:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.14it/s]\n",
      "\u001b[32m2024-11-07 21:29:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-07 21:29:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:29:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 21:29:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "\u001b[32m2024-11-07 21:29:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "\u001b[32m2024-11-07 21:29:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 21:29:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.70s/it]\n",
      "\u001b[32m2024-11-07 21:30:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.08s/it]\n",
      "\u001b[32m2024-11-07 21:30:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 21:30:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-07 21:30:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "\u001b[32m2024-11-07 21:30:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n",
      "\u001b[32m2024-11-07 21:30:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "\u001b[32m2024-11-07 21:30:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.65s/it]\n",
      "\u001b[32m2024-11-07 21:30:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-07 21:30:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 21:30:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 21:30:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n",
      "\u001b[32m2024-11-07 21:30:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.70s/it]\n",
      "\u001b[32m2024-11-07 21:31:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n",
      "\u001b[32m2024-11-07 21:31:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.41s/it]\n",
      "\u001b[32m2024-11-07 21:31:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 21:31:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 21:31:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\u001b[32m2024-11-07 21:31:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 21:31:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:19<00:00,  9.89s/it]\n",
      "\u001b[32m2024-11-07 21:31:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "\u001b[32m2024-11-07 21:31:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n",
      "\u001b[32m2024-11-07 21:31:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "\u001b[32m2024-11-07 21:31:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n",
      "\u001b[32m2024-11-07 21:32:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.47s/it]\n",
      "\u001b[32m2024-11-07 21:32:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 21:32:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "\u001b[32m2024-11-07 21:32:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 21:32:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\u001b[32m2024-11-07 21:32:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.68s/it]\n",
      "\u001b[32m2024-11-07 21:32:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.02s/it]\n",
      "\u001b[32m2024-11-07 21:32:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "\u001b[32m2024-11-07 21:32:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-07 21:32:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.97s/it]\n",
      "\u001b[32m2024-11-07 21:32:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 21:32:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-07 21:32:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-07 21:33:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 21:33:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "\u001b[32m2024-11-07 21:33:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.75s/it]\n",
      "\u001b[32m2024-11-07 21:33:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.02s/it]\n",
      "\u001b[32m2024-11-07 21:33:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.23s/it]\n",
      "\u001b[32m2024-11-07 21:33:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 21:33:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n",
      "\u001b[32m2024-11-07 21:33:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.07s/it]\n",
      "\u001b[32m2024-11-07 21:33:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 21:33:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 21:33:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.02s/it]\n",
      "\u001b[32m2024-11-07 21:34:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\u001b[32m2024-11-07 21:34:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n",
      "\u001b[32m2024-11-07 21:34:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.48s/it]\n",
      "\u001b[32m2024-11-07 21:34:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 21:34:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 21:34:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\u001b[32m2024-11-07 21:34:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "\u001b[32m2024-11-07 21:34:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.29s/it]\n",
      "\u001b[32m2024-11-07 21:34:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.06s/it]\n",
      "\u001b[32m2024-11-07 21:34:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.79s/it]\n",
      "\u001b[32m2024-11-07 21:35:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n",
      "\u001b[32m2024-11-07 21:35:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:35:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.20s/it]\n",
      "\u001b[32m2024-11-07 21:35:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.17s/it]\n",
      "\u001b[32m2024-11-07 21:35:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n",
      "\u001b[32m2024-11-07 21:35:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.19s/it]\n",
      "\u001b[32m2024-11-07 21:35:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.70s/it]\n",
      "\u001b[32m2024-11-07 21:35:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.58s/it]\n",
      "\u001b[32m2024-11-07 21:35:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n",
      "\u001b[32m2024-11-07 21:35:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 21:36:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.60s/it]\n",
      "\u001b[32m2024-11-07 21:36:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.23s/it]\n",
      "\u001b[32m2024-11-07 21:36:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:36:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 21:36:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.56s/it]\n",
      "\u001b[32m2024-11-07 21:36:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:36:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.87s/it]\n",
      "\u001b[32m2024-11-07 21:36:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 21:37:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.10s/it]\n",
      "\u001b[32m2024-11-07 21:37:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-07 21:37:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 21:37:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-07 21:37:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.57s/it]\n",
      "\u001b[32m2024-11-07 21:37:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.25s/it]\n",
      "\u001b[32m2024-11-07 21:37:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.75s/it]\n",
      "\u001b[32m2024-11-07 21:37:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.43s/it]\n",
      "\u001b[32m2024-11-07 21:37:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.29s/it]\n",
      "\u001b[32m2024-11-07 21:38:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.38s/it]\n",
      "\u001b[32m2024-11-07 21:38:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 21:38:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.35s/it]\n",
      "\u001b[32m2024-11-07 21:38:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.79s/it]\n",
      "\u001b[32m2024-11-07 21:38:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-07 21:38:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.71s/it]\n",
      "\u001b[32m2024-11-07 21:38:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 21:38:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.69s/it]\n",
      "\u001b[32m2024-11-07 21:39:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "\u001b[32m2024-11-07 21:39:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 21:39:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 21:39:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 21:39:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.57s/it]\n",
      "\u001b[32m2024-11-07 21:39:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-07 21:39:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.67s/it]\n",
      "\u001b[32m2024-11-07 21:39:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.96s/it]\n",
      "\u001b[32m2024-11-07 21:40:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.22s/it]\n",
      "\u001b[32m2024-11-07 21:40:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.91s/it]\n",
      "\u001b[32m2024-11-07 21:40:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 21:40:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 21:40:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.89s/it]\n",
      "\u001b[32m2024-11-07 21:40:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.19s/it]\n",
      "\u001b[32m2024-11-07 21:40:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 21:40:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.76s/it]\n",
      "\u001b[32m2024-11-07 21:40:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.47s/it]\n",
      "\u001b[32m2024-11-07 21:41:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 21:41:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.27s/it]\n",
      "\u001b[32m2024-11-07 21:41:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.09s/it]\n",
      "\u001b[32m2024-11-07 21:41:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.77s/it]\n",
      "\u001b[32m2024-11-07 21:41:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.89s/it]\n",
      "\u001b[32m2024-11-07 21:41:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 21:41:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.58s/it]\n",
      "\u001b[32m2024-11-07 21:41:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.16s/it]\n",
      "\u001b[32m2024-11-07 21:42:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.74s/it]\n",
      "\u001b[32m2024-11-07 21:42:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 21:42:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.61s/it]\n",
      "\u001b[32m2024-11-07 21:42:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.36s/it]\n",
      "\u001b[32m2024-11-07 21:42:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\u001b[32m2024-11-07 21:42:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.73s/it]\n",
      "\u001b[32m2024-11-07 21:42:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 21:43:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.70s/it]\n",
      "\u001b[32m2024-11-07 21:43:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.55it/s]\n",
      "\u001b[32m2024-11-07 21:43:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.18s/it]\n",
      "\u001b[32m2024-11-07 21:43:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 21:43:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 21:43:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.37s/it]\n",
      "\u001b[32m2024-11-07 21:43:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "\u001b[32m2024-11-07 21:43:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.05s/it]\n",
      "\u001b[32m2024-11-07 21:43:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.13s/it]\n",
      "\u001b[32m2024-11-07 21:43:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 21:44:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.13s/it]\n",
      "\u001b[32m2024-11-07 21:44:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "\u001b[32m2024-11-07 21:44:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 21:44:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.76s/it]\n",
      "\u001b[32m2024-11-07 21:44:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.36s/it]\n",
      "\u001b[32m2024-11-07 21:44:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "\u001b[32m2024-11-07 21:44:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.64s/it]\n",
      "\u001b[32m2024-11-07 21:44:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.56s/it]\n",
      "\u001b[32m2024-11-07 21:44:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 21:44:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.92s/it]\n",
      "\u001b[32m2024-11-07 21:45:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 21:45:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:12<00:00,  4.28s/it]\n",
      "\u001b[32m2024-11-07 21:45:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n",
      "\u001b[32m2024-11-07 21:45:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 21:45:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.97s/it]\n",
      "\u001b[32m2024-11-07 21:45:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.82s/it]\n",
      "\u001b[32m2024-11-07 21:45:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 21:46:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.12s/it]\n",
      "\u001b[32m2024-11-07 21:46:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.70s/it]\n",
      "\u001b[32m2024-11-07 21:46:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.51s/it]\n",
      "\u001b[32m2024-11-07 21:46:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.47s/it]\n",
      "\u001b[32m2024-11-07 21:46:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.51s/it]\n",
      "\u001b[32m2024-11-07 21:46:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 21:46:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.35s/it]\n",
      "\u001b[32m2024-11-07 21:47:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "\u001b[32m2024-11-07 21:47:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.33s/it]\n",
      "\u001b[32m2024-11-07 21:47:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.46s/it]\n",
      "\u001b[32m2024-11-07 21:47:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 21:47:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.20s/it]\n",
      "\u001b[32m2024-11-07 21:47:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-07 21:47:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 21:47:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.62s/it]\n",
      "\u001b[32m2024-11-07 21:47:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 21:48:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.62s/it]\n",
      "\u001b[32m2024-11-07 21:48:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.51s/it]\n",
      "\u001b[32m2024-11-07 21:48:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.75s/it]\n",
      "\u001b[32m2024-11-07 21:48:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.33s/it]\n",
      "\u001b[32m2024-11-07 21:48:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-07 21:48:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "\u001b[32m2024-11-07 21:48:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.13s/it]\n",
      "\u001b[32m2024-11-07 21:48:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.04s/it]\n",
      "\u001b[32m2024-11-07 21:49:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.82s/it]\n",
      "\u001b[32m2024-11-07 21:49:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.21s/it]\n",
      "\u001b[32m2024-11-07 21:49:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 21:49:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 21:49:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 21:49:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.89s/it]\n",
      "\u001b[32m2024-11-07 21:49:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 21:49:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 21:49:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.45s/it]\n",
      "\u001b[32m2024-11-07 21:49:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.48s/it]\n",
      "\u001b[32m2024-11-07 21:49:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 21:50:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 21:50:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.87s/it]\n",
      "\u001b[32m2024-11-07 21:50:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 21:50:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 21:50:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.88s/it]\n",
      "\u001b[32m2024-11-07 21:50:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.45s/it]\n",
      "\u001b[32m2024-11-07 21:50:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 21:50:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "\u001b[32m2024-11-07 21:50:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.33s/it]\n",
      "\u001b[32m2024-11-07 21:50:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 21:50:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 21:51:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 21:51:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 21:51:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 21:51:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 21:51:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-07 21:51:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n",
      "\u001b[32m2024-11-07 21:51:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\u001b[32m2024-11-07 21:51:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n",
      "\u001b[32m2024-11-07 21:51:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\n",
      "\u001b[32m2024-11-07 21:51:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 21:51:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/it]\n",
      "\u001b[32m2024-11-07 21:51:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 21:51:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\u001b[32m2024-11-07 21:51:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\u001b[32m2024-11-07 21:51:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.97s/it]\n",
      "\u001b[32m2024-11-07 21:51:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 21:52:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.41s/it]\n",
      "\u001b[32m2024-11-07 21:52:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.54s/it]\n",
      "\u001b[32m2024-11-07 21:52:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.48s/it]\n",
      "\u001b[32m2024-11-07 21:52:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 21:52:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "\u001b[32m2024-11-07 21:52:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 21:52:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 21:52:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 21:52:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 21:52:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 21:52:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.08s/it]\n",
      "\u001b[32m2024-11-07 21:52:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n",
      "\u001b[32m2024-11-07 21:52:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 21:52:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "\u001b[32m2024-11-07 21:52:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\u001b[32m2024-11-07 21:53:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "\u001b[32m2024-11-07 21:53:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n",
      "\u001b[32m2024-11-07 21:53:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.08s/it]\n",
      "\u001b[32m2024-11-07 21:53:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n",
      "\u001b[32m2024-11-07 21:53:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n",
      "\u001b[32m2024-11-07 21:53:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "\u001b[32m2024-11-07 21:53:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 21:53:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.58s/it]\n",
      "\u001b[32m2024-11-07 21:53:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.92s/it]\n",
      "\u001b[32m2024-11-07 21:53:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 21:53:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 21:53:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 21:54:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.81s/it]\n",
      "\u001b[32m2024-11-07 21:54:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.06s/it]\n",
      "\u001b[32m2024-11-07 21:54:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 21:54:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 21:54:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "\u001b[32m2024-11-07 21:54:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 21:54:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "\u001b[32m2024-11-07 21:54:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\u001b[32m2024-11-07 21:54:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "\u001b[32m2024-11-07 21:54:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.15s/it]\n",
      "\u001b[32m2024-11-07 21:54:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "\u001b[32m2024-11-07 21:54:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "\u001b[32m2024-11-07 21:55:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "\u001b[32m2024-11-07 21:55:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.90s/it]\n",
      "\u001b[32m2024-11-07 21:55:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 21:55:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\u001b[32m2024-11-07 21:55:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-07 21:55:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "\u001b[32m2024-11-07 21:55:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "\u001b[32m2024-11-07 21:55:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.71s/it]\n",
      "\u001b[32m2024-11-07 21:55:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "\u001b[32m2024-11-07 21:55:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 21:55:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "\u001b[32m2024-11-07 21:55:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 21:55:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 21:55:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 21:55:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.48s/it]\n",
      "\u001b[32m2024-11-07 21:55:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 21:55:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 21:56:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 21:56:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "\u001b[32m2024-11-07 21:56:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 21:56:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 21:56:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "\u001b[32m2024-11-07 21:56:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 21:56:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "\u001b[32m2024-11-07 21:56:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "\u001b[32m2024-11-07 21:56:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 21:56:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\u001b[32m2024-11-07 21:56:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 21:56:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 21:56:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.92s/it]\n",
      "\u001b[32m2024-11-07 21:56:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 21:56:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.12s/it]\n",
      "\u001b[32m2024-11-07 21:56:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 21:56:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n",
      "\u001b[32m2024-11-07 21:57:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 21:57:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.68s/it]\n",
      "\u001b[32m2024-11-07 21:57:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 21:57:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\u001b[32m2024-11-07 21:57:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.87s/it]\n",
      "\u001b[32m2024-11-07 21:57:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.06s/it]\n",
      "\u001b[32m2024-11-07 21:57:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 21:57:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.19s/it]\n",
      "\u001b[32m2024-11-07 21:57:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "\u001b[32m2024-11-07 21:57:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n",
      "\u001b[32m2024-11-07 21:57:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\n",
      "\u001b[32m2024-11-07 21:57:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 21:57:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-07 21:57:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 21:57:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\u001b[32m2024-11-07 21:57:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 181, triggered by: 0.28\n",
      "\u001b[31mTối ưu hiệu suất và bảo mật dữ liệu khi “lên mây” AWS cùng CMC TS 18-10-2024 Ứng dụng đám mây hiện đại và hạ tầng mạnh mẽ cho phép doanh nghiệp dựa trên dữ liệu tối ưu hóa dịch vụ, cải thiện trải nghiệm khách hàng, tăng doanh thu và nâng cao hiệu quả hoạt động. CMC TS đạt chứng nhận AWS MCP, giúp doanh nghiệp lên đám mây an toàn, hiệu suất cao / 07-10-2024\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 138, triggered by: 0.28\n",
      "\u001b[32mTheo một nghiên cứu do Enterprise Strategy Group thực hiện năm 2023, việc vận hành và kinh doanh của doanh nghiệp đang ngày càng tạo ra nhiều dữ liệu với tốc độ nhanh hơn và ở nhiều định dạng đa dạng hơn bao giờ hết, đặc biệt là khối lượng công việc liên quan đến trí tuệ nhân tạo (AI) và máy học (ML).\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 130, triggered by: token limit\n",
      "\u001b[34m21% doanh nghiệp cho rằng sản phẩm và dịch vụ cốt lõi của họ hoàn toàn phụ thuộc vào dữ liệu (dựa trên thông tin). 44% báo cáo rằng dữ liệu giúp hỗ trợ kinh doanh. 35% còn lại cho rằng họ cung cấp sự kết hợp giữa các sản phẩm và dịch vụ dựa trên thông tin và sản phẩm hữu hình.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 179, triggered by: token limit\n",
      "\u001b[35mỨng dụng đám mây hiện đại và hạ tầng mạnh mẽ cho phép doanh nghiệp dựa trên dữ liệu tối ưu hóa dịch vụ, cải thiện trải nghiệm khách hàng, tăng doanh thu và nâng cao hiệu quả hoạt động. Khai thác tiềm năng dữ liệu với AWS Cloud Migration Theo báo cáo của Synergy Research Group và Flexera 2024, Amazon Web Services (AWS) vẫn là nhà cung cấp dịch vụ đám mây hàng đầu, chiếm khoảng 34% thị phần toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 162, triggered by: 0.05\n",
      "\u001b[31mMột số liệu từ Flexera cho thấy 77% các doanh nghiệp đã và đang sử dụng dịch vụ của AWS, phản ánh sự phổ biến của nền tảng này trong cộng đồng doanh nghiệp trên toàn thế giới. AWS được các công ty lớn ưa chuộng trong việc triển khai các dịch vụ đám mây và các sáng kiến kỹ thuật số. Chuyển đổi hệ thống lên nền tảng AWS Cloud mang lại cho doanh nghiệp vô số lợi ích thiết thực:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 51, triggered by: 0.24\n",
      "\u001b[32mGiảm chi phí: AWS giúp giảm đến 66% Tổng Chi phí Sở hữu (TCO) trong 3 năm so với hạ tầng on-prem.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 68, triggered by: 0.26\n",
      "\u001b[34mTăng hiệu suất và cải thiện hiệu quả vận hành: Các ứng dụng chạy nhanh hơn, hệ thống hoạt động mượt mà hơn. Giảm rủi ro bảo mật:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 134, triggered by: 0.30\n",
      "\u001b[35mHạ tầng đám mây AWS cung cấp các giải pháp bảo mật tiêu chuẩn quốc tế. Tăng Cường Trải Nghiệm Khách Hàng: Sử dụng AWS cho phép doanh nghiệp tối ưu hóa quy trình và ứng dụng, từ đó cải thiện trải nghiệm khách hàng và thúc đẩy sự hài lòng, dẫn đến tăng trưởng doanh thu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 74, triggered by: 0.34\n",
      "\u001b[31mTận dụng tối đa Giá Trị Dữ Liệu: Tạo điều kiện để khai thác giá trị dữ liệu qua phân tích nâng cao, AI và ML, giúp đưa ra quyết định kinh doanh thông minh hơn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 97, triggered by: 0.12\n",
      "\u001b[32mChọn CMC TS để yên tâm trên hành trình lên mây AWS CMC TS là đối tác Advanced Tier Services của AWS và vừa đạt chứng nhận AWS Migration Competency Program (MCP), chứng tỏ khả năng triển khai AWS Cloud Migration với chất lượng cao nhất, được công nhận bởi AWS toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 62, triggered by: 0.20\n",
      "\u001b[34m30 năm tư vấn & triển khai giải pháp CNTT tổng thể toàn diện cho 10,000 tổ chức, doanh nghiệp toàn quốc ở đa lĩnh vực:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 169, triggered by: 0.41\n",
      "\u001b[35mBảo hiểm, Y tế, Tài chính, Xây dựng, … +40 chuyên gia được chứng nhận bởi AWS với nhiều chứng chỉ cao cấp Dịch vụ tư vấn hỗ trợ 24/7 của CMC TS theo framework của hãng. Miễn phí 2 tháng dịch vụ AWS khi đăng ký với CMC TS! CMC TS và AWS mang đến chương trình ưu đãi lớn cho doanh nghiệp chưa từng sử dụng AWS: Miễn phí 2 tháng sử dụng AWS Cloud\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 64, triggered by: final split\n",
      "\u001b[31mTặng 100 Hợp đồng điện tử C-Contract và 100 lượt ký số C-Sign trong 6 tháng Bứt phá tiềm năng của doanh nghiệp cùng CMC TS và AWS Cloud Migration > Link\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'Tối ưu hiệu suất và bảo mật dữ liệu khi “lên mây” AWS cùng CMC TS 18-10-2024 Ứng dụng đám mây hiện đại và hạ tầng mạnh mẽ cho phép doanh nghiệp dựa trên dữ liệu tối ưu hóa dịch vụ, cải thiện trải nghiệm khách hàng, tăng doanh thu và nâng cao hiệu quả hoạt động. CMC TS đạt chứng nhận AWS MCP, giúp doanh nghiệp lên đám mây an toàn, hiệu suất cao / 07-10-2024', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Theo một nghiên cứu do Enterprise Strategy Group thực hiện năm 2023, việc vận hành và kinh doanh của doanh nghiệp đang ngày càng tạo ra nhiều dữ liệu với tốc độ nhanh hơn và ở nhiều định dạng đa dạng hơn bao giờ hết, đặc biệt là khối lượng công việc liên quan đến trí tuệ nhân tạo (AI) và máy học (ML).', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': '21% doanh nghiệp cho rằng sản phẩm và dịch vụ cốt lõi của họ hoàn toàn phụ thuộc vào dữ liệu (dựa trên thông tin). 44% báo cáo rằng dữ liệu giúp hỗ trợ kinh doanh. 35% còn lại cho rằng họ cung cấp sự kết hợp giữa các sản phẩm và dịch vụ dựa trên thông tin và sản phẩm hữu hình.', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Ứng dụng đám mây hiện đại và hạ tầng mạnh mẽ cho phép doanh nghiệp dựa trên dữ liệu tối ưu hóa dịch vụ, cải thiện trải nghiệm khách hàng, tăng doanh thu và nâng cao hiệu quả hoạt động. Khai thác tiềm năng dữ liệu với AWS Cloud Migration Theo báo cáo của Synergy Research Group và Flexera 2024, Amazon Web Services (AWS) vẫn là nhà cung cấp dịch vụ đám mây hàng đầu, chiếm khoảng 34% thị phần toàn cầu.', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Một số liệu từ Flexera cho thấy 77% các doanh nghiệp đã và đang sử dụng dịch vụ của AWS, phản ánh sự phổ biến của nền tảng này trong cộng đồng doanh nghiệp trên toàn thế giới. AWS được các công ty lớn ưa chuộng trong việc triển khai các dịch vụ đám mây và các sáng kiến kỹ thuật số. Chuyển đổi hệ thống lên nền tảng AWS Cloud mang lại cho doanh nghiệp vô số lợi ích thiết thực:', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Giảm chi phí: AWS giúp giảm đến 66% Tổng Chi phí Sở hữu (TCO) trong 3 năm so với hạ tầng on-prem.', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Tăng hiệu suất và cải thiện hiệu quả vận hành: Các ứng dụng chạy nhanh hơn, hệ thống hoạt động mượt mà hơn. Giảm rủi ro bảo mật:', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Hạ tầng đám mây AWS cung cấp các giải pháp bảo mật tiêu chuẩn quốc tế. Tăng Cường Trải Nghiệm Khách Hàng: Sử dụng AWS cho phép doanh nghiệp tối ưu hóa quy trình và ứng dụng, từ đó cải thiện trải nghiệm khách hàng và thúc đẩy sự hài lòng, dẫn đến tăng trưởng doanh thu.', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Tận dụng tối đa Giá Trị Dữ Liệu: Tạo điều kiện để khai thác giá trị dữ liệu qua phân tích nâng cao, AI và ML, giúp đưa ra quyết định kinh doanh thông minh hơn.', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}, {'page_content': 'Chọn CMC TS để yên tâm trên hành trình lên mây AWS CMC TS là đối tác Advanced Tier Services của AWS và vừa đạt chứng nhận AWS Migration Competency Program (MCP), chứng tỏ khả năng triển khai AWS Cloud Migration với chất lượng cao nhất, được công nhận bởi AWS toàn cầu.', 'date': '2024-10', 'url': 'https://cmcts.com.vn/vi/news/toi-uu-hieu-suat-va-bao-mat-du-lieu-khi-len-may-aws-cung-cmc-ts.html'}]\n"
     ]
    }
   ],
   "source": [
    "chunks=handling_csv('data_for_chunks','tintuc_cmc_ts_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 21:58:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 43\n",
      "lastest date updated: 2024-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "\u001b[32m2024-11-07 21:58:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "\u001b[32m2024-11-07 21:58:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.35it/s]\n",
      "\u001b[32m2024-11-07 21:58:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 21:58:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-07 21:58:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "\u001b[32m2024-11-07 21:58:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 21:58:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 21:58:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 21:58:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "\u001b[32m2024-11-07 21:58:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "\u001b[32m2024-11-07 21:58:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "\u001b[32m2024-11-07 21:58:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\u001b[32m2024-11-07 21:58:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "\u001b[32m2024-11-07 21:58:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "\u001b[32m2024-11-07 21:58:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "\u001b[32m2024-11-07 21:58:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-07 21:58:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 21:58:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n",
      "\u001b[32m2024-11-07 21:58:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\u001b[32m2024-11-07 21:58:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.25it/s]\n",
      "\u001b[32m2024-11-07 21:58:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.35it/s]\n",
      "\u001b[32m2024-11-07 21:58:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\u001b[32m2024-11-07 21:58:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "\u001b[32m2024-11-07 21:58:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "\u001b[32m2024-11-07 21:58:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "\u001b[32m2024-11-07 21:58:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "\u001b[32m2024-11-07 21:58:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "\u001b[32m2024-11-07 21:58:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "\u001b[32m2024-11-07 21:58:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "\u001b[32m2024-11-07 21:58:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "\u001b[32m2024-11-07 21:58:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "\u001b[32m2024-11-07 21:58:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 21:58:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.02it/s]\n",
      "\u001b[32m2024-11-07 21:58:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 21:58:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "\u001b[32m2024-11-07 21:58:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "\u001b[32m2024-11-07 21:58:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 21:58:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 116, triggered by: token limit\n",
      "\u001b[31mTH Group hợp tác với CMC tiên phong ứng dụng AI vào hệ thống quản lý nhân sự 09/10/2024 Ngày 08/10/2024 tại Hà Nội, dự án triển khai Hệ thống quản lý và trích xuất thông tin hồ sơ xin việc thông minh (C-HR) cho TH Group đã chính thức đi vào vận hành.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 190, triggered by: token limit\n",
      "\u001b[32mDự án là minh chứng cho sự tiên phong trong lĩnh vực Chuyển đổi số và Ứng dụng AI vào quản lý nhân sự của TH Group, đồng thời đánh dấu hành trình phát triển hợp tác giữa hai Tập đoàn TH và Tập đoàn CMC, với sự tham gia tư vấn, triển khai của CMC Consulting và viện nghiên cứu CMC ATI. Ra đời năm 2009, Tập đoàn TH đã nhanh chóng trở thành một trong những đơn vị dẫn đầu trong ngành thực phẩm và đồ uống tại Việt Nam.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 123, triggered by: token limit\n",
      "\u001b[34mTrải qua 15 năm phát triển, đạt được nhiều thành tựu, TH Group đặt mục tiêu đến năm 2025, TH sẽ trở thành nhà sản xuất thực phẩm số một ở thị trường Việt Nam về các sản phẩm sạch có nguồn gốc thiên nhiên, xây dựng thành công thương hiệu không chỉ trong nước mà còn trên toàn cầu.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 114, triggered by: token limit\n",
      "\u001b[35mNgoài ra, Tập đoàn TH còn được biết đến là doanh nghiệp có tầm nhìn tiên phong ứng dụng công nghệ cao, chuyển đổi số ngay từ những ngày đầu phát triển, với việc ứng dụng SAP ERP trong hoạt động sản xuất kinh doanh sữa tươi sạch từ năm 2010.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 174, triggered by: 0.41\n",
      "\u001b[31mNăm 2017, TH tiếp tục áp dụng các phân hệ của giải pháp quản trị nguồn nhân lực tiên tiến SAP Success Factors để đẩy mạnh năng lực và năng suất làm việc của toàn Tập đoàn, nâng cao sự hài lòng của nhân viên. Trong quá trình phát triển, quy mô hoạt động của TH Group không ngừng mở rộng, đòi hỏi sự đổi mới và tối ưu hóa trong quản lý nội bộ, đặc biệt là quản lý nhân sự.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 79, triggered by: token limit\n",
      "\u001b[32mBà Trần Thị Quyên, Giám đốc Nhân sự TH Group cũng chia sẻ: TH là một tập đoàn có sức thu hút rất lớn, một năm lượng CV nhận được có khi tới hàng trăm nghìn hồ sơ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 194, triggered by: final split\n",
      "\u001b[34mVới số lượng ứng viên lớn như vậy, sức người và sức máy phải kết hợp cho thật thông minh để chọn được những ứng viên phù hợp nhất, phục vụ cho sự phát triển của tập đoàn. Đối mặt với những thách thức lớn trong việc tuyển dụng và quản lý hồ sơ ứng viên, Tập đoàn TH đã lựa chọn giải pháp C-HR, một phần mềm ứng dụng công nghệ AI do Tập đoàn CMC phát triển để tự động hóa quy trình số hóa dữ liệu CV của ứng viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'TH Group hợp tác với CMC tiên phong ứng dụng AI vào hệ thống quản lý nhân sự 09/10/2024 Ngày 08/10/2024 tại Hà Nội, dự án triển khai Hệ thống quản lý và trích xuất thông tin hồ sơ xin việc thông minh (C-HR) cho TH Group đã chính thức đi vào vận hành.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'Dự án là minh chứng cho sự tiên phong trong lĩnh vực Chuyển đổi số và Ứng dụng AI vào quản lý nhân sự của TH Group, đồng thời đánh dấu hành trình phát triển hợp tác giữa hai Tập đoàn TH và Tập đoàn CMC, với sự tham gia tư vấn, triển khai của CMC Consulting và viện nghiên cứu CMC ATI. Ra đời năm 2009, Tập đoàn TH đã nhanh chóng trở thành một trong những đơn vị dẫn đầu trong ngành thực phẩm và đồ uống tại Việt Nam.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'Trải qua 15 năm phát triển, đạt được nhiều thành tựu, TH Group đặt mục tiêu đến năm 2025, TH sẽ trở thành nhà sản xuất thực phẩm số một ở thị trường Việt Nam về các sản phẩm sạch có nguồn gốc thiên nhiên, xây dựng thành công thương hiệu không chỉ trong nước mà còn trên toàn cầu.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'Ngoài ra, Tập đoàn TH còn được biết đến là doanh nghiệp có tầm nhìn tiên phong ứng dụng công nghệ cao, chuyển đổi số ngay từ những ngày đầu phát triển, với việc ứng dụng SAP ERP trong hoạt động sản xuất kinh doanh sữa tươi sạch từ năm 2010.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'Năm 2017, TH tiếp tục áp dụng các phân hệ của giải pháp quản trị nguồn nhân lực tiên tiến SAP Success Factors để đẩy mạnh năng lực và năng suất làm việc của toàn Tập đoàn, nâng cao sự hài lòng của nhân viên. Trong quá trình phát triển, quy mô hoạt động của TH Group không ngừng mở rộng, đòi hỏi sự đổi mới và tối ưu hóa trong quản lý nội bộ, đặc biệt là quản lý nhân sự.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'Bà Trần Thị Quyên, Giám đốc Nhân sự TH Group cũng chia sẻ: TH là một tập đoàn có sức thu hút rất lớn, một năm lượng CV nhận được có khi tới hàng trăm nghìn hồ sơ.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'Với số lượng ứng viên lớn như vậy, sức người và sức máy phải kết hợp cho thật thông minh để chọn được những ứng viên phù hợp nhất, phục vụ cho sự phát triển của tập đoàn. Đối mặt với những thách thức lớn trong việc tuyển dụng và quản lý hồ sơ ứng viên, Tập đoàn TH đã lựa chọn giải pháp C-HR, một phần mềm ứng dụng công nghệ AI do Tập đoàn CMC phát triển để tự động hóa quy trình số hóa dữ liệu CV của ứng viên.', 'date': '2024-10', 'url': 'https://cmcati.vn/th-group-hop-tac-voi-cmc-tien-phong-ung-dung-ai-vao-he-thong-quan-ly-nhan-su/'}, {'page_content': 'CMC ATI Đồng Hành Với Chiến lược Chuyển đổi AI Toàn Cầu của Tập đoàn CMC 23/09/2024 Lễ công bố chiến lược chuyển đổi AI của Tập đoàn Công nghệ CMC Trong bối cảnh cuộc cách mạng công nghệ toàn cầu đang chuyển dịch mạnh mẽ sang trí tuệ nhân tạo (AI), CMC đã khẳng định vị thế là một trong những tập đoàn công nghệ tiên phong với chiến lược AI-X đầy tham vọng.', 'date': '2024-09', 'url': 'https://cmcati.vn/cmc-ati-dong-hanh-voi-chien-luoc-chuyen-doi-ai-toan-cau-cua-tap-doan-cmc/'}, {'page_content': 'Vào ngày 11/9, CMC lần đầu tiên công bố Chiến lược AI-X tại Hà Nội. Chỉ một tuần sau, vào ngày 18/9, CMC tiếp tục giới thiệu chiến lược này tại Nhật Bản, đánh dấu lần đầu tiên Chiến lược AI-X được công bố trên thị trường quốc tế. CMC công bố Chiến lược AI-X tại Nhật Bản Với thông điệp mạnh mẽ “Enable Your AI-X”, lễ khai trương văn phòng thứ ba của CMC Japan đã được tổ chức trang trọng tại khách sạn Gajoen Tokyo, Nhật Bản;.', 'date': '2024-09', 'url': 'https://cmcati.vn/cmc-ati-dong-hanh-voi-chien-luoc-chuyen-doi-ai-toan-cau-cua-tap-doan-cmc/'}, {'page_content': 'Sự kiện này là minh chứng rõ ràng cho cam kết của Tập đoàn CMC trong việc thúc đẩy Chiến lược “Chuyển đổi AI” toàn cầu giai đoạn 2024-2028. Việc mở văn phòng mới tại Nhật Bản là một bước đi quan trọng trong chuỗi hoạt động nhằm hiện thực hóa chiến lược này.', 'date': '2024-09', 'url': 'https://cmcati.vn/cmc-ati-dong-hanh-voi-chien-luoc-chuyen-doi-ai-toan-cau-cua-tap-doan-cmc/'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunks=handling_csv('data_for_chunks','tintuc_cmc_ati_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 22:00:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 406\n",
      "lastest date updated: 2024-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\u001b[32m2024-11-07 22:00:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.03s/it]\n",
      "\u001b[32m2024-11-07 22:00:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 22:00:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.48s/it]\n",
      "\u001b[32m2024-11-07 22:00:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.13s/it]\n",
      "\u001b[32m2024-11-07 22:00:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n",
      "\u001b[32m2024-11-07 22:00:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.74s/it]\n",
      "\u001b[32m2024-11-07 22:01:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\u001b[32m2024-11-07 22:01:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n",
      "\u001b[32m2024-11-07 22:01:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 22:01:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 22:01:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 22:01:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.06s/it]\n",
      "\u001b[32m2024-11-07 22:01:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:01:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.10s/it]\n",
      "\u001b[32m2024-11-07 22:01:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.88s/it]\n",
      "\u001b[32m2024-11-07 22:01:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 22:01:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n",
      "\u001b[32m2024-11-07 22:01:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.92s/it]\n",
      "\u001b[32m2024-11-07 22:02:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "\u001b[32m2024-11-07 22:02:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.82s/it]\n",
      "\u001b[32m2024-11-07 22:02:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\n",
      "\u001b[32m2024-11-07 22:02:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "\u001b[32m2024-11-07 22:02:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 22:02:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.85s/it]\n",
      "\u001b[32m2024-11-07 22:02:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.63s/it]\n",
      "\u001b[32m2024-11-07 22:02:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n",
      "\u001b[32m2024-11-07 22:02:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.79s/it]\n",
      "\u001b[32m2024-11-07 22:02:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.44s/it]\n",
      "\u001b[32m2024-11-07 22:02:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.41s/it]\n",
      "\u001b[32m2024-11-07 22:03:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\u001b[32m2024-11-07 22:03:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 22:03:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.52s/it]\n",
      "\u001b[32m2024-11-07 22:03:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 22:03:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.87s/it]\n",
      "\u001b[32m2024-11-07 22:03:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.64s/it]\n",
      "\u001b[32m2024-11-07 22:03:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.04s/it]\n",
      "\u001b[32m2024-11-07 22:03:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n",
      "\u001b[32m2024-11-07 22:03:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.22s/it]\n",
      "\u001b[32m2024-11-07 22:03:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  4.00s/it]\n",
      "\u001b[32m2024-11-07 22:03:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.20s/it]\n",
      "\u001b[32m2024-11-07 22:03:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 22:03:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.91s/it]\n",
      "\u001b[32m2024-11-07 22:04:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n",
      "\u001b[32m2024-11-07 22:04:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.87s/it]\n",
      "\u001b[32m2024-11-07 22:04:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "\u001b[32m2024-11-07 22:04:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "\u001b[32m2024-11-07 22:04:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 22:04:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 22:04:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.69s/it]\n",
      "\u001b[32m2024-11-07 22:04:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.64s/it]\n",
      "\u001b[32m2024-11-07 22:04:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.12s/it]\n",
      "\u001b[32m2024-11-07 22:04:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.57s/it]\n",
      "\u001b[32m2024-11-07 22:04:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-07 22:05:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.72s/it]\n",
      "\u001b[32m2024-11-07 22:05:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\u001b[32m2024-11-07 22:05:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "\u001b[32m2024-11-07 22:05:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.57s/it]\n",
      "\u001b[32m2024-11-07 22:05:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.97s/it]\n",
      "\u001b[32m2024-11-07 22:05:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.08s/it]\n",
      "\u001b[32m2024-11-07 22:05:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.24s/it]\n",
      "\u001b[32m2024-11-07 22:05:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.99s/it]\n",
      "\u001b[32m2024-11-07 22:05:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.56s/it]\n",
      "\u001b[32m2024-11-07 22:05:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "\u001b[32m2024-11-07 22:05:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\n",
      "\u001b[32m2024-11-07 22:06:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.24s/it]\n",
      "\u001b[32m2024-11-07 22:06:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.61s/it]\n",
      "\u001b[32m2024-11-07 22:06:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n",
      "\u001b[32m2024-11-07 22:06:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.14s/it]\n",
      "\u001b[32m2024-11-07 22:06:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.35s/it]\n",
      "\u001b[32m2024-11-07 22:06:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n",
      "\u001b[32m2024-11-07 22:06:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n",
      "\u001b[32m2024-11-07 22:06:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.18s/it]\n",
      "\u001b[32m2024-11-07 22:06:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.69s/it]\n",
      "\u001b[32m2024-11-07 22:06:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "\u001b[32m2024-11-07 22:06:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\u001b[32m2024-11-07 22:07:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.32s/it]\n",
      "\u001b[32m2024-11-07 22:07:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.12s/it]\n",
      "\u001b[32m2024-11-07 22:07:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:07:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.44s/it]\n",
      "\u001b[32m2024-11-07 22:07:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.88s/it]\n",
      "\u001b[32m2024-11-07 22:07:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.08s/it]\n",
      "\u001b[32m2024-11-07 22:07:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:07:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.51s/it]\n",
      "\u001b[32m2024-11-07 22:07:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "\u001b[32m2024-11-07 22:07:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.64s/it]\n",
      "\u001b[32m2024-11-07 22:07:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "\u001b[32m2024-11-07 22:07:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "\u001b[32m2024-11-07 22:07:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "\u001b[32m2024-11-07 22:08:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.95s/it]\n",
      "\u001b[32m2024-11-07 22:08:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n",
      "\u001b[32m2024-11-07 22:08:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.45s/it]\n",
      "\u001b[32m2024-11-07 22:08:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n",
      "\u001b[32m2024-11-07 22:08:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 22:08:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.39s/it]\n",
      "\u001b[32m2024-11-07 22:08:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 22:08:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n",
      "\u001b[32m2024-11-07 22:08:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.69s/it]\n",
      "\u001b[32m2024-11-07 22:08:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 22:08:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.18s/it]\n",
      "\u001b[32m2024-11-07 22:08:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.97s/it]\n",
      "\u001b[32m2024-11-07 22:09:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.79s/it]\n",
      "\u001b[32m2024-11-07 22:09:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 22:09:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "\u001b[32m2024-11-07 22:09:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "\u001b[32m2024-11-07 22:09:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "\u001b[32m2024-11-07 22:09:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.03s/it]\n",
      "\u001b[32m2024-11-07 22:09:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.98s/it]\n",
      "\u001b[32m2024-11-07 22:09:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n",
      "\u001b[32m2024-11-07 22:09:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\u001b[32m2024-11-07 22:09:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.57s/it]\n",
      "\u001b[32m2024-11-07 22:09:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "\u001b[32m2024-11-07 22:09:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.08s/it]\n",
      "\u001b[32m2024-11-07 22:09:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\u001b[32m2024-11-07 22:09:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.83s/it]\n",
      "\u001b[32m2024-11-07 22:10:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.87s/it]\n",
      "\u001b[32m2024-11-07 22:10:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  4.00s/it]\n",
      "\u001b[32m2024-11-07 22:10:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n",
      "\u001b[32m2024-11-07 22:10:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.77s/it]\n",
      "\u001b[32m2024-11-07 22:10:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "\u001b[32m2024-11-07 22:10:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "\u001b[32m2024-11-07 22:10:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.16s/it]\n",
      "\u001b[32m2024-11-07 22:10:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.86s/it]\n",
      "\u001b[32m2024-11-07 22:10:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "\u001b[32m2024-11-07 22:10:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.77s/it]\n",
      "\u001b[32m2024-11-07 22:10:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.98s/it]\n",
      "\u001b[32m2024-11-07 22:10:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.46s/it]\n",
      "\u001b[32m2024-11-07 22:11:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.72s/it]\n",
      "\u001b[32m2024-11-07 22:11:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 22:11:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.27s/it]\n",
      "\u001b[32m2024-11-07 22:11:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 22:11:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 22:11:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.67s/it]\n",
      "\u001b[32m2024-11-07 22:11:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 22:11:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.95s/it]\n",
      "\u001b[32m2024-11-07 22:11:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.56s/it]\n",
      "\u001b[32m2024-11-07 22:11:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.71s/it]\n",
      "\u001b[32m2024-11-07 22:12:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "\u001b[32m2024-11-07 22:12:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 22:12:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 22:12:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.15s/it]\n",
      "\u001b[32m2024-11-07 22:12:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.46s/it]\n",
      "\u001b[32m2024-11-07 22:12:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 22:12:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 22:12:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.37s/it]\n",
      "\u001b[32m2024-11-07 22:12:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 22:12:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "\u001b[32m2024-11-07 22:12:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.41s/it]\n",
      "\u001b[32m2024-11-07 22:12:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "\u001b[32m2024-11-07 22:13:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.42s/it]\n",
      "\u001b[32m2024-11-07 22:13:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.64s/it]\n",
      "\u001b[32m2024-11-07 22:13:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n",
      "\u001b[32m2024-11-07 22:13:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.56s/it]\n",
      "\u001b[32m2024-11-07 22:13:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 22:13:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:13:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "\u001b[32m2024-11-07 22:13:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.32s/it]\n",
      "\u001b[32m2024-11-07 22:13:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.44s/it]\n",
      "\u001b[32m2024-11-07 22:13:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 22:14:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 22:14:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "\u001b[32m2024-11-07 22:14:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "\u001b[32m2024-11-07 22:14:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 17/17 [00:22<00:00,  1.35s/it]\n",
      "\u001b[32m2024-11-07 22:14:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:14<00:00,  3.71s/it]\n",
      "\u001b[32m2024-11-07 22:14:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:13<00:00,  3.47s/it]\n",
      "\u001b[32m2024-11-07 22:15:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.11s/it]\n",
      "\u001b[32m2024-11-07 22:15:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:12<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 22:15:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:11<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 22:15:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.37s/it]\n",
      "\u001b[32m2024-11-07 22:15:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.75s/it]\n",
      "\u001b[32m2024-11-07 22:16:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 22:16:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.73s/it]\n",
      "\u001b[32m2024-11-07 22:16:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.12s/it]\n",
      "\u001b[32m2024-11-07 22:16:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.38s/it]\n",
      "\u001b[32m2024-11-07 22:16:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 22:16:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.74s/it]\n",
      "\u001b[32m2024-11-07 22:17:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.50s/it]\n",
      "\u001b[32m2024-11-07 22:17:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.78s/it]\n",
      "\u001b[32m2024-11-07 22:17:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "\u001b[32m2024-11-07 22:17:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.93s/it]\n",
      "\u001b[32m2024-11-07 22:17:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.41s/it]\n",
      "\u001b[32m2024-11-07 22:17:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.17s/it]\n",
      "\u001b[32m2024-11-07 22:17:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.65s/it]\n",
      "\u001b[32m2024-11-07 22:17:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 22:17:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 22:17:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.72s/it]\n",
      "\u001b[32m2024-11-07 22:18:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.94s/it]\n",
      "\u001b[32m2024-11-07 22:18:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 22:18:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 22:18:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.96s/it]\n",
      "\u001b[32m2024-11-07 22:18:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  5.00s/it]\n",
      "\u001b[32m2024-11-07 22:18:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.69s/it]\n",
      "\u001b[32m2024-11-07 22:18:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.80s/it]\n",
      "\u001b[32m2024-11-07 22:18:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:16<00:00,  5.48s/it]\n",
      "\u001b[32m2024-11-07 22:19:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.21s/it]\n",
      "\u001b[32m2024-11-07 22:19:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.61s/it]\n",
      "\u001b[32m2024-11-07 22:19:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.44s/it]\n",
      "\u001b[32m2024-11-07 22:19:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
      "\u001b[32m2024-11-07 22:19:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.22s/it]\n",
      "\u001b[32m2024-11-07 22:19:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.84s/it]\n",
      "\u001b[32m2024-11-07 22:19:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.38s/it]\n",
      "\u001b[32m2024-11-07 22:19:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.25s/it]\n",
      "\u001b[32m2024-11-07 22:20:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "\u001b[32m2024-11-07 22:20:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n",
      "\u001b[32m2024-11-07 22:20:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.33s/it]\n",
      "\u001b[32m2024-11-07 22:20:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n",
      "\u001b[32m2024-11-07 22:20:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n",
      "\u001b[32m2024-11-07 22:20:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.41s/it]\n",
      "\u001b[32m2024-11-07 22:20:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.47s/it]\n",
      "\u001b[32m2024-11-07 22:20:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.56s/it]\n",
      "\u001b[32m2024-11-07 22:21:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.97s/it]\n",
      "\u001b[32m2024-11-07 22:21:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "\u001b[32m2024-11-07 22:21:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.17s/it]\n",
      "\u001b[32m2024-11-07 22:21:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.63s/it]\n",
      "\u001b[32m2024-11-07 22:21:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.07s/it]\n",
      "\u001b[32m2024-11-07 22:21:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.93s/it]\n",
      "\u001b[32m2024-11-07 22:21:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 22:21:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.53s/it]\n",
      "\u001b[32m2024-11-07 22:21:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.48s/it]\n",
      "\u001b[32m2024-11-07 22:22:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.01s/it]\n",
      "\u001b[32m2024-11-07 22:22:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.18s/it]\n",
      "\u001b[32m2024-11-07 22:22:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.55s/it]\n",
      "\u001b[32m2024-11-07 22:22:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.89s/it]\n",
      "\u001b[32m2024-11-07 22:22:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 22:22:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.33s/it]\n",
      "\u001b[32m2024-11-07 22:22:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 13/13 [00:21<00:00,  1.69s/it]\n",
      "\u001b[32m2024-11-07 22:23:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\u001b[32m2024-11-07 22:23:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 22:23:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 22:23:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n",
      "\u001b[32m2024-11-07 22:23:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "\u001b[32m2024-11-07 22:23:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.81s/it]\n",
      "\u001b[32m2024-11-07 22:23:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 22:23:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.06s/it]\n",
      "\u001b[32m2024-11-07 22:23:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.42s/it]\n",
      "\u001b[32m2024-11-07 22:23:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n",
      "\u001b[32m2024-11-07 22:24:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:24:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.63s/it]\n",
      "\u001b[32m2024-11-07 22:24:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n",
      "\u001b[32m2024-11-07 22:24:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\u001b[32m2024-11-07 22:24:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "\u001b[32m2024-11-07 22:24:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 22:24:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\u001b[32m2024-11-07 22:24:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\u001b[32m2024-11-07 22:24:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 22:24:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "\u001b[32m2024-11-07 22:24:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 22:24:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 22:24:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n",
      "\u001b[32m2024-11-07 22:24:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "\u001b[32m2024-11-07 22:24:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 22:24:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 22:24:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 22:25:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 22:25:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "\u001b[32m2024-11-07 22:25:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.01s/it]\n",
      "\u001b[32m2024-11-07 22:25:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n",
      "\u001b[32m2024-11-07 22:25:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "\u001b[32m2024-11-07 22:25:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.98s/it]\n",
      "\u001b[32m2024-11-07 22:25:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.41s/it]\n",
      "\u001b[32m2024-11-07 22:25:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "\u001b[32m2024-11-07 22:25:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\u001b[32m2024-11-07 22:25:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 22:25:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 22:25:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 22:25:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 22:25:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 22:25:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n",
      "\u001b[32m2024-11-07 22:25:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 22:25:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.37s/it]\n",
      "\u001b[32m2024-11-07 22:26:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 22:26:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 22:26:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 22:26:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:26:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "\u001b[32m2024-11-07 22:26:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.19s/it]\n",
      "\u001b[32m2024-11-07 22:26:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\u001b[32m2024-11-07 22:26:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "\u001b[32m2024-11-07 22:26:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.68s/it]\n",
      "\u001b[32m2024-11-07 22:26:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\u001b[32m2024-11-07 22:26:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n",
      "\u001b[32m2024-11-07 22:26:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 22:26:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "\u001b[32m2024-11-07 22:26:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 22:26:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 22:26:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "\u001b[32m2024-11-07 22:26:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "\u001b[32m2024-11-07 22:26:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "\u001b[32m2024-11-07 22:27:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-07 22:27:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "\u001b[32m2024-11-07 22:27:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:27:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 22:27:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:08<00:00,  3.00s/it]\n",
      "\u001b[32m2024-11-07 22:27:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n",
      "\u001b[32m2024-11-07 22:27:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "\u001b[32m2024-11-07 22:27:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 22:27:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.54s/it]\n",
      "\u001b[32m2024-11-07 22:27:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 22:27:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.25s/it]\n",
      "\u001b[32m2024-11-07 22:27:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.96s/it]\n",
      "\u001b[32m2024-11-07 22:27:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.64s/it]\n",
      "\u001b[32m2024-11-07 22:28:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 22:28:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\u001b[32m2024-11-07 22:28:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 22:28:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n",
      "\u001b[32m2024-11-07 22:28:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\u001b[32m2024-11-07 22:28:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 22:28:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 22:28:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\u001b[32m2024-11-07 22:28:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.70s/it]\n",
      "\u001b[32m2024-11-07 22:28:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.37s/it]\n",
      "\u001b[32m2024-11-07 22:28:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.52s/it]\n",
      "\u001b[32m2024-11-07 22:28:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.49s/it]\n",
      "\u001b[32m2024-11-07 22:28:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 17/17 [00:13<00:00,  1.24it/s]\n",
      "\u001b[32m2024-11-07 22:28:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:29:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:07<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 22:29:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.45s/it]\n",
      "\u001b[32m2024-11-07 22:29:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.16s/it]\n",
      "\u001b[32m2024-11-07 22:29:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\u001b[32m2024-11-07 22:29:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 22:29:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\u001b[32m2024-11-07 22:29:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "\u001b[32m2024-11-07 22:29:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 22:29:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\u001b[32m2024-11-07 22:29:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 22:29:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "\u001b[32m2024-11-07 22:29:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.35s/it]\n",
      "\u001b[32m2024-11-07 22:29:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "\u001b[32m2024-11-07 22:30:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 22:30:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 22:30:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "\u001b[32m2024-11-07 22:30:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 22:30:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 22:30:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 22:30:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\u001b[32m2024-11-07 22:30:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.81s/it]\n",
      "\u001b[32m2024-11-07 22:30:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "\u001b[32m2024-11-07 22:30:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "\u001b[32m2024-11-07 22:30:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "\u001b[32m2024-11-07 22:30:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.25s/it]\n",
      "\u001b[32m2024-11-07 22:30:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 22:30:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 22:30:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 22:30:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.87s/it]\n",
      "\u001b[32m2024-11-07 22:30:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 22:30:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "\u001b[32m2024-11-07 22:31:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.42s/it]\n",
      "\u001b[32m2024-11-07 22:31:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.10s/it]\n",
      "\u001b[32m2024-11-07 22:31:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "\u001b[32m2024-11-07 22:31:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.97s/it]\n",
      "\u001b[32m2024-11-07 22:31:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.32s/it]\n",
      "\u001b[32m2024-11-07 22:31:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.24s/it]\n",
      "\u001b[32m2024-11-07 22:31:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 22:31:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.57s/it]\n",
      "\u001b[32m2024-11-07 22:31:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "\u001b[32m2024-11-07 22:31:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.73s/it]\n",
      "\u001b[32m2024-11-07 22:31:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n",
      "\u001b[32m2024-11-07 22:31:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\u001b[32m2024-11-07 22:31:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 22:31:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n",
      "\u001b[32m2024-11-07 22:31:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 22:32:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "\u001b[32m2024-11-07 22:32:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 22:32:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-07 22:32:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "\u001b[32m2024-11-07 22:32:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 22:32:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2024-11-07 22:32:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "\u001b[32m2024-11-07 22:32:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "\u001b[32m2024-11-07 22:32:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "\u001b[32m2024-11-07 22:32:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 22:32:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 22:32:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 22:32:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 22:32:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n",
      "\u001b[32m2024-11-07 22:32:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "\u001b[32m2024-11-07 22:32:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 22:32:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "\u001b[32m2024-11-07 22:32:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 22:32:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.40s/it]\n",
      "\u001b[32m2024-11-07 22:32:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.13s/it]\n",
      "\u001b[32m2024-11-07 22:32:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n",
      "\u001b[32m2024-11-07 22:32:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/it]\n",
      "\u001b[32m2024-11-07 22:32:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.67s/it]\n",
      "\u001b[32m2024-11-07 22:32:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 22:32:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.78s/it]\n",
      "\u001b[32m2024-11-07 22:32:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.34s/it]\n",
      "\u001b[32m2024-11-07 22:32:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 22:32:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\u001b[32m2024-11-07 22:33:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 22:33:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-07 22:33:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "\u001b[32m2024-11-07 22:33:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "\u001b[32m2024-11-07 22:33:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n",
      "\u001b[32m2024-11-07 22:33:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 22:33:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.24s/it]\n",
      "\u001b[32m2024-11-07 22:33:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "\u001b[32m2024-11-07 22:33:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "\u001b[32m2024-11-07 22:33:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\u001b[32m2024-11-07 22:33:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\u001b[32m2024-11-07 22:33:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "\u001b[32m2024-11-07 22:33:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "\u001b[32m2024-11-07 22:33:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-07 22:33:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 22:33:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 22:33:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 197, triggered by: token limit\n",
      "\u001b[31mSinh viên Trường Đại học CMC nắm bắt cơ hội trong ngành công nghiệp bán dẫn – một trong những trụ cột quan trọng của nền kinh tế số Th10 29, 2024 Ngày 28/10 vừa qua, Phòng Công tác sinh viên Trường Đại học CMC đã phối hợp với Công ty Cổ phần Xuất bản Khoa học và Giáo dục Thời đại – TIMES tổ chức thành công buổi tọa đàm mở với chủ đề: “Chiến trường bán dẫn – Vị thế của Việt Nam trong bức tranh toàn cảnh – Cơ hội của sinh viên Gen Z”.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 159, triggered by: 0.35\n",
      "\u001b[32mĐúng với tên chủ đề, buổi tọa đàm nhằm cung cấp cho các bạn sinh viên những kiến thức và thông tin được cập nhật mới nhất về chính sách, nguồn nhân lực của thế giới và Việt Nam về lĩnh vực bán dẫn – một trong những trụ cột quan trọng của nền kinh tế số hiện nay. Buổi tọa đàm có sự tham gia của diễn giả Vũ Trọng Đại – Giám đốc TIMES, TS.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 150, triggered by: 0.37\n",
      "\u001b[34mPhạm Sỹ Thành – Giám đốc trung tâm Nghiên cứu Kinh tế và Chiến lược Trung Quốc (CESS) và TS. Nguyễn Tuệ Anh – Chuyên gia nghiên cứu cao cấp về chính sách công tại Vương Quốc Anh. Về phía Trường Đại học CMC có sự tham dự của ông Lê Anh Tuấn – Phó Giám đốc cùng các cán bộ Phòng Công tác sinh viên và đông đảo các bạn sinh viên.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 153, triggered by: 0.35\n",
      "\u001b[35mQua phần trình bày tham luận của diễn giả TS. Phạm Sỹ Thành  và TS. Nguyễn Tuệ Anh, sinh viên đã có cơ hội tiếp cận những phân tích sâu sắc về tình hình phát triển ngành bán dẫn trên thế giới, tiềm năng và thách thức cho Việt Nam, cũng như vai trò của chính sách và chiến lược trong việc phát triển nguồn nhân lực chất lượng cao.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 198, triggered by: 0.39\n",
      "\u001b[31mNhững chia sẻ và góc nhìn từ các diễn giả đã giúp sinh viên hiểu rõ hơn về các xu hướng công nghệ, sự cạnh tranh trong ngành, và cách thức Việt Nam có thể tận dụng cơ hội để vươn lên thành một mắt xích quan trọng trong chuỗi cung ứng bán dẫn toàn cầu. Đồng thời, các bạn cũng được thỏa sức tìm hiểu, hỏi đáp và giao lưu với các diễn giả về vấn đề mình quan tâm tới lĩnh vực đầy tiềm năng này.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 186, triggered by: token limit\n",
      "\u001b[32mBuổi tọa đàm khép lại trong không khí tràn đầy hứng khởi, nhờ những chia sẻ và giải đáp vô cùng tâm huyết từ các vị diễn giả. Thay mặt ban tổ chức, xin gửi lời cảm ơn chân thành đến các vị diễn giả Vũ Trọng Đại, TS. Phạm Sỹ Thành và TS. Nguyễn Tuệ Anh đã mang đến cho sinh viên không chỉ kiến thức sâu rộng mà còn những góc nhìn quý báu về tương lai ngành bán dẫn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 126, triggered by: 0.31\n",
      "\u001b[34mHy vọng rằng những thông tin và kinh nghiệm thực tiễn được chia sẻ từ buổi tọa đàm sẽ là hành trang hữu ích cho các bạn sinh viên trong tương lai, tham gia nghiên cứu và đóng góp vào sự phát triển của ngành bán dẫn Việt Nam. Chúc cho cuốn sách “Chiến trường bán dẫn” của NXB.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 51, triggered by: 0.15\n",
      "\u001b[35mTIMES sẽ lan tỏa hơn nữa tới các độc giả quan tâm không chỉ ở Việt Nam mà còn trên thế giới. Xem thêm:\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 61, triggered by: final split\n",
      "\u001b[31mBộ trưởng Nguyễn Mạnh Hùng: CMC có thể làm tốt về AI để trở thành công ty AI toàn cầu, góp sức đưa Việt Nam vào kỷ nguyên mới\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'Sinh viên Trường Đại học CMC nắm bắt cơ hội trong ngành công nghiệp bán dẫn – một trong những trụ cột quan trọng của nền kinh tế số Th10 29, 2024 Ngày 28/10 vừa qua, Phòng Công tác sinh viên Trường Đại học CMC đã phối hợp với Công ty Cổ phần Xuất bản Khoa học và Giáo dục Thời đại – TIMES tổ chức thành công buổi tọa đàm mở với chủ đề: “Chiến trường bán dẫn – Vị thế của Việt Nam trong bức tranh toàn cảnh – Cơ hội của sinh viên Gen Z”.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Đúng với tên chủ đề, buổi tọa đàm nhằm cung cấp cho các bạn sinh viên những kiến thức và thông tin được cập nhật mới nhất về chính sách, nguồn nhân lực của thế giới và Việt Nam về lĩnh vực bán dẫn – một trong những trụ cột quan trọng của nền kinh tế số hiện nay. Buổi tọa đàm có sự tham gia của diễn giả Vũ Trọng Đại – Giám đốc TIMES, TS.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Phạm Sỹ Thành – Giám đốc trung tâm Nghiên cứu Kinh tế và Chiến lược Trung Quốc (CESS) và TS. Nguyễn Tuệ Anh – Chuyên gia nghiên cứu cao cấp về chính sách công tại Vương Quốc Anh. Về phía Trường Đại học CMC có sự tham dự của ông Lê Anh Tuấn – Phó Giám đốc cùng các cán bộ Phòng Công tác sinh viên và đông đảo các bạn sinh viên.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Qua phần trình bày tham luận của diễn giả TS. Phạm Sỹ Thành  và TS. Nguyễn Tuệ Anh, sinh viên đã có cơ hội tiếp cận những phân tích sâu sắc về tình hình phát triển ngành bán dẫn trên thế giới, tiềm năng và thách thức cho Việt Nam, cũng như vai trò của chính sách và chiến lược trong việc phát triển nguồn nhân lực chất lượng cao.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Những chia sẻ và góc nhìn từ các diễn giả đã giúp sinh viên hiểu rõ hơn về các xu hướng công nghệ, sự cạnh tranh trong ngành, và cách thức Việt Nam có thể tận dụng cơ hội để vươn lên thành một mắt xích quan trọng trong chuỗi cung ứng bán dẫn toàn cầu. Đồng thời, các bạn cũng được thỏa sức tìm hiểu, hỏi đáp và giao lưu với các diễn giả về vấn đề mình quan tâm tới lĩnh vực đầy tiềm năng này.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Buổi tọa đàm khép lại trong không khí tràn đầy hứng khởi, nhờ những chia sẻ và giải đáp vô cùng tâm huyết từ các vị diễn giả. Thay mặt ban tổ chức, xin gửi lời cảm ơn chân thành đến các vị diễn giả Vũ Trọng Đại, TS. Phạm Sỹ Thành và TS. Nguyễn Tuệ Anh đã mang đến cho sinh viên không chỉ kiến thức sâu rộng mà còn những góc nhìn quý báu về tương lai ngành bán dẫn.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Hy vọng rằng những thông tin và kinh nghiệm thực tiễn được chia sẻ từ buổi tọa đàm sẽ là hành trang hữu ích cho các bạn sinh viên trong tương lai, tham gia nghiên cứu và đóng góp vào sự phát triển của ngành bán dẫn Việt Nam. Chúc cho cuốn sách “Chiến trường bán dẫn” của NXB.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'TIMES sẽ lan tỏa hơn nữa tới các độc giả quan tâm không chỉ ở Việt Nam mà còn trên thế giới. Xem thêm:', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Bộ trưởng Nguyễn Mạnh Hùng: CMC có thể làm tốt về AI để trở thành công ty AI toàn cầu, góp sức đưa Việt Nam vào kỷ nguyên mới', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/sinh-vien-truong-dai-hoc-cmc-nam-bat-co-hoi-trong-nganh-cong-nghiep-ban-dan-mot-trong-nhung-tru-cot-quan-trong-cua-nen-kinh-te-so/'}, {'page_content': 'Bộ trưởng Nguyễn Mạnh Hùng: CMC có thể làm tốt về AI để trở thành công ty AI toàn cầu, góp sức đưa Việt Nam vào kỷ nguyên mới Th10 28, 2024 Chiều ngày 25/10 vừa qua, Bộ trưởng Bộ Thông tin và Truyền thông (TT&TT) Nguyễn Mạnh Hùng chủ trì buổi làm việc của Bộ với lãnh đạo, cán bộ chủ chốt của Tập đoàn Công nghệ CMC.', 'date': '2024-10', 'url': 'https://cmc-u.edu.vn/bo-truong-nguyen-manh-hung-cmc-co-the-lam-tot-ve-ai-de-tro-thanh-cong-ty-ai-toan-cau-gop-suc-dua-viet-nam-vao-ky-nguyen-moi/'}]\n"
     ]
    }
   ],
   "source": [
    "chunks=handling_csv('data_for_chunks','tintuc_cmc_uni_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-07 22:35:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of documents: 992\n",
      "lastest date updated: 2024-10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "\u001b[32m2024-11-07 22:35:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.78s/it]\n",
      "\u001b[32m2024-11-07 22:35:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "\u001b[32m2024-11-07 22:35:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.92s/it]\n",
      "\u001b[32m2024-11-07 22:35:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-07 22:35:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.33it/s]\n",
      "\u001b[32m2024-11-07 22:35:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 22:35:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n",
      "\u001b[32m2024-11-07 22:35:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 22:35:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 22:35:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.88s/it]\n",
      "\u001b[32m2024-11-07 22:35:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.38s/it]\n",
      "\u001b[32m2024-11-07 22:36:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.73s/it]\n",
      "\u001b[32m2024-11-07 22:36:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n",
      "\u001b[32m2024-11-07 22:36:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\u001b[32m2024-11-07 22:36:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 22:36:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n",
      "\u001b[32m2024-11-07 22:36:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "\u001b[32m2024-11-07 22:36:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "\u001b[32m2024-11-07 22:36:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.75s/it]\n",
      "\u001b[32m2024-11-07 22:36:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "\u001b[32m2024-11-07 22:36:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.78s/it]\n",
      "\u001b[32m2024-11-07 22:36:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.31s/it]\n",
      "\u001b[32m2024-11-07 22:36:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.37s/it]\n",
      "\u001b[32m2024-11-07 22:36:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "\u001b[32m2024-11-07 22:36:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:36:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 22:36:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.42it/s]\n",
      "\u001b[32m2024-11-07 22:36:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\u001b[32m2024-11-07 22:37:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "\u001b[32m2024-11-07 22:37:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 22:37:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-07 22:37:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "\u001b[32m2024-11-07 22:37:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.32s/it]\n",
      "\u001b[32m2024-11-07 22:37:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\u001b[32m2024-11-07 22:37:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.83s/it]\n",
      "\u001b[32m2024-11-07 22:37:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\u001b[32m2024-11-07 22:37:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "\u001b[32m2024-11-07 22:37:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "\u001b[32m2024-11-07 22:37:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\u001b[32m2024-11-07 22:37:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "\u001b[32m2024-11-07 22:37:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "\u001b[32m2024-11-07 22:37:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "\u001b[32m2024-11-07 22:37:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.28s/it]\n",
      "\u001b[32m2024-11-07 22:37:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.55s/it]\n",
      "\u001b[32m2024-11-07 22:37:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 22:37:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 22:37:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n",
      "\u001b[32m2024-11-07 22:37:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.58s/it]\n",
      "\u001b[32m2024-11-07 22:38:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\u001b[32m2024-11-07 22:38:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 22:38:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "\u001b[32m2024-11-07 22:38:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.94s/it]\n",
      "\u001b[32m2024-11-07 22:38:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "\u001b[32m2024-11-07 22:38:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.98s/it]\n",
      "\u001b[32m2024-11-07 22:38:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.24s/it]\n",
      "\u001b[32m2024-11-07 22:38:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\u001b[32m2024-11-07 22:38:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.43s/it]\n",
      "\u001b[32m2024-11-07 22:38:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 22:38:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 22:38:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.71s/it]\n",
      "\u001b[32m2024-11-07 22:38:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n",
      "\u001b[32m2024-11-07 22:38:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "\u001b[32m2024-11-07 22:38:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 22:38:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 22:38:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.02s/it]\n",
      "\u001b[32m2024-11-07 22:38:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 22:38:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.06s/it]\n",
      "\u001b[32m2024-11-07 22:38:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.79s/it]\n",
      "\u001b[32m2024-11-07 22:39:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "\u001b[32m2024-11-07 22:39:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n",
      "\u001b[32m2024-11-07 22:39:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "\u001b[32m2024-11-07 22:39:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 22:39:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.67s/it]\n",
      "\u001b[32m2024-11-07 22:39:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 22:39:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 22:39:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\u001b[32m2024-11-07 22:39:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "\u001b[32m2024-11-07 22:39:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.13s/it]\n",
      "\u001b[32m2024-11-07 22:39:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "\u001b[32m2024-11-07 22:39:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.38s/it]\n",
      "\u001b[32m2024-11-07 22:39:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.87s/it]\n",
      "\u001b[32m2024-11-07 22:39:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 22:39:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.27s/it]\n",
      "\u001b[32m2024-11-07 22:40:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "\u001b[32m2024-11-07 22:40:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.05s/it]\n",
      "\u001b[32m2024-11-07 22:40:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.05s/it]\n",
      "\u001b[32m2024-11-07 22:40:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.08s/it]\n",
      "\u001b[32m2024-11-07 22:40:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 22:40:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.49s/it]\n",
      "\u001b[32m2024-11-07 22:40:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n",
      "\u001b[32m2024-11-07 22:40:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 22:40:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 22:40:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "\u001b[32m2024-11-07 22:40:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 22:40:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.37s/it]\n",
      "\u001b[32m2024-11-07 22:40:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.51s/it]\n",
      "\u001b[32m2024-11-07 22:40:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.66s/it]\n",
      "\u001b[32m2024-11-07 22:40:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.04s/it]\n",
      "\u001b[32m2024-11-07 22:41:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.57s/it]\n",
      "\u001b[32m2024-11-07 22:41:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.53s/it]\n",
      "\u001b[32m2024-11-07 22:41:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.11s/it]\n",
      "\u001b[32m2024-11-07 22:41:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.96s/it]\n",
      "\u001b[32m2024-11-07 22:41:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 22:41:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.20s/it]\n",
      "\u001b[32m2024-11-07 22:41:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\u001b[32m2024-11-07 22:41:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "\u001b[32m2024-11-07 22:41:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 22:41:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.95s/it]\n",
      "\u001b[32m2024-11-07 22:41:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.47s/it]\n",
      "\u001b[32m2024-11-07 22:41:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\n",
      "\u001b[32m2024-11-07 22:41:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n",
      "\u001b[32m2024-11-07 22:42:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\u001b[32m2024-11-07 22:42:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 22:42:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
      "\u001b[32m2024-11-07 22:42:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 22:42:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n",
      "\u001b[32m2024-11-07 22:42:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.14s/it]\n",
      "\u001b[32m2024-11-07 22:42:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.63s/it]\n",
      "\u001b[32m2024-11-07 22:42:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n",
      "\u001b[32m2024-11-07 22:42:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.62s/it]\n",
      "\u001b[32m2024-11-07 22:42:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "\u001b[32m2024-11-07 22:42:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\u001b[32m2024-11-07 22:42:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.80s/it]\n",
      "\u001b[32m2024-11-07 22:42:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.36s/it]\n",
      "\u001b[32m2024-11-07 22:42:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.35s/it]\n",
      "\u001b[32m2024-11-07 22:43:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "\u001b[32m2024-11-07 22:43:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.59s/it]\n",
      "\u001b[32m2024-11-07 22:43:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.81s/it]\n",
      "\u001b[32m2024-11-07 22:43:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 22:43:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.47s/it]\n",
      "\u001b[32m2024-11-07 22:43:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 22:43:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "\u001b[32m2024-11-07 22:43:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 22:43:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.66it/s]\n",
      "\u001b[32m2024-11-07 22:43:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "\u001b[32m2024-11-07 22:43:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n",
      "\u001b[32m2024-11-07 22:43:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\u001b[32m2024-11-07 22:43:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "\u001b[32m2024-11-07 22:43:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "\u001b[32m2024-11-07 22:43:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "\u001b[32m2024-11-07 22:43:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 22:43:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "\u001b[32m2024-11-07 22:43:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "\u001b[32m2024-11-07 22:44:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.96s/it]\n",
      "\u001b[32m2024-11-07 22:44:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.55s/it]\n",
      "\u001b[32m2024-11-07 22:44:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:44:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:44:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 22:44:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:44:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 22:44:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
      "\u001b[32m2024-11-07 22:44:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "\u001b[32m2024-11-07 22:44:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\u001b[32m2024-11-07 22:44:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.14s/it]\n",
      "\u001b[32m2024-11-07 22:44:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 22:44:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "\u001b[32m2024-11-07 22:44:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.98s/it]\n",
      "\u001b[32m2024-11-07 22:44:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "\u001b[32m2024-11-07 22:44:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.37s/it]\n",
      "\u001b[32m2024-11-07 22:44:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 22:45:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "\u001b[32m2024-11-07 22:45:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.39s/it]\n",
      "\u001b[32m2024-11-07 22:45:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 22:45:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\u001b[32m2024-11-07 22:45:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\u001b[32m2024-11-07 22:45:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.21s/it]\n",
      "\u001b[32m2024-11-07 22:45:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "\u001b[32m2024-11-07 22:45:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\u001b[32m2024-11-07 22:45:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:45:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.64s/it]\n",
      "\u001b[32m2024-11-07 22:45:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.27s/it]\n",
      "\u001b[32m2024-11-07 22:45:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\u001b[32m2024-11-07 22:45:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.34s/it]\n",
      "\u001b[32m2024-11-07 22:45:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 22:45:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 22:46:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "\u001b[32m2024-11-07 22:46:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "\u001b[32m2024-11-07 22:46:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\u001b[32m2024-11-07 22:46:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "\u001b[32m2024-11-07 22:46:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "\u001b[32m2024-11-07 22:46:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\u001b[32m2024-11-07 22:46:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 22:46:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 22:46:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 22:46:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "\u001b[32m2024-11-07 22:46:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 22:46:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\u001b[32m2024-11-07 22:46:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\u001b[32m2024-11-07 22:46:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.97it/s]\n",
      "\u001b[32m2024-11-07 22:46:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "\u001b[32m2024-11-07 22:46:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "\u001b[32m2024-11-07 22:46:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.82it/s]\n",
      "\u001b[32m2024-11-07 22:46:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 22:46:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 22:46:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.20s/it]\n",
      "\u001b[32m2024-11-07 22:46:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\u001b[32m2024-11-07 22:46:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-07 22:46:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\u001b[32m2024-11-07 22:46:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.77s/it]\n",
      "\u001b[32m2024-11-07 22:46:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 22:47:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\u001b[32m2024-11-07 22:47:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-07 22:47:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\u001b[32m2024-11-07 22:47:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\u001b[32m2024-11-07 22:47:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\u001b[32m2024-11-07 22:47:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.03s/it]\n",
      "\u001b[32m2024-11-07 22:47:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "\u001b[32m2024-11-07 22:47:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-07 22:47:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "\u001b[32m2024-11-07 22:47:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-07 22:47:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 22:47:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 22:47:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.09s/it]\n",
      "\u001b[32m2024-11-07 22:47:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\u001b[32m2024-11-07 22:47:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 22:47:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.59s/it]\n",
      "\u001b[32m2024-11-07 22:47:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.33s/it]\n",
      "\u001b[32m2024-11-07 22:47:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 22:47:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\u001b[32m2024-11-07 22:47:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\u001b[32m2024-11-07 22:48:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 22:48:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2024-11-07 22:48:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 22:48:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\u001b[32m2024-11-07 22:48:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 22:48:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\u001b[32m2024-11-07 22:48:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 22:48:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 22:48:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "\u001b[32m2024-11-07 22:48:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 22:48:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.27s/it]\n",
      "\u001b[32m2024-11-07 22:48:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 22:48:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 22:48:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.76s/it]\n",
      "\u001b[32m2024-11-07 22:48:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "\u001b[32m2024-11-07 22:48:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.25s/it]\n",
      "\u001b[32m2024-11-07 22:48:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n",
      "\u001b[32m2024-11-07 22:48:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "\u001b[32m2024-11-07 22:48:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "\u001b[32m2024-11-07 22:48:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 22:48:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "\u001b[32m2024-11-07 22:48:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.53s/it]\n",
      "\u001b[32m2024-11-07 22:49:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:49:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.28s/it]\n",
      "\u001b[32m2024-11-07 22:49:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-07 22:49:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\u001b[32m2024-11-07 22:49:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:49:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\n",
      "\u001b[32m2024-11-07 22:49:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "\u001b[32m2024-11-07 22:49:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "\u001b[32m2024-11-07 22:49:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-07 22:49:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "\u001b[32m2024-11-07 22:49:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\u001b[32m2024-11-07 22:49:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 22:49:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-07 22:49:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\u001b[32m2024-11-07 22:49:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n",
      "\u001b[32m2024-11-07 22:49:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "\u001b[32m2024-11-07 22:49:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.39s/it]\n",
      "\u001b[32m2024-11-07 22:49:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 22:49:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.87s/it]\n",
      "\u001b[32m2024-11-07 22:49:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 22:49:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 22:49:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\u001b[32m2024-11-07 22:49:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 22:50:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "\u001b[32m2024-11-07 22:50:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "\u001b[32m2024-11-07 22:50:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-07 22:50:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "\u001b[32m2024-11-07 22:50:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "\u001b[32m2024-11-07 22:50:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.48s/it]\n",
      "\u001b[32m2024-11-07 22:50:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 22:50:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\u001b[32m2024-11-07 22:50:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 22:50:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "\u001b[32m2024-11-07 22:50:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.00s/it]\n",
      "\u001b[32m2024-11-07 22:50:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\u001b[32m2024-11-07 22:50:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "\u001b[32m2024-11-07 22:50:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "\u001b[32m2024-11-07 22:50:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.69s/it]\n",
      "\u001b[32m2024-11-07 22:50:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n",
      "\u001b[32m2024-11-07 22:50:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "\u001b[32m2024-11-07 22:50:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 22:50:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 22:50:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n",
      "\u001b[32m2024-11-07 22:50:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "\u001b[32m2024-11-07 22:50:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\u001b[32m2024-11-07 22:50:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.05s/it]\n",
      "\u001b[32m2024-11-07 22:50:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 22:51:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 22:51:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.26s/it]\n",
      "\u001b[32m2024-11-07 22:51:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n",
      "\u001b[32m2024-11-07 22:51:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-07 22:51:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\n",
      "\u001b[32m2024-11-07 22:51:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "\u001b[32m2024-11-07 22:51:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2024-11-07 22:51:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 22:51:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.42s/it]\n",
      "\u001b[32m2024-11-07 22:51:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "\u001b[32m2024-11-07 22:51:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "\u001b[32m2024-11-07 22:51:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 22:51:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 22:51:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 22:51:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.65s/it]\n",
      "\u001b[32m2024-11-07 22:51:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\u001b[32m2024-11-07 22:51:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 22:51:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.23s/it]\n",
      "\u001b[32m2024-11-07 22:51:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 22:51:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.83s/it]\n",
      "\u001b[32m2024-11-07 22:51:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\u001b[32m2024-11-07 22:51:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "\u001b[32m2024-11-07 22:52:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 22:52:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 22:52:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\u001b[32m2024-11-07 22:52:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\u001b[32m2024-11-07 22:52:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-07 22:52:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\u001b[32m2024-11-07 22:52:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-07 22:52:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 22:52:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\u001b[32m2024-11-07 22:52:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "\u001b[32m2024-11-07 22:52:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "\u001b[32m2024-11-07 22:52:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "\u001b[32m2024-11-07 22:52:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\u001b[32m2024-11-07 22:52:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\u001b[32m2024-11-07 22:52:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.54s/it]\n",
      "\u001b[32m2024-11-07 22:52:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.09s/it]\n",
      "\u001b[32m2024-11-07 22:52:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "\u001b[32m2024-11-07 22:52:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\u001b[32m2024-11-07 22:52:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 22:52:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\u001b[32m2024-11-07 22:52:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "\u001b[32m2024-11-07 22:52:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 22:52:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "\u001b[32m2024-11-07 22:52:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.40s/it]\n",
      "\u001b[32m2024-11-07 22:52:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 22:52:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.65s/it]\n",
      "\u001b[32m2024-11-07 22:53:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\u001b[32m2024-11-07 22:53:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\u001b[32m2024-11-07 22:53:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "\u001b[32m2024-11-07 22:53:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\u001b[32m2024-11-07 22:53:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "\u001b[32m2024-11-07 22:53:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 22:53:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "\u001b[32m2024-11-07 22:53:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\u001b[32m2024-11-07 22:53:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n",
      "\u001b[32m2024-11-07 22:53:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 22:53:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.94s/it]\n",
      "\u001b[32m2024-11-07 22:53:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.69s/it]\n",
      "\u001b[32m2024-11-07 22:53:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\u001b[32m2024-11-07 22:53:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.58it/s]\n",
      "\u001b[32m2024-11-07 22:53:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.32s/it]\n",
      "\u001b[32m2024-11-07 22:53:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "\u001b[32m2024-11-07 22:53:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "\u001b[32m2024-11-07 22:53:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.67s/it]\n",
      "\u001b[32m2024-11-07 22:53:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "\u001b[32m2024-11-07 22:53:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 22:53:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\u001b[32m2024-11-07 22:53:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "\u001b[32m2024-11-07 22:53:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 22:53:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 22:54:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.74s/it]\n",
      "\u001b[32m2024-11-07 22:54:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "\u001b[32m2024-11-07 22:54:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-07 22:54:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "\u001b[32m2024-11-07 22:54:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "\u001b[32m2024-11-07 22:54:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "\u001b[32m2024-11-07 22:54:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\u001b[32m2024-11-07 22:54:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 22:54:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.39it/s]\n",
      "\u001b[32m2024-11-07 22:54:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "\u001b[32m2024-11-07 22:54:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "\u001b[32m2024-11-07 22:54:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "\u001b[32m2024-11-07 22:54:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "\u001b[32m2024-11-07 22:54:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "\u001b[32m2024-11-07 22:54:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "\u001b[32m2024-11-07 22:54:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 22:54:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "\u001b[32m2024-11-07 22:54:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "\u001b[32m2024-11-07 22:54:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "\u001b[32m2024-11-07 22:54:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "\u001b[32m2024-11-07 22:54:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 22:54:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "\u001b[32m2024-11-07 22:54:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-07 22:54:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.55s/it]\n",
      "\u001b[32m2024-11-07 22:54:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n",
      "\u001b[32m2024-11-07 22:54:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "\u001b[32m2024-11-07 22:54:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.48it/s]\n",
      "\u001b[32m2024-11-07 22:54:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-07 22:54:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n",
      "\u001b[32m2024-11-07 22:54:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 22:54:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 22:54:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "\u001b[32m2024-11-07 22:54:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 22:54:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-07 22:54:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "\u001b[32m2024-11-07 22:54:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "\u001b[32m2024-11-07 22:54:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-07 22:54:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 22:54:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "\u001b[32m2024-11-07 22:54:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.97s/it]\n",
      "\u001b[32m2024-11-07 22:55:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n",
      "\u001b[32m2024-11-07 22:55:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\u001b[32m2024-11-07 22:55:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.18it/s]\n",
      "\u001b[32m2024-11-07 22:55:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\u001b[32m2024-11-07 22:55:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-07 22:55:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\u001b[32m2024-11-07 22:55:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 22:55:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.46s/it]\n",
      "\u001b[32m2024-11-07 22:55:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "\u001b[32m2024-11-07 22:55:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.95s/it]\n",
      "\u001b[32m2024-11-07 22:55:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-07 22:55:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.99it/s]\n",
      "\u001b[32m2024-11-07 22:55:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n",
      "\u001b[32m2024-11-07 22:55:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]\n",
      "\u001b[32m2024-11-07 22:55:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "\u001b[32m2024-11-07 22:55:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "\u001b[32m2024-11-07 22:55:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\u001b[32m2024-11-07 22:55:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "\u001b[32m2024-11-07 22:55:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.85s/it]\n",
      "\u001b[32m2024-11-07 22:55:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "\u001b[32m2024-11-07 22:55:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 22:55:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "\u001b[32m2024-11-07 22:55:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 22:55:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 22:55:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.41s/it]\n",
      "\u001b[32m2024-11-07 22:55:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "\u001b[32m2024-11-07 22:55:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\u001b[32m2024-11-07 22:55:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\u001b[32m2024-11-07 22:56:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-07 22:56:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 22:56:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "\u001b[32m2024-11-07 22:56:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-07 22:56:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "\u001b[32m2024-11-07 22:56:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "\u001b[32m2024-11-07 22:56:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "\u001b[32m2024-11-07 22:56:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 22:56:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "\u001b[32m2024-11-07 22:56:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.95s/it]\n",
      "\u001b[32m2024-11-07 22:56:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 22:56:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.40s/it]\n",
      "\u001b[32m2024-11-07 22:56:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\u001b[32m2024-11-07 22:56:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "\u001b[32m2024-11-07 22:56:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-07 22:56:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "\u001b[32m2024-11-07 22:56:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "\u001b[32m2024-11-07 22:56:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.37s/it]\n",
      "\u001b[32m2024-11-07 22:56:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.93s/it]\n",
      "\u001b[32m2024-11-07 22:56:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 22:56:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "\u001b[32m2024-11-07 22:56:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "\u001b[32m2024-11-07 22:56:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 22:56:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\u001b[32m2024-11-07 22:56:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-07 22:56:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "\u001b[32m2024-11-07 22:56:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "\u001b[32m2024-11-07 22:57:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "\u001b[32m2024-11-07 22:57:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.86s/it]\n",
      "\u001b[32m2024-11-07 22:57:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "\u001b[32m2024-11-07 22:57:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.73s/it]\n",
      "\u001b[32m2024-11-07 22:57:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.06it/s]\n",
      "\u001b[32m2024-11-07 22:57:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.19s/it]\n",
      "\u001b[32m2024-11-07 22:57:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "\u001b[32m2024-11-07 22:57:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "\u001b[32m2024-11-07 22:57:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\u001b[32m2024-11-07 22:57:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.81s/it]\n",
      "\u001b[32m2024-11-07 22:57:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.98s/it]\n",
      "\u001b[32m2024-11-07 22:57:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 22:57:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "\u001b[32m2024-11-07 22:57:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "\u001b[32m2024-11-07 22:57:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "\u001b[32m2024-11-07 22:57:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "\u001b[32m2024-11-07 22:57:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "\u001b[32m2024-11-07 22:57:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.22s/it]\n",
      "\u001b[32m2024-11-07 22:57:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "\u001b[32m2024-11-07 22:57:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "\u001b[32m2024-11-07 22:57:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "\u001b[32m2024-11-07 22:57:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\u001b[32m2024-11-07 22:57:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.30s/it]\n",
      "\u001b[32m2024-11-07 22:57:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.76s/it]\n",
      "\u001b[32m2024-11-07 22:58:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 22:58:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.24s/it]\n",
      "\u001b[32m2024-11-07 22:58:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "\u001b[32m2024-11-07 22:58:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n",
      "\u001b[32m2024-11-07 22:58:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\u001b[32m2024-11-07 22:58:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "\u001b[32m2024-11-07 22:58:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\u001b[32m2024-11-07 22:58:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.14s/it]\n",
      "\u001b[32m2024-11-07 22:58:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.08s/it]\n",
      "\u001b[32m2024-11-07 22:58:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 22:58:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-07 22:58:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.09s/it]\n",
      "\u001b[32m2024-11-07 22:58:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.65s/it]\n",
      "\u001b[32m2024-11-07 22:58:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.60it/s]\n",
      "\u001b[32m2024-11-07 22:58:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 22:58:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "\u001b[32m2024-11-07 22:58:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "\u001b[32m2024-11-07 22:58:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\u001b[32m2024-11-07 22:58:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.12s/it]\n",
      "\u001b[32m2024-11-07 22:59:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\u001b[32m2024-11-07 22:59:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n",
      "\u001b[32m2024-11-07 22:59:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "\u001b[32m2024-11-07 22:59:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-07 22:59:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n",
      "\u001b[32m2024-11-07 22:59:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 22:59:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-07 22:59:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "\u001b[32m2024-11-07 22:59:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.91s/it]\n",
      "\u001b[32m2024-11-07 22:59:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "\u001b[32m2024-11-07 22:59:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 22:59:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 22:59:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.36s/it]\n",
      "\u001b[32m2024-11-07 22:59:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\u001b[32m2024-11-07 22:59:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.98s/it]\n",
      "\u001b[32m2024-11-07 22:59:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.31s/it]\n",
      "\u001b[32m2024-11-07 22:59:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n",
      "\u001b[32m2024-11-07 22:59:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "\u001b[32m2024-11-07 22:59:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 22:59:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "\u001b[32m2024-11-07 22:59:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n",
      "\u001b[32m2024-11-07 22:59:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n",
      "\u001b[32m2024-11-07 22:59:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 22:59:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.63s/it]\n",
      "\u001b[32m2024-11-07 22:59:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.01s/it]\n",
      "\u001b[32m2024-11-07 23:00:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "\u001b[32m2024-11-07 23:00:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "\u001b[32m2024-11-07 23:00:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.00s/it]\n",
      "\u001b[32m2024-11-07 23:00:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.37s/it]\n",
      "\u001b[32m2024-11-07 23:00:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n",
      "\u001b[32m2024-11-07 23:00:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.69s/it]\n",
      "\u001b[32m2024-11-07 23:00:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "\u001b[32m2024-11-07 23:00:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "\u001b[32m2024-11-07 23:00:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "\u001b[32m2024-11-07 23:00:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 23:00:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.58s/it]\n",
      "\u001b[32m2024-11-07 23:00:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.86s/it]\n",
      "\u001b[32m2024-11-07 23:00:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\u001b[32m2024-11-07 23:00:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "\u001b[32m2024-11-07 23:00:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n",
      "\u001b[32m2024-11-07 23:00:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "\u001b[32m2024-11-07 23:00:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "\u001b[32m2024-11-07 23:00:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "\u001b[32m2024-11-07 23:00:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 23:00:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "\u001b[32m2024-11-07 23:00:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 23:00:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 23:00:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "\u001b[32m2024-11-07 23:00:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.47s/it]\n",
      "\u001b[32m2024-11-07 23:00:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 23:00:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-07 23:00:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.66s/it]\n",
      "\u001b[32m2024-11-07 23:00:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.00s/it]\n",
      "\u001b[32m2024-11-07 23:01:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "\u001b[32m2024-11-07 23:01:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "\u001b[32m2024-11-07 23:01:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n",
      "\u001b[32m2024-11-07 23:01:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "\u001b[32m2024-11-07 23:01:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.87s/it]\n",
      "\u001b[32m2024-11-07 23:01:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.33s/it]\n",
      "\u001b[32m2024-11-07 23:01:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 23:01:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.09s/it]\n",
      "\u001b[32m2024-11-07 23:01:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-07 23:01:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "\u001b[32m2024-11-07 23:01:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\u001b[32m2024-11-07 23:01:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "\u001b[32m2024-11-07 23:01:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "\u001b[32m2024-11-07 23:01:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.84s/it]\n",
      "\u001b[32m2024-11-07 23:01:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "\u001b[32m2024-11-07 23:01:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "\u001b[32m2024-11-07 23:01:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.62s/it]\n",
      "\u001b[32m2024-11-07 23:01:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\u001b[32m2024-11-07 23:01:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "\u001b[32m2024-11-07 23:01:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n",
      "\u001b[32m2024-11-07 23:01:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\u001b[32m2024-11-07 23:01:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.63it/s]\n",
      "\u001b[32m2024-11-07 23:01:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "\u001b[32m2024-11-07 23:01:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "\u001b[32m2024-11-07 23:01:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "\u001b[32m2024-11-07 23:01:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n",
      "\u001b[32m2024-11-07 23:01:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.27s/it]\n",
      "\u001b[32m2024-11-07 23:01:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n",
      "\u001b[32m2024-11-07 23:01:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "\u001b[32m2024-11-07 23:01:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "\u001b[32m2024-11-07 23:01:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "\u001b[32m2024-11-07 23:01:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\u001b[32m2024-11-07 23:02:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "\u001b[32m2024-11-07 23:02:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n",
      "\u001b[32m2024-11-07 23:02:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "\u001b[32m2024-11-07 23:02:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "\u001b[32m2024-11-07 23:02:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.84s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "\u001b[32m2024-11-07 23:02:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "\u001b[32m2024-11-07 23:02:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 23:02:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.73it/s]\n",
      "\u001b[32m2024-11-07 23:02:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 23:02:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]\n",
      "\u001b[32m2024-11-07 23:02:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\u001b[32m2024-11-07 23:02:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.60it/s]\n",
      "\u001b[32m2024-11-07 23:02:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.63s/it]\n",
      "\u001b[32m2024-11-07 23:02:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 23:02:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "\u001b[32m2024-11-07 23:02:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.66it/s]\n",
      "\u001b[32m2024-11-07 23:02:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.45s/it]\n",
      "\u001b[32m2024-11-07 23:02:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.90s/it]\n",
      "\u001b[32m2024-11-07 23:02:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.11s/it]\n",
      "\u001b[32m2024-11-07 23:02:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.34s/it]\n",
      "\u001b[32m2024-11-07 23:02:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.12s/it]\n",
      "\u001b[32m2024-11-07 23:02:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "\u001b[32m2024-11-07 23:02:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.03s/it]\n",
      "\u001b[32m2024-11-07 23:02:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.19it/s]\n",
      "\u001b[32m2024-11-07 23:02:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 23:02:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n",
      "\u001b[32m2024-11-07 23:02:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "\u001b[32m2024-11-07 23:02:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.77s/it]\n",
      "\u001b[32m2024-11-07 23:02:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.44s/it]\n",
      "\u001b[32m2024-11-07 23:03:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "\u001b[32m2024-11-07 23:03:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.16s/it]\n",
      "\u001b[32m2024-11-07 23:03:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.14s/it]\n",
      "\u001b[32m2024-11-07 23:03:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "\u001b[32m2024-11-07 23:03:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "\u001b[32m2024-11-07 23:03:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.94s/it]\n",
      "\u001b[32m2024-11-07 23:03:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "\u001b[32m2024-11-07 23:03:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 23:03:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "\u001b[32m2024-11-07 23:03:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "\u001b[32m2024-11-07 23:03:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\u001b[32m2024-11-07 23:03:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "\u001b[32m2024-11-07 23:03:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "\u001b[32m2024-11-07 23:03:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 23:03:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "\u001b[32m2024-11-07 23:03:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "\u001b[32m2024-11-07 23:03:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.16it/s]\n",
      "\u001b[32m2024-11-07 23:03:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n",
      "\u001b[32m2024-11-07 23:03:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.14it/s]\n",
      "\u001b[32m2024-11-07 23:03:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-07 23:03:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.37s/it]\n",
      "\u001b[32m2024-11-07 23:03:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\u001b[32m2024-11-07 23:03:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "\u001b[32m2024-11-07 23:03:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "\u001b[32m2024-11-07 23:03:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 23:03:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "\u001b[32m2024-11-07 23:03:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "\u001b[32m2024-11-07 23:03:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "\u001b[32m2024-11-07 23:03:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "\u001b[32m2024-11-07 23:04:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.13s/it]\n",
      "\u001b[32m2024-11-07 23:04:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n",
      "\u001b[32m2024-11-07 23:04:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n",
      "\u001b[32m2024-11-07 23:04:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "\u001b[32m2024-11-07 23:04:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\u001b[32m2024-11-07 23:04:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "\u001b[32m2024-11-07 23:04:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.57s/it]\n",
      "\u001b[32m2024-11-07 23:04:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "\u001b[32m2024-11-07 23:04:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "\u001b[32m2024-11-07 23:04:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "\u001b[32m2024-11-07 23:04:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.13s/it]\n",
      "\u001b[32m2024-11-07 23:04:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.16it/s]\n",
      "\u001b[32m2024-11-07 23:04:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.41s/it]\n",
      "\u001b[32m2024-11-07 23:04:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n",
      "\u001b[32m2024-11-07 23:04:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
      "\u001b[32m2024-11-07 23:04:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "\u001b[32m2024-11-07 23:04:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]\n",
      "\u001b[32m2024-11-07 23:04:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "\u001b[32m2024-11-07 23:04:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.60it/s]\n",
      "\u001b[32m2024-11-07 23:04:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 23:04:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
      "\u001b[32m2024-11-07 23:04:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 23:04:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "\u001b[32m2024-11-07 23:04:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "\u001b[32m2024-11-07 23:04:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.21it/s]\n",
      "\u001b[32m2024-11-07 23:04:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "\u001b[32m2024-11-07 23:04:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.19s/it]\n",
      "\u001b[32m2024-11-07 23:04:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 23:04:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.22s/it]\n",
      "\u001b[32m2024-11-07 23:04:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 23:04:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "\u001b[32m2024-11-07 23:05:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.71s/it]\n",
      "\u001b[32m2024-11-07 23:05:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n",
      "\u001b[32m2024-11-07 23:05:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "\u001b[32m2024-11-07 23:05:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n",
      "\u001b[32m2024-11-07 23:05:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\u001b[32m2024-11-07 23:05:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n",
      "\u001b[32m2024-11-07 23:05:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.95it/s]\n",
      "\u001b[32m2024-11-07 23:05:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "\u001b[32m2024-11-07 23:05:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\u001b[32m2024-11-07 23:05:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 23:05:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.38it/s]\n",
      "\u001b[32m2024-11-07 23:05:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 23:05:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "\u001b[32m2024-11-07 23:05:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\u001b[32m2024-11-07 23:05:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 23:05:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "\u001b[32m2024-11-07 23:05:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "\u001b[32m2024-11-07 23:05:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.05it/s]\n",
      "\u001b[32m2024-11-07 23:05:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.47it/s]\n",
      "\u001b[32m2024-11-07 23:05:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.35s/it]\n",
      "\u001b[32m2024-11-07 23:05:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-07 23:05:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.81s/it]\n",
      "\u001b[32m2024-11-07 23:05:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.20it/s]\n",
      "\u001b[32m2024-11-07 23:05:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "\u001b[32m2024-11-07 23:05:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 23:05:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n",
      "\u001b[32m2024-11-07 23:05:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "\u001b[32m2024-11-07 23:05:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\u001b[32m2024-11-07 23:05:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n",
      "\u001b[32m2024-11-07 23:05:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "\u001b[32m2024-11-07 23:05:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.02s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "\u001b[32m2024-11-07 23:05:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "\u001b[32m2024-11-07 23:05:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "\u001b[32m2024-11-07 23:05:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.01it/s]\n",
      "\u001b[32m2024-11-07 23:05:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.98s/it]\n",
      "\u001b[32m2024-11-07 23:06:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "\u001b[32m2024-11-07 23:06:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n",
      "\u001b[32m2024-11-07 23:06:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-07 23:06:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-07 23:06:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n",
      "\u001b[32m2024-11-07 23:06:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "\u001b[32m2024-11-07 23:06:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "\u001b[32m2024-11-07 23:06:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "\u001b[32m2024-11-07 23:06:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.25s/it]\n",
      "\u001b[32m2024-11-07 23:06:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "\u001b[32m2024-11-07 23:06:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "\u001b[32m2024-11-07 23:06:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 23:06:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "\u001b[32m2024-11-07 23:06:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n",
      "\u001b[32m2024-11-07 23:06:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
      "\u001b[32m2024-11-07 23:06:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.33s/it]\n",
      "\u001b[32m2024-11-07 23:06:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.14s/it]\n",
      "\u001b[32m2024-11-07 23:06:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 23:06:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "\u001b[32m2024-11-07 23:06:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-07 23:06:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 23:06:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "\u001b[32m2024-11-07 23:06:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.22s/it]\n",
      "\u001b[32m2024-11-07 23:06:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n",
      "\u001b[32m2024-11-07 23:06:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.94it/s]\n",
      "\u001b[32m2024-11-07 23:06:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\u001b[32m2024-11-07 23:06:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.57s/it]\n",
      "\u001b[32m2024-11-07 23:06:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.87s/it]\n",
      "\u001b[32m2024-11-07 23:07:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]\n",
      "\u001b[32m2024-11-07 23:07:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "\u001b[32m2024-11-07 23:07:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "\u001b[32m2024-11-07 23:07:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.61s/it]\n",
      "\u001b[32m2024-11-07 23:07:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "\u001b[32m2024-11-07 23:07:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "\u001b[32m2024-11-07 23:07:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.75s/it]\n",
      "\u001b[32m2024-11-07 23:07:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "\u001b[32m2024-11-07 23:07:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.44s/it]\n",
      "\u001b[32m2024-11-07 23:07:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.29s/it]\n",
      "\u001b[32m2024-11-07 23:07:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.80s/it]\n",
      "\u001b[32m2024-11-07 23:07:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.85s/it]\n",
      "\u001b[32m2024-11-07 23:07:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.91s/it]\n",
      "\u001b[32m2024-11-07 23:07:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 23:07:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\u001b[32m2024-11-07 23:07:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\n",
      "\u001b[32m2024-11-07 23:07:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.84s/it]\n",
      "\u001b[32m2024-11-07 23:07:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:15<00:00,  5.06s/it]\n",
      "\u001b[32m2024-11-07 23:07:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "\u001b[32m2024-11-07 23:07:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.40it/s]\n",
      "\u001b[32m2024-11-07 23:07:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "\u001b[32m2024-11-07 23:07:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "\u001b[32m2024-11-07 23:07:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.30s/it]\n",
      "\u001b[32m2024-11-07 23:08:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.68it/s]\n",
      "\u001b[32m2024-11-07 23:08:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 23:08:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "\u001b[32m2024-11-07 23:08:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.11it/s]\n",
      "\u001b[32m2024-11-07 23:08:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.34s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.65it/s]\n",
      "\u001b[32m2024-11-07 23:08:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-07 23:08:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.07s/it]\n",
      "\u001b[32m2024-11-07 23:08:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.34it/s]\n",
      "\u001b[32m2024-11-07 23:08:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\n",
      "\u001b[32m2024-11-07 23:08:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 23:08:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n",
      "\u001b[32m2024-11-07 23:08:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.74s/it]\n",
      "\u001b[32m2024-11-07 23:08:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.56s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.42it/s]\n",
      "\u001b[32m2024-11-07 23:08:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "\u001b[32m2024-11-07 23:08:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.59it/s]\n",
      "\u001b[32m2024-11-07 23:08:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "\u001b[32m2024-11-07 23:08:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "\u001b[32m2024-11-07 23:08:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "\u001b[32m2024-11-07 23:08:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "\u001b[32m2024-11-07 23:08:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.57it/s]\n",
      "\u001b[32m2024-11-07 23:08:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n",
      "\u001b[32m2024-11-07 23:08:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "\u001b[32m2024-11-07 23:08:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "\u001b[32m2024-11-07 23:08:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.31it/s]\n",
      "\u001b[32m2024-11-07 23:08:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.34it/s]\n",
      "\u001b[32m2024-11-07 23:08:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "\u001b[32m2024-11-07 23:08:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.09it/s]\n",
      "\u001b[32m2024-11-07 23:08:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.39it/s]\n",
      "\u001b[32m2024-11-07 23:08:41 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "\u001b[32m2024-11-07 23:08:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.48it/s]\n",
      "\u001b[32m2024-11-07 23:08:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "\u001b[32m2024-11-07 23:08:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
      "\u001b[32m2024-11-07 23:08:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.95s/it]\n",
      "\u001b[32m2024-11-07 23:08:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 23:08:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n",
      "\u001b[32m2024-11-07 23:08:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "\u001b[32m2024-11-07 23:08:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.72it/s]\n",
      "\u001b[32m2024-11-07 23:08:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n",
      "\u001b[32m2024-11-07 23:08:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\u001b[32m2024-11-07 23:08:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 23:08:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "\u001b[32m2024-11-07 23:08:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\u001b[32m2024-11-07 23:08:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.09it/s]\n",
      "\u001b[32m2024-11-07 23:08:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\u001b[32m2024-11-07 23:09:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.64it/s]\n",
      "\u001b[32m2024-11-07 23:09:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "\u001b[32m2024-11-07 23:09:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n",
      "\u001b[32m2024-11-07 23:09:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "\u001b[32m2024-11-07 23:09:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.29it/s]\n",
      "\u001b[32m2024-11-07 23:09:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.35s/it]\n",
      "\u001b[32m2024-11-07 23:09:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "\u001b[32m2024-11-07 23:09:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "\u001b[32m2024-11-07 23:09:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n",
      "\u001b[32m2024-11-07 23:09:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.62it/s]\n",
      "\u001b[32m2024-11-07 23:09:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n",
      "\u001b[32m2024-11-07 23:09:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.10it/s]\n",
      "\u001b[32m2024-11-07 23:09:18 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-07 23:09:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
      "\u001b[32m2024-11-07 23:09:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\n",
      "\u001b[32m2024-11-07 23:09:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "\u001b[32m2024-11-07 23:09:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n",
      "\u001b[32m2024-11-07 23:09:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n",
      "\u001b[32m2024-11-07 23:09:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "\u001b[32m2024-11-07 23:09:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "\u001b[32m2024-11-07 23:09:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "\u001b[32m2024-11-07 23:09:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\u001b[32m2024-11-07 23:09:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "\u001b[32m2024-11-07 23:09:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n",
      "\u001b[32m2024-11-07 23:09:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 23:09:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.62s/it]\n",
      "\u001b[32m2024-11-07 23:09:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "\u001b[32m2024-11-07 23:09:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "\u001b[32m2024-11-07 23:09:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.82s/it]\n",
      "\u001b[32m2024-11-07 23:09:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 23:09:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n",
      "\u001b[32m2024-11-07 23:09:43 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.36it/s]\n",
      "\u001b[32m2024-11-07 23:09:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.18s/it]\n",
      "\u001b[32m2024-11-07 23:09:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "\u001b[32m2024-11-07 23:09:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "\u001b[32m2024-11-07 23:09:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 23:09:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 23:09:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n",
      "\u001b[32m2024-11-07 23:09:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.66it/s]\n",
      "\u001b[32m2024-11-07 23:09:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n",
      "\u001b[32m2024-11-07 23:09:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "\u001b[32m2024-11-07 23:09:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-07 23:09:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n",
      "\u001b[32m2024-11-07 23:09:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "\u001b[32m2024-11-07 23:09:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.01it/s]\n",
      "\u001b[32m2024-11-07 23:09:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.12it/s]\n",
      "\u001b[32m2024-11-07 23:10:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.79s/it]\n",
      "\u001b[32m2024-11-07 23:10:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n",
      "\u001b[32m2024-11-07 23:10:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\u001b[32m2024-11-07 23:10:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.23it/s]\n",
      "\u001b[32m2024-11-07 23:10:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "\u001b[32m2024-11-07 23:10:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]\n",
      "\u001b[32m2024-11-07 23:10:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n",
      "\u001b[32m2024-11-07 23:10:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "\u001b[32m2024-11-07 23:10:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "\u001b[32m2024-11-07 23:10:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.43it/s]\n",
      "\u001b[32m2024-11-07 23:10:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-07 23:10:13 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\n",
      "\u001b[32m2024-11-07 23:10:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.48s/it]\n",
      "\u001b[32m2024-11-07 23:10:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 23:10:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.11s/it]\n",
      "\u001b[32m2024-11-07 23:10:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "\u001b[32m2024-11-07 23:10:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "\u001b[32m2024-11-07 23:10:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "\u001b[32m2024-11-07 23:10:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "\u001b[32m2024-11-07 23:10:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.02s/it]\n",
      "\u001b[32m2024-11-07 23:10:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\n",
      "\u001b[32m2024-11-07 23:10:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 23:10:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-07 23:10:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n",
      "\u001b[32m2024-11-07 23:10:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "\u001b[32m2024-11-07 23:10:35 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      "\u001b[32m2024-11-07 23:10:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.99s/it]\n",
      "\u001b[32m2024-11-07 23:10:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n",
      "\u001b[32m2024-11-07 23:10:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.56it/s]\n",
      "\u001b[32m2024-11-07 23:10:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "\u001b[32m2024-11-07 23:10:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\u001b[32m2024-11-07 23:10:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.01s/it]\n",
      "\u001b[32m2024-11-07 23:10:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n",
      "\u001b[32m2024-11-07 23:10:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n",
      "\u001b[32m2024-11-07 23:10:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "\u001b[32m2024-11-07 23:10:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.07s/it]\n",
      "\u001b[32m2024-11-07 23:10:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-07 23:10:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.43s/it]\n",
      "\u001b[32m2024-11-07 23:10:59 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n",
      "\u001b[32m2024-11-07 23:11:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "\u001b[32m2024-11-07 23:11:03 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "\u001b[32m2024-11-07 23:11:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 23:11:07 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n",
      "\u001b[32m2024-11-07 23:11:08 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.52s/it]\n",
      "\u001b[32m2024-11-07 23:11:10 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "\u001b[32m2024-11-07 23:11:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.81s/it]\n",
      "\u001b[32m2024-11-07 23:11:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "\u001b[32m2024-11-07 23:11:21 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.26it/s]\n",
      "\u001b[32m2024-11-07 23:11:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "\u001b[32m2024-11-07 23:11:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n",
      "\u001b[32m2024-11-07 23:11:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "\u001b[32m2024-11-07 23:11:26 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "\u001b[32m2024-11-07 23:11:27 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "\u001b[32m2024-11-07 23:11:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "\u001b[32m2024-11-07 23:11:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n",
      "\u001b[32m2024-11-07 23:11:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.48s/it]\n",
      "\u001b[32m2024-11-07 23:11:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "\u001b[32m2024-11-07 23:11:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 23:11:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.86s/it]\n",
      "\u001b[32m2024-11-07 23:11:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.25it/s]\n",
      "\u001b[32m2024-11-07 23:11:37 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "\u001b[32m2024-11-07 23:11:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "\u001b[32m2024-11-07 23:11:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "\u001b[32m2024-11-07 23:11:40 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.67s/it]\n",
      "\u001b[32m2024-11-07 23:11:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n",
      "\u001b[32m2024-11-07 23:11:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/it]\n",
      "\u001b[32m2024-11-07 23:11:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.32it/s]\n",
      "\u001b[32m2024-11-07 23:11:45 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "\u001b[32m2024-11-07 23:11:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.34it/s]\n",
      "\u001b[32m2024-11-07 23:11:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.46it/s]\n",
      "\u001b[32m2024-11-07 23:11:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n",
      "\u001b[32m2024-11-07 23:11:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "\u001b[32m2024-11-07 23:11:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n",
      "\u001b[32m2024-11-07 23:11:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "\u001b[32m2024-11-07 23:11:49 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "\u001b[32m2024-11-07 23:11:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.49s/it]\n",
      "\u001b[32m2024-11-07 23:11:52 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n",
      "\u001b[32m2024-11-07 23:11:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "\u001b[32m2024-11-07 23:11:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "\u001b[32m2024-11-07 23:11:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n",
      "\u001b[32m2024-11-07 23:11:56 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "\u001b[32m2024-11-07 23:11:57 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "\u001b[32m2024-11-07 23:12:00 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.20s/it]\n",
      "\u001b[32m2024-11-07 23:12:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.29it/s]\n",
      "\u001b[32m2024-11-07 23:12:05 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n",
      "\u001b[32m2024-11-07 23:12:06 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.14s/it]\n",
      "\u001b[32m2024-11-07 23:12:09 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.84s/it]\n",
      "\u001b[32m2024-11-07 23:12:12 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n",
      "\u001b[32m2024-11-07 23:12:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\u001b[32m2024-11-07 23:12:17 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.61s/it]\n",
      "\u001b[32m2024-11-07 23:12:19 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "\u001b[32m2024-11-07 23:12:22 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "\u001b[32m2024-11-07 23:12:23 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.93s/it]\n",
      "\u001b[32m2024-11-07 23:12:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\u001b[32m2024-11-07 23:12:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/it]\n",
      "\u001b[32m2024-11-07 23:12:31 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.33s/it]\n",
      "\u001b[32m2024-11-07 23:12:33 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "\u001b[32m2024-11-07 23:12:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.51s/it]\n",
      "\u001b[32m2024-11-07 23:12:39 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n",
      "\u001b[32m2024-11-07 23:12:44 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.32s/it]\n",
      "\u001b[32m2024-11-07 23:12:47 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.47s/it]\n",
      "\u001b[32m2024-11-07 23:12:53 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n",
      "\u001b[32m2024-11-07 23:12:54 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\u001b[32m2024-11-07 23:12:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.18s/it]\n",
      "\u001b[32m2024-11-07 23:13:01 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "\u001b[32m2024-11-07 23:13:02 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "\u001b[32m2024-11-07 23:13:04 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.49s/it]\n",
      "\u001b[32m2024-11-07 23:13:11 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.58s/it]\n",
      "\u001b[32m2024-11-07 23:13:14 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n",
      "\u001b[32m2024-11-07 23:13:15 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "\u001b[32m2024-11-07 23:13:16 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.90s/it]\n",
      "\u001b[32m2024-11-07 23:13:20 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\u001b[32m2024-11-07 23:13:24 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.43s/it]\n",
      "\u001b[32m2024-11-07 23:13:28 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "\u001b[32m2024-11-07 23:13:30 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.89s/it]\n",
      "\u001b[32m2024-11-07 23:13:34 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.76s/it]\n",
      "\u001b[32m2024-11-07 23:13:38 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n",
      "\u001b[32m2024-11-07 23:13:42 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "\u001b[32m2024-11-07 23:13:46 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n",
      "\u001b[32m2024-11-07 23:13:48 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1, tokens 138, triggered by: 0.44\n",
      "\u001b[31mCMC kiện toàn bộ máy lãnh đạo sẵn sàng cho chiến lược chuyển đổi AI 14 October 2024 Ngày 14/10, tại Hà Nội, Tập đoàn Công nghệ CMC đã tổ chức buổi lễ bổ nhiệm Giám đốc Chiến lược và Giám đốc Công nghệ, đánh dấu một bước tiến quan trọng trong chiến lược chuyển đổi AI của tập đoàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 2, tokens 158, triggered by: token limit\n",
      "\u001b[32mSự kiện này không chỉ khẳng định cam kết của CMC trong việc duy trì vị thế tiên phong mà còn thể hiện quyết tâm tối ưu hóa nguồn lực để đáp ứng những thách thức của thị trường công nghệ thông tin hiện nay. Ảnh 1: Ông Nguyễn Trung Chính - Chủ tịch HĐQT/ Chủ tịch Điều hành Tập đoàn Công nghệ CMC phát biểu tại buổi lễ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 3, tokens 234, triggered by: token limit\n",
      "\u001b[34mPhát biểu tại buổi lễ, ông Nguyễn Trung Chính - Chủ tịch HĐQT/ Chủ tịch Điều hành Tập đoàn Công nghệ CMC đã nhấn mạnh sự phát triển nhanh chóng và cạnh tranh ngày càng gay gắt của thị trường đòi hỏi các tập đoàn công nghệ như CMC cần một chiến lược toàn diện và đặc biệt là các chiến lược về công nghệ để duy trì vị thế tiên phong và đạt được các mục tiêu tăng trưởng bền vững. “Lễ bổ nhiệm ngày hôm nay đánh dấu bước tiến quan trọng trong hành trình phát triển của Tập đoàn CMC.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 4, tokens 164, triggered by: token limit\n",
      "\u001b[35mVới việc bổ sung các vị trí lãnh đạo chủ chốt, Ban lãnh đạo của Tập đoàn giờ đây đã có 8 thành viên, đảm bảo sự đầy đủ và kiện toàn bộ máy quản trị cấp cao. Điều này khẳng định rằng Tập đoàn CMC đang xây dựng một đội ngũ lãnh đạo mạnh mẽ, với sự chuyên môn hoá và phân công rõ ràng”, Chủ tịch CMC chia sẻ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 5, tokens 167, triggered by: token limit\n",
      "\u001b[31mĐể hỗ trợ Ban lãnh đạo Tập đoàn CMC và các Đơn vị thành viên trong công tác định hướng triển khai các chiến lược kinh doanh, tối ưu hóa nguồn lực và dẫn dắt các sáng kiến về công nghệ và đổi mới sản phẩm, Ban lãnh đạo Tập đoàn CMC đã quyết định bổ nhiệm ông Đặng Tùng Sơn làm Giám đốc Chiến lược và ông Đặng Văn Tú giữ chức vụ Giám đốc Công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 6, tokens 183, triggered by: -0.03\n",
      "\u001b[32mChủ tịch CMC trao quyết định bổ nhiệm cho ông Đặng Tùng Sơn giữ vị trí làm Giám đốc Chiến lược Ông Đặng Tùng Sơn tốt nghiệp Thạc sĩ chuyên ngành Viễn thông tại Đại học Pierre và Marie Curie (Pháp) và Quản trị Kinh doanh (MBA) tại Viện Công nghệ Châu Á (Thái Lan). Ông Sơn đã có 20 kinh nghiệm làm việc tại nhiều vị trí quan trọng tại EVN Telecom, Hiệp hội Internet Việt Nam,.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 7, tokens 172, triggered by: 0.21\n",
      "\u001b[34m. .và trong đó có hơn 12 năm làm việc và đồng hành cùng CMC Telecom. Trong thời gian giữ vai trò Phó Tổng Giám đốc – Giám đốc Kinh doanh và Marketing tại CMC Telecom, ông Đặng Tùng Sơn đã điều hành toàn bộ hoạt động Kinh doanh Marketing của CMC Telecom đạt kết quả tốt trong điều kiện kinh tế gặp nhiều khó khăn, suy thoái, thị trường cạnh tranh nhiều đối thủ trong nước và quốc tế.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 8, tokens 151, triggered by: 0.39\n",
      "\u001b[35mNgoài ra, các hoạt động phát triển thị trường, quảng bá hình ảnh, kết nối đối tác,. . . của CMC Telecom nói riêng và Tập đoàn CMC nói chung ngày càng được mở rộng, nâng tầm vị thế và đạt được nhiều kết quả tích cực. Ông đã được vinh danh với giải thưởng Lãnh đạo xuất sắc cấp Tập đoàn năm tài chính 2018.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 9, tokens 50, triggered by: 0.29\n",
      "\u001b[31mChủ tịch CMC trao quyết định bổ nhiệm cho ông Đặng Văn Tú giữ chức vụ Giám đốc Công nghệ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 10, tokens 145, triggered by: 0.41\n",
      "\u001b[32mÔng  Đặng Văn Tú tốt nghiệp Thạc sĩ chuyên ngành Chuyển đổi số tại Trường Quản lý IÉSEG (Pháp) và Thạc sĩ chuyên ngành Quản trị Kinh doanh tại Đại học Paris I Panthéon-Sorbonne (Pháp). Ông Tú đã có 17 năm kinh nghiệm làm việc tại nhiều công ty công nghệ lớn như HPT Việt Nam, Microsoft, Softline International,.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 11, tokens 163, triggered by: 0.35\n",
      "\u001b[34m. .Giai đoạn 2021-2022, ông Đặng Văn Tú giữ chức vụ Giám đốc Khối Giải pháp Cloud của CMC TS và ghi dấu ấn với nhiều kết quả hoạt động tích cực. Sau đó, ông Đặng Văn Tú có thời gian du học tại Paris (Pháp) để nâng cao trình độ, hoàn tất bằng Thạc sĩ và quay trở lại giữ chức vụ Giám đốc Công nghệ của CMC Global.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 12, tokens 107, triggered by: token limit\n",
      "\u001b[35mBộ máy Ban điều hành Tập đoàn Công nghệ CMC tháng 10/2024 Trước đó, vào ngày 14/08/2024, CMC đã tổ chức lễ bổ nhiệm ông Nguyễn Minh Tuệ giữ vị trí Giám đốc Tài chính Tập đoàn.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 13, tokens 123, triggered by: token limit\n",
      "\u001b[31mChủ tịch Nguyễn Trung Chính đã bày tỏ sự tin tưởng vào khả năng và kinh nghiệm của ông Minh Tuệ, người đã gắn bó với CMC gần 5 năm và có những đóng góp đáng kể trong các vai trò trước đây như Phó Ban Tài chính Kế hoạch và Trưởng ban Kiểm toán Nội bộ.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 14, tokens 195, triggered by: 0.40\n",
      "\u001b[32mChủ tịch kỳ vọng tân CFO sẽ đưa quản trị tài chính lên môi trường số, xây dựng hệ thống cơ sở dữ liệu tài chính vững chắc và tạo ra những báo cáo có giá trị tư vấn, giúp hệ thống quản trị của Tập đoàn hiệu quả hơn. Đáp lại sự tin tưởng đó, ông Minh Tuệ cam kết sẽ nỗ lực hết mình để góp phần vào sự phát triển của CMC. Chủ tịch CMC trao quyết định bổ nhiệm cho ông Nguyễn Minh Tuệ\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 15, tokens 179, triggered by: 0.39\n",
      "\u001b[34mVới đội ngũ lãnh đạo đã được hoàn thiện, Tập đoàn CMC giờ đây sẵn sàng hướng tới những mục tiêu chiến lược lớn lao hơn, tận dụng tối đa nguồn lực và sức mạnh từ từng thành viên để đưa công ty vào giai đoạn phát triển mới. Đây là yếu tố thiết yếu để đưa Tập đoàn vượt qua những thử thách, đồng thời củng cố nền tảng vững chắc cho những bước tiến đột phá trong tương lai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 16, tokens 152, triggered by: token limit\n",
      "\u001b[35mĐể hỗ trợ cho những thay đổi này, CMC đã công bố chiến lược chuyển đổi AI mang tên \"Enable Your AI-X\". Lễ công bố diễn ra tháng 9 tại Hà Nội, nhấn mạnh rằng việc xây dựng một chiến lược chuyển đổi AI không chỉ đơn thuần là tích hợp công nghệ, mà còn là một tầm nhìn dài hạn với lộ trình phát triển bền vững và toàn diện.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 17, tokens 185, triggered by: 0.44\n",
      "\u001b[31mChủ tịch Nguyễn Trung Chính nhận định rằng \"AI Transformation (AI-X)\" là quá trình ứng dụng công nghệ AI để thay đổi tổng thể cách thức hoạt động trong mọi lĩnh vực của xã hội. Mục tiêu của chiến lược này là tận dụng tiềm năng của công nghệ AI để đổi mới sáng tạo, cải tiến hiệu suất, gia tăng giá trị và tạo ra nền kinh tế số, với cam kết trách nhiệm và đạo đức nhằm nâng cao chất lượng cuộc sống\".\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 18, tokens 193, triggered by: 0.34\n",
      "\u001b[32mCMC cam kết cung cấp các giải pháp AI tiên tiến và cá nhân hóa, phù hợp với nhu cầu của từng doanh nghiệp. Thông qua các giải pháp này, doanh nghiệp có thể nâng cao hiệu quả quản lý, tăng cường khả năng cạnh tranh và mở rộng quy mô hoạt động bền vững. \"Enable Your AI-X\" không chỉ là một khẩu hiệu, mà là lời cam kết của CMC trong việc hỗ trợ khách hàng khai thác tối đa tiềm năng của AI, biến những ý tưởng sáng tạo thành hiện thực.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Split 19, tokens 175, triggered by: final split\n",
      "\u001b[34mBan lãnh đạo CMC tin tưởng rằng với những kỹ năng và kinh nghiệm dày dặn của mình, ông Đặng Tùng Sơn, ông Đặng Văn Tú và ông Nguyễn Minh Tuệ sẽ đóng góp tích cực vào sự phát triển của Tập đoàn. CMC kỳ vọng rằng chiến lược chuyển đổi AI sẽ được triển khai hiệu quả, mở rộng cơ hội và nâng cao vị thế trên thị trường công nghệ trong tương lai.\u001b[0m\n",
      "----------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "[{'page_content': 'CMC kiện toàn bộ máy lãnh đạo sẵn sàng cho chiến lược chuyển đổi AI 14 October 2024 Ngày 14/10, tại Hà Nội, Tập đoàn Công nghệ CMC đã tổ chức buổi lễ bổ nhiệm Giám đốc Chiến lược và Giám đốc Công nghệ, đánh dấu một bước tiến quan trọng trong chiến lược chuyển đổi AI của tập đoàn.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Sự kiện này không chỉ khẳng định cam kết của CMC trong việc duy trì vị thế tiên phong mà còn thể hiện quyết tâm tối ưu hóa nguồn lực để đáp ứng những thách thức của thị trường công nghệ thông tin hiện nay. Ảnh 1: Ông Nguyễn Trung Chính - Chủ tịch HĐQT/ Chủ tịch Điều hành Tập đoàn Công nghệ CMC phát biểu tại buổi lễ.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Phát biểu tại buổi lễ, ông Nguyễn Trung Chính - Chủ tịch HĐQT/ Chủ tịch Điều hành Tập đoàn Công nghệ CMC đã nhấn mạnh sự phát triển nhanh chóng và cạnh tranh ngày càng gay gắt của thị trường đòi hỏi các tập đoàn công nghệ như CMC cần một chiến lược toàn diện và đặc biệt là các chiến lược về công nghệ để duy trì vị thế tiên phong và đạt được các mục tiêu tăng trưởng bền vững. “Lễ bổ nhiệm ngày hôm nay đánh dấu bước tiến quan trọng trong hành trình phát triển của Tập đoàn CMC.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Với việc bổ sung các vị trí lãnh đạo chủ chốt, Ban lãnh đạo của Tập đoàn giờ đây đã có 8 thành viên, đảm bảo sự đầy đủ và kiện toàn bộ máy quản trị cấp cao. Điều này khẳng định rằng Tập đoàn CMC đang xây dựng một đội ngũ lãnh đạo mạnh mẽ, với sự chuyên môn hoá và phân công rõ ràng”, Chủ tịch CMC chia sẻ.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Để hỗ trợ Ban lãnh đạo Tập đoàn CMC và các Đơn vị thành viên trong công tác định hướng triển khai các chiến lược kinh doanh, tối ưu hóa nguồn lực và dẫn dắt các sáng kiến về công nghệ và đổi mới sản phẩm, Ban lãnh đạo Tập đoàn CMC đã quyết định bổ nhiệm ông Đặng Tùng Sơn làm Giám đốc Chiến lược và ông Đặng Văn Tú giữ chức vụ Giám đốc Công nghệ.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Chủ tịch CMC trao quyết định bổ nhiệm cho ông Đặng Tùng Sơn giữ vị trí làm Giám đốc Chiến lược Ông Đặng Tùng Sơn tốt nghiệp Thạc sĩ chuyên ngành Viễn thông tại Đại học Pierre và Marie Curie (Pháp) và Quản trị Kinh doanh (MBA) tại Viện Công nghệ Châu Á (Thái Lan). Ông Sơn đã có 20 kinh nghiệm làm việc tại nhiều vị trí quan trọng tại EVN Telecom, Hiệp hội Internet Việt Nam,.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': '. .và trong đó có hơn 12 năm làm việc và đồng hành cùng CMC Telecom. Trong thời gian giữ vai trò Phó Tổng Giám đốc – Giám đốc Kinh doanh và Marketing tại CMC Telecom, ông Đặng Tùng Sơn đã điều hành toàn bộ hoạt động Kinh doanh Marketing của CMC Telecom đạt kết quả tốt trong điều kiện kinh tế gặp nhiều khó khăn, suy thoái, thị trường cạnh tranh nhiều đối thủ trong nước và quốc tế.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Ngoài ra, các hoạt động phát triển thị trường, quảng bá hình ảnh, kết nối đối tác,. . . của CMC Telecom nói riêng và Tập đoàn CMC nói chung ngày càng được mở rộng, nâng tầm vị thế và đạt được nhiều kết quả tích cực. Ông đã được vinh danh với giải thưởng Lãnh đạo xuất sắc cấp Tập đoàn năm tài chính 2018.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Chủ tịch CMC trao quyết định bổ nhiệm cho ông Đặng Văn Tú giữ chức vụ Giám đốc Công nghệ.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}, {'page_content': 'Ông  Đặng Văn Tú tốt nghiệp Thạc sĩ chuyên ngành Chuyển đổi số tại Trường Quản lý IÉSEG (Pháp) và Thạc sĩ chuyên ngành Quản trị Kinh doanh tại Đại học Paris I Panthéon-Sorbonne (Pháp). Ông Tú đã có 17 năm kinh nghiệm làm việc tại nhiều công ty công nghệ lớn như HPT Việt Nam, Microsoft, Softline International,.', 'date': '2024-10', 'url': 'https://www.cmc.com.vn/insight-detail/cmc-kien-toan-bo-may-lanh-dao-san-sang-cho-chien-luoc-chuyen-doi-ai-202410148561.html'}]\n"
     ]
    }
   ],
   "source": [
    "chunks=handling_csv('data_for_chunks','tintuc_cmc_url.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-08 00:39:25 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.97s/it]\n",
      "\u001b[32m2024-11-08 00:39:29 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.10s/it]\n",
      "\u001b[32m2024-11-08 00:39:32 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.99s/it]\n",
      "\u001b[32m2024-11-08 00:39:36 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 3/3 [00:13<00:00,  4.34s/it]\n",
      "\u001b[32m2024-11-08 00:39:50 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.89it/s]\n",
      "\u001b[32m2024-11-08 00:39:51 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.58s/it]\n",
      "\u001b[32m2024-11-08 00:39:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n",
      "\u001b[32m2024-11-08 00:39:55 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "\u001b[32m2024-11-08 00:39:58 INFO semantic_chunkers.utils.logger Single document exceeds the maximum token limit of 200. Splitting to sentences before semantically merging.\u001b[0m\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]e:\\Python\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "e:\\Python\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "e:\\Python\\Lib\\site-packages\\numpy\\core\\_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "e:\\Python\\Lib\\site-packages\\numpy\\core\\_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "e:\\Python\\Lib\\site-packages\\numpy\\core\\_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '26 CHANGE AGENT của C7+HABITS chính thức lộ diện 🥳.Sau hơn hai tháng triển khai tuyển chọn gắt gao, BTC chương trình C7+Habits đã chọn ra được 26 gương mặt xuất sắc nhất đại diện cho gần 4000 CMC-ers và trở thành C7+Habits Change Agent! .Các Change Agent được chọn lựa dựa trên các tiêu chí:.✅ Kiến thức:', 'date': '2024-11'}\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def handling_txt(url):\n",
    "    with open(f'data_for_chunks/{url}','r', encoding='utf-8') as suky_doc:\n",
    "        documents=suky_doc.read()\n",
    "    splitted_docs=documents.replace('\\n','.').split('seperate-1')\n",
    "    current_month = datetime.now().strftime('%Y-%m')\n",
    "    chunk =statistic_chunking(splitted_docs)\n",
    "    inserted_chunk=[]\n",
    "    for i in chunk:\n",
    "        inserted_chunk.extend(\n",
    "            [\n",
    "                {\n",
    "                    'content':x.content,\n",
    "                    'date': current_month\n",
    "                } for x in i \n",
    "            ]\n",
    "        )\n",
    "    print(inserted_chunk[0])\n",
    "    \n",
    "    client =MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cmc_data_3']\n",
    "    collection = db['resource']\n",
    "    counter_collection = db['counters']  # Collection to store the counter for auto-increment\n",
    "    def get_next_id():\n",
    "        counter_doc = counter_collection.find_one_and_update(\n",
    "            {'_id': 'resource_id'},\n",
    "            {'$inc': {'count': 1}},\n",
    "            upsert=True,\n",
    "            return_document=True\n",
    "        )\n",
    "        return counter_doc['count']\n",
    "    chunk_docs=[{'_id': get_next_id(),'page_content':x['content'],'date': current_month,'source':url} for x in inserted_chunk]\n",
    "    collection.insert_many(documents=chunk_docs)\n",
    "\n",
    "    client.close()\n",
    "concawc=handling_txt('additional.txt')\n",
    "print(concawc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
